{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571212e9",
   "metadata": {},
   "source": [
    "## Ensemble Exploration\n",
    "Questions to find answers to:\n",
    "- What is a good workflow for passing one image through the ensemble\n",
    "- What is a suitable loss? (Data is needed for that.)\n",
    "- Deep mutual learning losses vs standard student teacher loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.load_models import load_flownet2, load_pwcnet, init_weights\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp, warpImage, correlation_layer, min_convolution, meanfield\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "\n",
    "\n",
    "from models.pdd_net.pdd_student import OBELISK2d, deeds2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c1294",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow2 = load_flownet2().cuda()\n",
    "pwc = load_pwcnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = cv2.optflow.DualTVL1OpticalFlow_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baaca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.nn.Sequential(torch.nn.Conv2d(1,32,kernel_size=5,stride=2,padding=4,dilation=2),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(64),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(64,24,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "                          torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = OBELISK2d()\n",
    "reg = deeds2d()\n",
    "init_weights(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d52119",
   "metadata": {},
   "source": [
    "PWC and Flow2 seem to occupy around 1,5 GB on a graphics card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.load('Data/img.pth')\n",
    "segs = torch.load('Data/seg.pth')\n",
    "\n",
    "fix = 1; mov=2\n",
    "fixed = imgs[fix:fix+1,:,:].float() /255\n",
    "moving = imgs[mov:mov+1,:,:].float() /255\n",
    "\n",
    "fixed_seg = segs[fix:fix+1, :,:].float().contiguous()\n",
    "moving_seg = segs[mov:mov+1,:,:].float().contiguous()\n",
    "\n",
    "#fixed = F.interpolate(fixed.unsqueeze(0), size=(100,100)).view(1,100,100)\n",
    "#moving = F.interpolate(moving.unsqueeze(0), size=(100,100)).view(1,100,100)\n",
    "\n",
    "#fixed_seg = F.interpolate(fixed_seg.unsqueeze(0), size=(100,100)).view(1,100,100)\n",
    "#moving_seg = F.interpolate(moving_seg.unsqueeze(0), size=(100,100)).view(1,100,100)\n",
    "\n",
    "C,h,w = fixed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ee7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_in = preprocessing_flownet(fixed.reshape(h,w,C),moving.reshape(h,w,C)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f2044",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow2_out = flow2(flow_in).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwc_in = preprocessing_pwc(fixed.reshape(h,w,C),moving.reshape(h,w,C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwc.eval()\n",
    "pwc_out = pwc(pwc_in.cuda())\n",
    "pwc_out = pwc_out[0]*20\n",
    "pwc_out = pwc_out.cpu().data.numpy()\n",
    "\n",
    "pwc_out = np.swapaxes(np.swapaxes(pwc_out, 0, 1), 1, 2) \n",
    "\n",
    "divisor = 64\n",
    "H_ = int(ceil(h/divisor) * divisor)\n",
    "W_ = int(ceil(w/divisor) * divisor)\n",
    "\n",
    "u_ = cv2.resize(pwc_out[:,:,0],(w,h))\n",
    "v_ = cv2.resize(pwc_out[:,:,1],(w,h))\n",
    "u_ *= w/ float(W_)\n",
    "v_ *= h/ float(H_)\n",
    "pwc_out = np.dstack((u_,v_))\n",
    "\n",
    "pwc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c25eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow2_out = flow2_out.squeeze().cpu().detach().numpy().transpose(1,2,0)\n",
    "flow2_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "displace_range=11\n",
    "feat00 = seq(fixed.unsqueeze(0))\n",
    "feat50 = seq(moving.unsqueeze(0))\n",
    "ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "cost_soft, pred_xy = meanfield(ssd_distance, fixed.unsqueeze(0), displace_range, h//4, w//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531fcefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xy.squeeze().detach().view(h,w,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "in1 = fixed.view(h,w,1).detach().numpy().astype(np.float32) \n",
    "in2 = moving.view(h,w,1).detach().numpy().astype(np.float32) \n",
    "\n",
    "baseline_flow = baseline.calc(in1,in2,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf48ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.subplot(161)\n",
    "plt.title(\"FlowNet2\")\n",
    "plt.imshow(flow2img(flow2_out))\n",
    "\n",
    "plt.subplot(162)\n",
    "plt.title(\"PWC\")\n",
    "plt.imshow(flow2img(pwc_out))\n",
    "\n",
    "#plt.subplot(163)\n",
    "#plt.title(\"PDD-Untrained\")\n",
    "#plt.imshow(flow2img(pred_xy.squeeze().detach().view(h,w,2)))\n",
    "\n",
    "plt.subplot(164)\n",
    "plt.title(\"Baseline\")\n",
    "plt.imshow(flow2img(baseline_flow))\n",
    "\n",
    "plt.subplot(165)\n",
    "plt.title('Fixed')\n",
    "plt.imshow(fixed.squeeze().detach())\n",
    "\n",
    "plt.subplot(166)\n",
    "plt.title('Moving')\n",
    "plt.imshow(moving.squeeze().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c821f",
   "metadata": {},
   "source": [
    "So not happy with PWC\n",
    "\n",
    "BUT! PDD with init_weights, looks quite close to the desired flow. Ish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f26ac6",
   "metadata": {},
   "source": [
    "# Trying to learn on the data\n",
    "this is basically overfitting on one image with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ea282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = OBELISK2d()\n",
    "reg = deeds2d()\n",
    "init_weights(net)\n",
    "net.train()\n",
    "reg.train()\n",
    "\n",
    "# 20 epochs should be fine for overfitting\n",
    "epochs = 20\n",
    "optimizer = torch.optim.Adam(list(net.parameters())+list(reg.parameters()),lr=0.05)\n",
    "\n",
    "disp_range = 0.25#0.25\n",
    "displacement_width = 15#15#11#17\n",
    "shift_xy = F.affine_grid(disp_range*torch.eye(2,3).unsqueeze(0),(1,1,displacement_width,displacement_width)).view(1,1,-1,2) \n",
    "grid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,grid_size,grid_size)).view(1,-1,1,2)\n",
    "\n",
    "# Testing with only one image to overfit on the flow and check if it works\n",
    "# verfitting with upscale\n",
    "diffs = []\n",
    "\n",
    "# Genrate the flow we want to approximate\n",
    "\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    #teacher_output = flow2(flow_in).cpu()\n",
    "\n",
    "    # Generate the pdd-output\n",
    "    fixed.requires_grad = True\n",
    "    moving.requires_grad=True\n",
    "    \n",
    "    feat00 = net(fixed.unsqueeze(0))\n",
    "    feat50 = net(moving.unsqueeze(0))\n",
    "    \n",
    "    soft_cost, pred_xy = reg(feat00,feat50)\n",
    "    pred_xy = pred_xy.view(1,grid_size,grid_size,2)\n",
    "    diffloss = 1.5*((pred_xy[0,:,1:,:]-pred_xy[0,:,:-1,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,1:,:,:]-pred_xy[0,:-1,:,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,:,:,1:]-pred_xy[0,:,:,:-1])**2).mean()\n",
    "    \n",
    "    # Not sure what this does. \n",
    "    nonlocal_label = (F.grid_sample(labelMatrixOneHot(moving_seg,9).float(),grid_xy+shift_xy,padding_mode='border')\\\n",
    "                          *soft_cost.view(1,-1,grid_size**2,displacement_width**2)).sum(1,keepdim=True)\n",
    "    fixed_label = F.grid_sample(labelMatrixOneHot(fixed_seg,9).float(),grid_xy,padding_mode='border')#.long().squeeze(1)\n",
    "\n",
    "    orig_labelloss = ((fixed_label-nonlocal_label)**2).mean()\n",
    "    diff = orig_labelloss + diffloss\n",
    "    diff.backward()\n",
    "    diffs.append(diff.item())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0571a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs), diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "reg.eval()\n",
    "\n",
    "feat00 = net(fixed.unsqueeze(0))\n",
    "feat50 = net(moving.unsqueeze(0))\n",
    "\n",
    "cost_soft, pred_xy = reg(feat00,feat50)\n",
    "teacher_out = flow2(flow_in).cpu()\n",
    "teacher_grid = F.grid_sample(teacher_out, grid_xy)\n",
    "\n",
    "dense_flow_fit = F.interpolate(pred_xy.transpose(0,1).view(1,2,grid_size,grid_size),size=(h,w),mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,h,w),align_corners=False)\n",
    "warped_seg = F.grid_sample(fixed_seg.float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False)\n",
    "\n",
    "warped_baseline = warpImage(fixed_seg.unsqueeze(0).cpu(), torch.from_numpy(baseline_flow).unsqueeze(0).view(1,2,h,w).cpu())\n",
    "\n",
    "#warped_baseline = F.grid_sample(moving_seg.float().unsqueeze(1),torch.from_numpy(baseline_flow).unsqueeze(0),mode='nearest',align_corners=False)\n",
    "d1 = dice_coeff(moving_seg,warped_seg.squeeze(),8)\n",
    "print(\"Dice between moving and warped: \",d1,d1.mean())\n",
    "d2 = dice_coeff(moving_seg,warped_baseline.squeeze(),8)\n",
    "print(\"Dice between moving and baseline: \",d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,8)\n",
    "print(\"Dice between fixed and moving: \",d3, d3.mean())\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title(\"PDD-Output\")\n",
    "plt.imshow(showFlow(pred_xy.transpose(0,1).reshape(2,grid_size,grid_size).detach()))\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Fixed')\n",
    "plt.imshow(fixed.detach().squeeze())\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title('Moving')\n",
    "plt.imshow(moving.detach().squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40ac60",
   "metadata": {},
   "source": [
    "## Let's get a small pdd_net to learn FlowNet2 warpings\n",
    "\n",
    "trying to overfit on the wapred data of the flownet2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d97d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = OBELISK2d()\n",
    "reg = deeds2d()\n",
    "init_weights(net)\n",
    "net.train()\n",
    "reg.train()\n",
    "\n",
    "# 20 epochs should be fine for overfitting\n",
    "epochs = 30\n",
    "optimizer = torch.optim.Adam(list(net.parameters())+list(reg.parameters()),lr=0.05)\n",
    "\n",
    "disp_range = 0.25#0.25\n",
    "displacement_width = 15#15#11#17\n",
    "shift_xy = F.affine_grid(disp_range*torch.eye(2,3).unsqueeze(0),(1,1,displacement_width,displacement_width)).view(1,1,-1,2) \n",
    "grid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,grid_size,grid_size)).view(1,-1,1,2)\n",
    "\n",
    "# Testing with only one image to overfit on the flow and check if it works\n",
    "# verfitting with upscale\n",
    "diffs = []\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    # Genrate the flow we want to approximate\n",
    "    teacher_flow = flow2(flow_in).cpu()\n",
    "    warped_moving_teacher = warpImage(labelMatrixOneHot(fixed_seg,9), teacher_flow)\n",
    "\n",
    "    # Generate the pdd-output\n",
    "    fixed.requires_grad = True\n",
    "    moving.requires_grad=True\n",
    "    \n",
    "    feat00 = net(fixed.unsqueeze(0))\n",
    "    feat50 = net(moving.unsqueeze(0))\n",
    "    \n",
    "    soft_cost, pred_xy = reg(feat00,feat50)\n",
    "    pred_xy = pred_xy.view(1,grid_size,grid_size,2)\n",
    "    \n",
    "    diffloss = 1.5*((pred_xy[0,:,1:,:]-pred_xy[0,:,:-1,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,1:,:,:]-pred_xy[0,:-1,:,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,:,:,1:]-pred_xy[0,:,:,:-1])**2).mean()\n",
    "    \n",
    "    warped_seg = (F.grid_sample(labelMatrixOneHot(fixed_seg,9).float(),grid_xy+shift_xy,padding_mode='border')\\\n",
    "                          *soft_cost.view(1,-1,grid_size**2,displacement_width**2)).sum(1,keepdim=True)\n",
    "    warped_teacher = F.grid_sample(warped_moving_teacher, grid_xy)\n",
    "    \n",
    "    diff =(warped_teacher-warped_seg).sum()\n",
    "    diff.backward()\n",
    "    diffs.append(diff.item())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95678ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs), diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa98635",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "reg.eval()\n",
    "\n",
    "feat00 = net(fixed.unsqueeze(0))\n",
    "feat50 = net(moving.unsqueeze(0))\n",
    "\n",
    "cost_soft, pred_xy = reg(feat00,feat50)\n",
    "teacher_out = flow2(flow_in).cpu()\n",
    "teacher_grid = F.grid_sample(teacher_out, grid_xy)\n",
    "\n",
    "dense_flow_fit = F.interpolate(pred_xy.transpose(0,1).view(1,2,grid_size,grid_size),size=(h,w),mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,h,w),align_corners=False)\n",
    "warped_seg = F.grid_sample(fixed_seg.float().unsqueeze(0),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False)\n",
    "\n",
    "warped_baseline = warpImage(fixed_seg.unsqueeze(0).cpu(), torch.from_numpy(baseline_flow).unsqueeze(0).view(1,2,h,w).cpu())\n",
    "\n",
    "#warped_baseline = F.grid_sample(moving_seg.float().unsqueeze(1),torch.from_numpy(baseline_flow).unsqueeze(0),mode='nearest',align_corners=False)\n",
    "d1 = dice_coeff(moving_seg,warped_seg.squeeze(),8)\n",
    "print(d1,d1.mean())\n",
    "d2 = dice_coeff(moving_seg,warped_baseline.squeeze(),8)\n",
    "print(d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,8)\n",
    "print(d3, d3.mean())\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title(\"PDD-Output\")\n",
    "plt.imshow(showFlow(pred_xy.transpose(0,1).reshape(2,grid_size,grid_size).detach()))\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Fixed')\n",
    "plt.imshow(fixed.detach().squeeze())\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title('Moving')\n",
    "plt.imshow(moving.detach().squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d621f",
   "metadata": {},
   "source": [
    "## Train Pdd with Flow2 as teacher\n",
    "Only try to learn the flow estimation from the flownet\n",
    "\n",
    "This is to approximate the teacher and only the teacher output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609502b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = torch.sqrt(1.0/(torch.bincount(segs.view(-1)).float()))\n",
    "class_weight = class_weight/class_weight.mean()\n",
    "class_weight[0] = 0.15\n",
    "class_weight = class_weight.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11b5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "epochs = 100\n",
    "lr = 0.025\n",
    "#delta = 0.8\n",
    "\n",
    "net = OBELISK2d()\n",
    "reg = deeds2d()\n",
    "net.train()\n",
    "reg.train()\n",
    "\n",
    "init_weights(net)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=list(net.parameters()) + list(reg.parameters()), lr=lr)\n",
    "\n",
    "torch.manual_seed(10)\n",
    "# Now, we prepare our train & test dataset.\n",
    "test_set = torch.LongTensor([35, 41, 0, 4, 39, 17])\n",
    "train_set = torch.arange(43)\n",
    "for idx in test_set:\n",
    "    train_set = train_set[train_set != idx]\n",
    "\n",
    "diffs=[]\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:] / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:] / 255\n",
    "    #Flow output from teacher1\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:]\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:]\n",
    "        \n",
    "    flow_in = preprocessing_flownet(fixed.reshape(h,w,C),moving.reshape(h,w,C)).cuda()\n",
    "    teacher_flow = flow2(flow_in).cpu()\n",
    "    warped_moving_teacher = warpImage(labelMatrixOneHot(fixed_seg,9), teacher_flow)\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = net(fixed.unsqueeze(0))\n",
    "    feat50 = net(moving.unsqueeze(0))\n",
    "\n",
    "    # Need some help here. I am not using the soft_cost at all. Not sure how tho\n",
    "    soft_cost, pred_xy = reg(feat00,feat50)\n",
    "    \n",
    "    pred_xy = pred_xy.view(1,grid_size,grid_size,2)\n",
    "    \n",
    "    diffloss = 1.5*((pred_xy[0,:,1:,:]-pred_xy[0,:,:-1,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,1:,:,:]-pred_xy[0,:-1,:,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,:,:,1:]-pred_xy[0,:,:,:-1])**2).mean()\n",
    "    \n",
    "    warped_seg = (F.grid_sample(labelMatrixOneHot(fixed_seg,9).float(),grid_xy+shift_xy,padding_mode='border')\\\n",
    "                          *soft_cost.view(1,-1,grid_size**2,displacement_width**2)).sum(1,keepdim=True)\n",
    "    warped_teacher = F.grid_sample(warped_moving_teacher, grid_xy).detach()\n",
    "\n",
    "    teacher_loss = torch.pow((warped_teacher - warped_seg),2)\n",
    "    loss = teacher_loss.mean()\n",
    "    #loss = (3/4 * orig_labelloss + (1/4 * teacher_loss)).mean()\n",
    "    loss.backward()\n",
    "    diffs.append(loss.item())\n",
    "    \n",
    "    #diff.backward()\n",
    "    #diffs.append(diff.item())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13818fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs), diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f9410",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "reg.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:] / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:] / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:]\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:]\n",
    "\n",
    "feat1 = net(fixed.unsqueeze(0))\n",
    "feat2 = net(moving.unsqueeze(0))\n",
    "\n",
    "soft_cost, pred_xy = reg(feat1,feat2)\n",
    "\n",
    "dense_flow_fit = F.interpolate(pred_xy.transpose(0,1).view(1,2,grid_size,grid_size),size=(h,w),mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,h,w),align_corners=False)\n",
    "warped_seg = F.grid_sample(fixed_seg.float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False)\n",
    "\n",
    "in1 = fixed.view(h,w,1).detach().numpy().astype(np.float32) \n",
    "in2 = moving.view(h,w,1).detach().numpy().astype(np.float32) \n",
    "\n",
    "baseline_flow = baseline.calc(in1,in2,None)\n",
    "warped_baseline = warpImage(fixed_seg.unsqueeze(0).cpu().float(), torch.from_numpy(baseline_flow).unsqueeze(0).view(1,2,h,w).cpu())\n",
    "\n",
    "d1 = dice_coeff(moving_seg,warped_seg.squeeze(),9)\n",
    "print(\"PDD-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(moving_seg, warped_baseline, 9)\n",
    "print(\"Baseline: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8070559",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a57f1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c801184",
   "metadata": {},
   "source": [
    "## Using Flow2 as teacher and training on regular data\n",
    "combining the teacher loss with the data loss\n",
    "\n",
    "With a very high delta (not using the flownet it works...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "epochs = 1000\n",
    "lr = 0.005\n",
    "delta = 0.5\n",
    "\n",
    "net = OBELISK2d()\n",
    "reg = deeds2d()\n",
    "net.train()\n",
    "reg.train()\n",
    "\n",
    "init_weights(net)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=list(net.parameters()) + list(reg.parameters()), lr=lr)\n",
    "\n",
    "disp_range = 0.25#0.25\n",
    "displacement_width = 15#15#11#17\n",
    "shift_xy = F.affine_grid(disp_range*torch.eye(2,3).unsqueeze(0),(1,1,displacement_width,displacement_width)).view(1,1,-1,2) \n",
    "grid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,grid_size,grid_size)).view(1,-1,1,2)\n",
    "\n",
    "total_loss = []\n",
    "\n",
    "kl_loss = torch.nn.KLDivLoss()\n",
    "\n",
    "torch.manual_seed(10)\n",
    "\n",
    "pat_indices = torch.cat((torch.arange(0, 17), torch.arange(18, 43)), 0)\n",
    "\n",
    "rnd_perm_idc = torch.randperm(pat_indices.size(0))\n",
    "pat_indices = pat_indices[rnd_perm_idc]\n",
    "\n",
    "# Now, we prepare our train & test dataset.\n",
    "test_set = torch.LongTensor([35, 41, 0, 4, 39, 17])\n",
    "train_set = torch.arange(43)\n",
    "for idx in test_set:\n",
    "    train_set = train_set[train_set != idx]\n",
    "\n",
    "diffs = []\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:] / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:] / 255\n",
    "    #Flow output from teacher1\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:]\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:]\n",
    "        \n",
    "    flow_in = preprocessing_flownet(fixed.reshape(h,w,C),moving.reshape(h,w,C)).cuda()\n",
    "    teacher_flow = flow2(flow_in).cpu()\n",
    "    warped_moving_teacher = warpImage(labelMatrixOneHot(moving_seg,9), teacher_flow)\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = net(fixed.unsqueeze(0))\n",
    "    feat50 = net(moving.unsqueeze(0))\n",
    "\n",
    "    # Need some help here. I am not using the soft_cost at all. Not sure how tho\n",
    "    soft_cost, pred_xy = reg(feat00,feat50)\n",
    "    \n",
    "    pred_xy = pred_xy.view(1,grid_size,grid_size,2)\n",
    "    \n",
    "    diffloss = 1.5*((pred_xy[0,:,1:,:]-pred_xy[0,:,:-1,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,1:,:,:]-pred_xy[0,:-1,:,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,:,:,1:]-pred_xy[0,:,:,:-1])**2).mean()\n",
    "    \n",
    "    warped_seg = (F.grid_sample(labelMatrixOneHot(moving_seg,9).float(),grid_xy+shift_xy,padding_mode='border')\\\n",
    "                          *soft_cost.view(1,-1,grid_size**2,displacement_width**2)).sum(1,keepdim=True)\n",
    "    warped_teacher = F.grid_sample(warped_moving_teacher, grid_xy).detach()\n",
    "\n",
    "    teacher_loss = torch.pow((warped_seg - warped_teacher),2).mean()\n",
    "    \n",
    "    nonlocal_label = (F.grid_sample(labelMatrixOneHot(moving_seg,9).float(),grid_xy+shift_xy,padding_mode='border')\\\n",
    "                          *soft_cost.view(1,-1,grid_size**2,displacement_width**2)).sum(1,keepdim=True)\n",
    "    fixed_label = F.grid_sample(labelMatrixOneHot(fixed_seg,9).float(),grid_xy,padding_mode='border')#.long().squeeze(1)\n",
    "\n",
    "    orig_labelloss = ((nonlocal_label-fixed_label)**2).mean()\n",
    "    \n",
    "    \n",
    "    loss = (diffloss + (1-delta)*teacher_loss + delta*orig_labelloss)\n",
    "    loss.backward()\n",
    "    diffs.append(loss.item())\n",
    "    \n",
    "    #diff.backward()\n",
    "    #diffs.append(diff.item())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22745cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs), diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "reg.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:] / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:] / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:]\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:]\n",
    "\n",
    "feat1 = net(fixed.unsqueeze(0))\n",
    "feat2 = net(moving.unsqueeze(0))\n",
    "\n",
    "soft_cost, pred_xy = reg(feat1,feat2)\n",
    "\n",
    "dense_flow_fit = F.interpolate(pred_xy.transpose(0,1).view(1,2,grid_size,grid_size),size=(h,w),mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,h,w),align_corners=False)\n",
    "warped_seg = F.grid_sample(moving_seg.float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False)\n",
    "\n",
    "in1 = fixed.view(h,w,1).detach().numpy().astype(np.float32) \n",
    "in2 = moving.view(h,w,1).detach().numpy().astype(np.float32) \n",
    "\n",
    "baseline_flow = baseline.calc(in1,in2,None)\n",
    "warped_baseline = warpImage(moving_seg.unsqueeze(0).cpu().float(), torch.from_numpy(baseline_flow).unsqueeze(0).view(1,2,h,w).cpu())\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_seg.squeeze(),8)\n",
    "print(\"PDD-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg, warped_baseline, 8)\n",
    "print(\"Baseline: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ffe89",
   "metadata": {},
   "source": [
    "## Playing with KLDiv\n",
    "Using klDiv and the learning diff and loss.\n",
    "Setting delta to different values, and check, which one learnes the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "epochs = 1000\n",
    "lr = 0.0025\n",
    "delta = 0.5\n",
    "\n",
    "net = OBELISK2d()\n",
    "reg = deeds2d()\n",
    "net.train()\n",
    "reg.train()\n",
    "\n",
    "init_weights(net)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=list(net.parameters()) + list(reg.parameters()), lr=lr)\n",
    "\n",
    "disp_range = 0.25#0.25\n",
    "displacement_width = 15#15#11#17\n",
    "shift_xy = F.affine_grid(disp_range*torch.eye(2,3).unsqueeze(0),(1,1,displacement_width,displacement_width)).view(1,1,-1,2) \n",
    "grid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,grid_size,grid_size)).view(1,-1,1,2)\n",
    "\n",
    "total_loss = []\n",
    "\n",
    "kl_loss = torch.nn.KLDivLoss()\n",
    "\n",
    "torch.manual_seed(10)\n",
    "\n",
    "pat_indices = torch.cat((torch.arange(0, 17), torch.arange(18, 43)), 0)\n",
    "\n",
    "rnd_perm_idc = torch.randperm(pat_indices.size(0))\n",
    "pat_indices = pat_indices[rnd_perm_idc]\n",
    "\n",
    "# Now, we prepare our train & test dataset.\n",
    "test_set = torch.LongTensor([35, 41, 0, 4, 39, 17])\n",
    "train_set = torch.arange(43)\n",
    "for idx in test_set:\n",
    "    train_set = train_set[train_set != idx]\n",
    "\n",
    "diffs = []\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:] / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:] / 255\n",
    "    #Flow output from teacher1\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:]\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:]\n",
    "        \n",
    "    flow_in = preprocessing_flownet(fixed.reshape(h,w,C),moving.reshape(h,w,C)).cuda()\n",
    "    teacher_flow = flow2(flow_in).cpu()\n",
    "    warped_moving_teacher = warpImage(labelMatrixOneHot(moving_seg,9), teacher_flow)\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = net(fixed.unsqueeze(0))\n",
    "    feat50 = net(moving.unsqueeze(0))\n",
    "\n",
    "    # Need some help here. I am not using the soft_cost at all. Not sure how tho\n",
    "    soft_cost, pred_xy = reg(feat00,feat50)\n",
    "    \n",
    "    pred_xy = pred_xy.view(1,grid_size,grid_size,2)\n",
    "    \n",
    "    diffloss = 1.5*((pred_xy[0,:,1:,:]-pred_xy[0,:,:-1,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,1:,:,:]-pred_xy[0,:-1,:,:])**2).mean()+\\\n",
    "            1.5*((pred_xy[0,:,:,1:]-pred_xy[0,:,:,:-1])**2).mean()\n",
    "    \n",
    "    warped_seg = (F.grid_sample(labelMatrixOneHot(moving_seg,9).float(),grid_xy+shift_xy,padding_mode='border')\\\n",
    "                          *soft_cost.view(1,-1,grid_size**2,displacement_width**2)).sum(1,keepdim=True)\n",
    "    warped_teacher = F.grid_sample(warped_moving_teacher, grid_xy).detach()\n",
    "\n",
    "    teacher_loss = - kl_loss(warped_seg,warped_teacher)\n",
    "    \n",
    "    \n",
    "    nonlocal_label = (F.grid_sample(labelMatrixOneHot(moving_seg,9).float(),grid_xy+shift_xy,padding_mode='border')\\\n",
    "                          *soft_cost.view(1,-1,grid_size**2,displacement_width**2)).sum(1,keepdim=True)\n",
    "    fixed_label = F.grid_sample(labelMatrixOneHot(fixed_seg,9).float(),grid_xy,padding_mode='border')#.long().squeeze(1)\n",
    "\n",
    "    orig_labelloss = ((nonlocal_label-fixed_label)**2).mean()\n",
    "\n",
    "    loss = diffloss + (1-delta)*teacher_loss + delta*orig_labelloss\n",
    "    loss.backward()\n",
    "    diffs.append(loss.item())\n",
    "    \n",
    "    #diff.backward()\n",
    "    #diffs.append(diff.item())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65378b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs), diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719af5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "reg.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:] / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:] / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:]\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:]\n",
    "\n",
    "feat1 = net(fixed.unsqueeze(0))\n",
    "feat2 = net(moving.unsqueeze(0))\n",
    "\n",
    "soft_cost, pred_xy = reg(feat1,feat2)\n",
    "\n",
    "dense_flow_fit = F.interpolate(pred_xy.transpose(0,1).view(1,2,grid_size,grid_size),size=(h,w),mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,h,w),align_corners=False)\n",
    "warped_seg = F.grid_sample(moving_seg.float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False)\n",
    "\n",
    "in1 = fixed.view(h,w,1).detach().numpy().astype(np.float32) \n",
    "in2 = moving.view(h,w,1).detach().numpy().astype(np.float32) \n",
    "\n",
    "baseline_flow = baseline.calc(in1,in2,None)\n",
    "warped_baseline = warpImage(moving_seg.unsqueeze(0).cpu().float(), torch.from_numpy(baseline_flow).unsqueeze(0).view(1,2,h,w).cpu())\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_seg.squeeze(),8)\n",
    "print(\"PDD-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg, warped_baseline, 8)\n",
    "print(\"Baseline: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,8)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ea740",
   "metadata": {},
   "source": [
    "# Verdict\n",
    "seems to outperform the baseline somehow...\n",
    "Actually, is this stuff working??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c647760",
   "metadata": {},
   "source": [
    "# 16.06.21 Comparing obelisk to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3adc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
