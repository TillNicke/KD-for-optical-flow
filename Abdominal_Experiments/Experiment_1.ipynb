{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551930c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import misc\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import medpy\n",
    "from medpy.io import load\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import ceil\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.load_models import load_flownet2, load_pwcnet, init_weights\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp, warpImage #, correlation_layer, meanfield\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "\n",
    "\n",
    "from models.pdd_net.pdd_student import OBELISK2d, deeds2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e082cc",
   "metadata": {},
   "source": [
    "# Data\n",
    "Load data and split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.load('Data/img.pth')\n",
    "segs = torch.load('Data/seg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7739cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a training split \n",
    "torch.manual_seed(10)\n",
    "# Now, we prepare our train & test dataset.\n",
    "test_set = torch.LongTensor([35, 41, 0, 4, 39])\n",
    "train_set = torch.arange(43)\n",
    "for idx in test_set:\n",
    "    train_set = train_set[train_set != idx]\n",
    "print(\"Train: \", train_set)\n",
    "print(\"Test: \", test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7656e256",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_normal(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant(m.bias, 0.0)\n",
    "\n",
    "class OBELISK2d(nn.Module):\n",
    "    def __init__(self, chan = 16):\n",
    "\n",
    "        super(OBELISK2d, self).__init__()\n",
    "        channels = chan\n",
    "        self.offsets = nn.Parameter(torch.randn(2,channels *2,2) *0.05)\n",
    "        self.layer0 = nn.Conv2d(1, 4, 5, stride=2, bias=False, padding=2)\n",
    "        self.batch0 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.layer1 = nn.Conv2d(channels *8, channels *4, 1, bias=False, groups=1)\n",
    "        self.batch1 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer2 = nn.Conv2d(channels *4, channels *4, 3, bias=False, padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer3 = nn.Conv2d(channels *4, channels *1, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_img):\n",
    "        img_in = F.avg_pool2d(input_img ,3 ,padding=1 ,stride=2)\n",
    "        img_in = F.relu(self.batch0(self.layer0(img_in)))\n",
    "        sampled = F.grid_sample(img_in ,ogrid_xy + self.offsets[0 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "        sampled -= F.grid_sample(img_in ,ogrid_xy + self.offsets[1 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "\n",
    "        x = F.relu(self.batch1(self.layer1(sampled)))\n",
    "        x = F.relu(self.batch2(self.layer2(x)))\n",
    "        features = self.layer3(x)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d9d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize the sequential used for comparisson\n",
    "# The output will be used later with the correlation layer and the meanfield inference\n",
    "seq = torch.nn.Sequential(torch.nn.Conv2d(1,32,kernel_size=5,stride=2,padding=4,dilation=2),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(64),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(64,24,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "                          torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccaddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_convolution(ssd_distance, displace_range, H, W):\n",
    "    # Prepare operators for smooth dense displacement space\n",
    "    pad1 = nn.ReplicationPad2d(5)\n",
    "    avg1 = nn.AvgPool2d(5,stride=1)\n",
    "    max1 = nn.MaxPool2d(3,stride=1)\n",
    "    pad2 = nn.ReplicationPad2d(6)\n",
    "    # approximate min convolution / displacement compatibility\n",
    "\n",
    "    # 1) switch dimensions in order to get per HW position the displacement with \"highest correlation\" by\n",
    "    # means of lowest SSD \n",
    "    # therefore, swap the dimensions of the tensor in order to make the pooling operations work along the \n",
    "    # displacement search region: [1,121,80,64] -> [1,80,64,121] -> [1,80*64,11,11] = [1,5120,11,11]\n",
    "    # using appropriate padding, -max(-x) u get the min value and 2x avg-pooling afterwards for quadratic smoothing\n",
    "    ssd_minconv = avg1(avg1(-max1(-pad1(ssd_distance.permute(0,2,3,1).reshape(1,-1,displace_range,displace_range)))))\n",
    "\n",
    "    # 2)reconstruct the spatial arangement [1,121,80,78] and perform the spatial mean-field inference under valid padding\n",
    "    ssd_minconv = ssd_minconv.permute(0,2,3,1).view(1,-1,H,W)\n",
    "    min_conv_cost = avg1(avg1(avg1(pad2(ssd_minconv))))\n",
    "    \n",
    "    return min_conv_cost\n",
    "\n",
    "# meanfield converts 4D tensor with SSD distance cost (of all displacements) into regularised probabilistic field\n",
    "def meanfield(ssd_distance,img_fixed,displace_range,H,W):\n",
    "\n",
    "    crnt_dev = ssd_distance.device\n",
    "\n",
    "\n",
    "    cost = min_convolution(ssd_distance, displace_range, H, W)\n",
    "\n",
    "    # probabilistic output: compute the contributions weights of every discrete displacement pair for all positions\n",
    "    # along 121 possible xy displacements -> normalize to [0,1] with softmax:\n",
    "    # in order to have the lowest SSD value as the \"max\" 1 value, multiply it with -10 beforehand\n",
    "\n",
    "    # therefore apply the softmax along the displacement dimension\n",
    "    # reshaping the cost tensor as follows: [1,121,H,W] -> [121, H*W] -> [H*W,121] : perform softmax along dim 1\n",
    "    soft_cost = F.softmax(-10*cost.view(displace_range**2,-1).t(),1)\n",
    "\n",
    "    #calculate displacement field (could be shorted when stacking x,y - but less intuitive)\n",
    "    # idea: 1) construct a meshgrid of all discrete displacement pairs per position\n",
    "    #       2) use broadcasting to get the weighted contributions of all displacement values (separated for x&y)\n",
    "    #          (soft_cost) [H*W,121] x [1,121] (xs,ys) : sum along dim 1 -> [H*W] -> reshape [H,W]\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    disp_mesh_grid = disp_hw*F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,displace_range,displace_range),align_corners=True)\n",
    "    disp_mesh_grid /= torch.Tensor([(W-1)*.5,(H-1)*.5])\n",
    "\n",
    "    disp_xy = torch.sum(soft_cost.view(1,H,W,-1,1)*disp_mesh_grid.view(1,1,1,-1,2).to(crnt_dev),3).permute(0,3,1,2) \n",
    "    \n",
    "    # the transform will later be resampled to high resolution and we have to add the identity transform\n",
    "\n",
    "\n",
    "    return soft_cost,disp_xy\n",
    "def correlation_layer(displace_range, feat_moving, feat_fixed):\n",
    "    # tensor dimensionalities in comments are for our arbitrary choice of\n",
    "    # displace_range = 11 & feat sizes of [1,24,80,64];\n",
    "    # they clearly depend on the actual choice of feature stride and displace_range and only serve as numerical examples here.\n",
    "    \n",
    "    # feat_mov: [1,24,80,64] -> 24 feature channels + spatial HW dims\n",
    "    # feat_mov_unfold: [24,121,5120] -> mind chans, 11*11 = 121 displ steps, 5120 = 80*64 spatial positions\n",
    "    \n",
    "    # feat_fixed: [24,1,5120] -> compute scalarproduct along feature dimension per broadcast + sum along 0\n",
    "    # and reshape to [1,121,80,64]\n",
    "\n",
    "    \n",
    "    # TODO IMPLEMENT THE CORRELATION LAYER (or find the solution in learn2reg_discrete.py)\n",
    "    \n",
    "    # tensor dimensionalities in comments are for an arbitrary choice of\n",
    "    # displace_range = 11 & feat sizes of [1,24,80,78];\n",
    "    # they clearly depend on the actual choice and only serve as numerical examples here.\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    # feat_mov: [1,24,80,78] -> 24 feature channels + spatial HW dims\n",
    "    # feat_mov_unfold: [24,121,6240] -> mind chans, 11*11 = 121 displ steps, 6240 = 80*78 spatial positions\n",
    "    feat_moving_unfold = F.unfold(feat_moving.transpose(1,0),(displace_range,displace_range),padding=disp_hw)\n",
    "    B,C,H,W = feat_fixed.size()\n",
    "    \n",
    "    # feat_fixed: [24,1,6240] -> compute scalarproduct along feature dimension per broadcast + sum along 0\n",
    "    # and reshape to [1,121,80,78]\n",
    "    ssd_distance = ((feat_moving_unfold-feat_fixed.view(C,1,-1))**2).sum(0).view(1,displace_range**2,H,W)\n",
    "    #reshape the 4D tensor back to spatial dimensions\n",
    "    return ssd_distance#.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac34342",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "Compare both options in terms of performance and mean dice score, when trained for 1000 epochs with same optimizer. Evaluation will be done on test_set after the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e4ff3c",
   "metadata": {},
   "source": [
    "### Obelisk Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6185c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First for the obelisk network as feature extractor\n",
    "obel = OBELISK2d(24)\n",
    "init_weights(obel)\n",
    "obel.cuda().train()\n",
    "\n",
    "epochs = 1000\n",
    "# minibatch training\n",
    "grad_accum = 4\n",
    "optimizer = torch.optim.Adam(list(obel.parameters()),lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6eb1d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "diffs = []\n",
    "\n",
    "# Genrate the flow we want to approximate\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # taining examples randomly selected\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    # Label onehot and scale to outputsize \n",
    "    label_moving = F.one_hot(moving_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    _,C1,Hf,Wf = label_moving.size()\n",
    "    label_moving = F.interpolate(label_moving,size=(H//4,Wf//4),mode='bilinear')\n",
    "    label_fixed = F.one_hot(fixed_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    label_fixed = F.interpolate(label_fixed,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "    # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "    # according to the corresponding discrete displacement pair\n",
    "    label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,9,displace_range**2,-1)\n",
    "    \n",
    "    \n",
    "    # passed through obelisk layer\n",
    "    feat00 = obel(fixed.cuda())      # fixed\n",
    "    feat50 = obel(moving.cuda())     # moving\n",
    "    \n",
    "     # compute the cost tensor using the correlation layer\n",
    "    ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "    label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "    # compute the loss as sum of squared differences between the fixed label representation and the \"warped\" labels\n",
    "    label_distance1 = torch.sum(torch.pow(label_fixed.reshape(9,-1)-label_warped.reshape(9,-1),2),0)\n",
    "    loss = label_distance1.mean()\n",
    "    # perform the backpropagation and weight updates\n",
    "    loss.backward()\n",
    "\n",
    "    diffs.append(loss.item())\n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1ba8c2",
   "metadata": {},
   "source": [
    "### Obelisk Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc91ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obel.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feat1 = obel(fixed.cuda())\n",
    "    feat2 = obel(moving.cuda())\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, feat2, feat1).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,pred_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "dense_flow_fit = F.interpolate(pred_xy, scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "\n",
    "warped_seg = F.grid_sample(fixed_seg.float().unsqueeze(1).cuda(),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "\n",
    "d1 = dice_coeff(moving_seg,warped_seg.squeeze(),9)\n",
    "print(\"PDD-Student: \", d1,d1.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "\n",
    "#visualise\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e47e58",
   "metadata": {},
   "source": [
    "### Seq training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.cuda().train()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(seq.parameters()),lr=0.00025)\n",
    "disp_hw = 5\n",
    "displace_range = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11a915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdx in range(epochs):\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    \n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    img_fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float()/255\n",
    "    img_moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float()/255\n",
    "\n",
    "    #feat_fixed = seq(img_fixed)\n",
    "    #feat_moving = seq(img_moving)\n",
    "\n",
    "    seg_fixed = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    seg_moving = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    label_moving = F.one_hot(seg_moving,num_classes=9).permute(0,3,1,2).float()\n",
    "    _,C1,Hf,Wf = label_moving.size()\n",
    "    label_moving = F.interpolate(label_moving,size=(H//4,Wf//4),mode='bilinear')\n",
    "    label_fixed = F.one_hot(seg_fixed,num_classes=9).permute(0,3,1,2).float()\n",
    "    label_fixed = F.interpolate(label_fixed,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "    # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "    # according to the corresponding discrete displacement pair\n",
    "    label_moving_unfold = F.unfold(\n",
    "        label_moving,(displace_range,displace_range),padding=disp_hw\n",
    "    ).view(1,9,displace_range**2,-1)\n",
    "    \n",
    "\n",
    "    #forward path: pass both images through the network so that the weights appear in the computation graph\n",
    "    # and will be updated\n",
    "    feat_fixed = seq(img_fixed.cuda()).cpu()\n",
    "    feat_moving = seq(img_moving.cuda()).cpu()\n",
    "    # compute the cost tensor using the correlation layer\n",
    "    ssd_distance = correlation_layer(displace_range, feat_moving, feat_fixed)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, img_fixed, displace_range, H//4, W//4)\n",
    "    # loss computation:\n",
    "    # compute the weighted sum of the shifted moving label versions \n",
    "    \n",
    "    label_warped = torch.sum(soft_cost.t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "    # compute the loss as sum of squared differences between the fixed label representation and the \"warped\" labels\n",
    "    label_distance1 = torch.sum(torch.pow(label_fixed.reshape(9,-1)-label_warped.reshape(9,-1),2),0)\n",
    "    loss = label_distance1.mean()\n",
    "    # perform the backpropagation and weight updates\n",
    "    loss.backward()\n",
    "    if (pdx+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c17b7e",
   "metadata": {},
   "source": [
    "### Seq Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07132da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed_img = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving_img = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = seq(fixed_img.cuda())\n",
    "    moving_feat = seq(moving_img.cuda())\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,disp_xy = meanfield(ssd_distance, fixed_img.unsqueeze(1), displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_seg.squeeze(),9)\n",
    "print(\"CNN-Student: \", d1,d1.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "#visualise\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e1208",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45662a95",
   "metadata": {},
   "source": [
    "CNN can actually warp the labels, Obelisk has some problems. Let's see if they can learn a teacher output in Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d0a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
