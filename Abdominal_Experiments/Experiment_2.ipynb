{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a039e0",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "In this experiment I will investigate if and how the pddNet (build from a CNN and mean field inference) can learn the output of a teacher and eventually combine two teacher networks for one ensemble which output is to be learned by the student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc0c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import misc\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import medpy\n",
    "from medpy.io import load\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.load_models import load_flownet2, load_pwcnet, init_weights\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp, warpImage #, correlation_layer, meanfield\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "\n",
    "\n",
    "from models.pdd_net.pdd_student import OBELISK2d, deeds2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f1db29",
   "metadata": {},
   "source": [
    "# Data\n",
    "Load data and split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d74d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.load('Data/img.pth')\n",
    "segs = torch.load('Data/seg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0cfd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a training split \n",
    "torch.manual_seed(10)\n",
    "# Now, we prepare our train & test dataset.\n",
    "test_set = torch.LongTensor([35, 41, 0, 4, 39])\n",
    "train_set = torch.arange(43)\n",
    "for idx in test_set:\n",
    "    train_set = train_set[train_set != idx]\n",
    "print(\"Train: \", train_set)\n",
    "print(\"Test: \", test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04451ef2",
   "metadata": {},
   "source": [
    "## FlowNet2 as teacher network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce930e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow2 = load_flownet2().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4ff55",
   "metadata": {},
   "source": [
    "## Student creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_hw = 5\n",
    "displace_range = 11\n",
    "\n",
    "o_m = H//4\n",
    "o_n = W//4\n",
    "ogrid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,o_m,o_n)).view(1,1,-1,2).cuda()\n",
    "disp_range = 0.25\n",
    "displacement_width = 15    \n",
    "shift_xy = F.affine_grid(disp_range*torch.eye(2,3).unsqueeze(0),(1,1,displacement_width,displacement_width)).view(1,1,-1,2).cuda()\n",
    "grid_size = 32#25#30\n",
    "grid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,grid_size,grid_size)).view(1,-1,1,2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_normal(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant(m.bias, 0.0)\n",
    "\n",
    "class OBELISK2d(nn.Module):\n",
    "    def __init__(self, chan = 16):\n",
    "\n",
    "        super(OBELISK2d, self).__init__()\n",
    "        channels = chan\n",
    "        self.offsets = nn.Parameter(torch.randn(2,channels *2,2) *0.05)\n",
    "        self.layer0 = nn.Conv2d(1, 4, 5, stride=2, bias=False, padding=2)\n",
    "        self.batch0 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.layer1 = nn.Conv2d(channels *8, channels *4, 1, bias=False, groups=1)\n",
    "        self.batch1 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer2 = nn.Conv2d(channels *4, channels *4, 3, bias=False, padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer3 = nn.Conv2d(channels *4, channels *1, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_img):\n",
    "        img_in = F.avg_pool2d(input_img ,3 ,padding=1 ,stride=2)\n",
    "        img_in = F.relu(self.batch0(self.layer0(img_in)))\n",
    "        sampled = F.grid_sample(img_in ,ogrid_xy + self.offsets[0 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "        sampled -= F.grid_sample(img_in ,ogrid_xy + self.offsets[1 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "\n",
    "        x = F.relu(self.batch1(self.layer1(sampled)))\n",
    "        x = F.relu(self.batch2(self.layer2(x)))\n",
    "        features = self.layer3(x)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca07962",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.nn.Sequential(torch.nn.Conv2d(1,32,kernel_size=5,stride=2,padding=4,dilation=2),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(64),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(64,24,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "                          torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_convolution(ssd_distance, displace_range, H, W):\n",
    "    # Prepare operators for smooth dense displacement space\n",
    "    pad1 = nn.ReplicationPad2d(5)\n",
    "    avg1 = nn.AvgPool2d(5,stride=1)\n",
    "    max1 = nn.MaxPool2d(3,stride=1)\n",
    "    pad2 = nn.ReplicationPad2d(6)\n",
    "    # approximate min convolution / displacement compatibility\n",
    "\n",
    "    ssd_minconv = avg1(avg1(-max1(-pad1(ssd_distance.permute(0,2,3,1).reshape(1,-1,displace_range,displace_range)))))\n",
    "\n",
    "    ssd_minconv = ssd_minconv.permute(0,2,3,1).view(1,-1,H,W)\n",
    "    min_conv_cost = avg1(avg1(avg1(pad2(ssd_minconv))))\n",
    "    \n",
    "    return min_conv_cost\n",
    "\n",
    "def meanfield(ssd_distance,img_fixed,displace_range,H,W):\n",
    "\n",
    "    crnt_dev = ssd_distance.device\n",
    "\n",
    "\n",
    "    cost = min_convolution(ssd_distance, displace_range, H, W)\n",
    "\n",
    "    soft_cost = F.softmax(-10*cost.view(displace_range**2,-1).t(),1)\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    disp_mesh_grid = disp_hw*F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,displace_range,displace_range),align_corners=True)\n",
    "    disp_mesh_grid /= torch.Tensor([(W-1)*.5,(H-1)*.5])\n",
    "\n",
    "    disp_xy = torch.sum(soft_cost.view(1,H,W,-1,1)*disp_mesh_grid.view(1,1,1,-1,2).to(crnt_dev),3).permute(0,3,1,2) \n",
    "    \n",
    "\n",
    "    return soft_cost,disp_xy\n",
    "\n",
    "def correlation_layer(displace_range, feat_moving, feat_fixed):\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    feat_moving_unfold = F.unfold(feat_moving.transpose(1,0),(displace_range,displace_range),padding=disp_hw)\n",
    "    B,C,H,W = feat_fixed.size()\n",
    "    \n",
    "    ssd_distance = ((feat_moving_unfold-feat_fixed.view(C,1,-1))**2).sum(0).view(1,displace_range**2,H,W)\n",
    "\n",
    "    return ssd_distance#.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8c1e0",
   "metadata": {},
   "source": [
    "# 2.1 Using Teacher Flow as loss\n",
    "Trained for 1000 epochs without any label help, as we want to simulate semi-supervised learning. Using MSE as loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081dee2f",
   "metadata": {},
   "source": [
    "## Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd069aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "seq = torch.nn.Sequential(torch.nn.Conv2d(1,32,kernel_size=5,stride=2,padding=4,dilation=2),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(64),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(64,24,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "                          torch.nn.Sigmoid())\n",
    "seq.cuda().train()\n",
    "optimizer = torch.optim.Adam(list(seq.parameters()),lr=0.00025)\n",
    "grad_accum=4\n",
    "loss_fnc = torch.nn.KLDivLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    # get the teacher output\n",
    "    flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "    teacher_flow = flow2(flow_in)\n",
    "    teacher_flow = F.interpolate(teacher_flow, size=(H//4,W//4), mode='bilinear')\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = seq(fixed.cuda())\n",
    "    feat50 = seq(moving.cuda())\n",
    "\n",
    "    ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "    #pdd_flow_pred = F.interpolate(disp_xy, scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    loss = torch.sum(torch.pow(disp_xy - teacher_flow, 2))\n",
    "    #loss = loss_fnc(pdd_flow_pred,teacher_flow)\n",
    "    loss.backward()\n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96efd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "teacher_flow = flow2(flow_in)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = seq(fixed.cuda())\n",
    "    moving_feat = seq(moving.cuda())\n",
    "\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "#warped_student_seg = warp(moving_seg.unsqueeze(0).float().cuda(), dense_flow_fit.squeeze().cuda()).cpu()\n",
    "#warped_teacher_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+teacher_flow.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "warped_teacher_seg = warp(moving_seg.unsqueeze(0).float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),9)\n",
    "print(\"CNN-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg,warped_teacher_seg.squeeze(),9)\n",
    "print(\"Teacher: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_student_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9382c1a9",
   "metadata": {},
   "source": [
    "## Obelisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a33439",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(list(seq.parameters()),lr=0.00025)\n",
    "obel = OBELISK2d(24)\n",
    "init_weights(obel)\n",
    "obel.cuda().train()\n",
    "grad_accum=4\n",
    "loss_fnc = torch.nn.KLDivLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    # get the teacher output\n",
    "    flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "    teacher_flow = flow2(flow_in)\n",
    "    teacher_flow = F.interpolate(teacher_flow, size=(H//4,W//4), mode='bilinear')\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = obel(fixed.cuda())\n",
    "    feat50 = obel(moving.cuda())\n",
    "\n",
    "    ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "    \n",
    "    loss = torch.sum(torch.pow(disp_xy - teacher_flow, 2))\n",
    "    #loss = loss_fnc(pdd_flow_pred,teacher_flow)\n",
    "    loss.backward()\n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "teacher_flow = flow2(flow_in)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = obel(fixed.cuda())\n",
    "    moving_feat = obel(moving.cuda())\n",
    "\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "#warped_student_seg = warp(moving_seg.unsqueeze(0).float().cuda(), dense_flow_fit.squeeze().cuda()).cpu()\n",
    "#warped_teacher_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+teacher_flow.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "warped_teacher_seg = warp(moving_seg.unsqueeze(0).float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),9)\n",
    "print(\"PDD-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg,warped_teacher_seg.squeeze(),9)\n",
    "print(\"Teacher: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_student_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e9c08",
   "metadata": {},
   "source": [
    "# 2.2 Training with displacement and teacher flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f120a1",
   "metadata": {},
   "source": [
    "## Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ea83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.nn.Sequential(torch.nn.Conv2d(1,32,kernel_size=5,stride=2,padding=4,dilation=2),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(64),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(64,24,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "                          torch.nn.Sigmoid())\n",
    "\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(list(seq.parameters()),lr=0.00025)\n",
    "seq.cuda().train()\n",
    "grad_accum=4\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    # Label onehot and scale to outputsize \n",
    "    label_moving = F.one_hot(moving_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    _,C1,Hf,Wf = label_moving.size()\n",
    "    label_moving = F.interpolate(label_moving,size=(H//4,Wf//4),mode='bilinear')\n",
    "    label_fixed = F.one_hot(fixed_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    label_fixed = F.interpolate(label_fixed,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "    # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "    # according to the corresponding discrete displacement pair\n",
    "    label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,9,displace_range**2,-1)\n",
    "    \n",
    "    # get the teacher output\n",
    "    flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "    teacher_flow = flow2(flow_in)\n",
    "    teacher_flow = F.interpolate(teacher_flow, size=(H//4,W//4), mode='bilinear')\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = seq(fixed.cuda())\n",
    "    feat50 = seq(moving.cuda())\n",
    "\n",
    "    ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "    #pdd_flow_pred = F.interpolate(disp_xy, scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    loss = torch.sum(torch.pow(disp_xy - teacher_flow, 2))\n",
    "    \n",
    "    label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "    # compute the loss as sum of squared differences between the fixed label representation and the \"warped\" labels\n",
    "    label_distance1 = torch.sum(torch.pow(label_fixed.reshape(9,-1)-label_warped.reshape(9,-1),2),0)\n",
    "    \n",
    "    loss += label_distance1.mean()\n",
    "    \n",
    "    loss.backward()\n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfbe657",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "teacher_flow = flow2(flow_in)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = seq(fixed.cuda())\n",
    "    moving_feat = seq(moving.cuda())\n",
    "\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "#warped_student_seg = warp(moving_seg.unsqueeze(0).float().cuda(), dense_flow_fit.squeeze().cuda()).cpu()\n",
    "\n",
    "#warped_teacher_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+teacher_flow.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "warped_teacher_seg = warp(moving_seg.unsqueeze(0).float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "#warped_teacher_seg = warpImage(moving_seg.unsqueeze(0).float().cuda(), teacher_flow.cuda()).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),9)\n",
    "print(\"PDD-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg,warped_teacher_seg.squeeze(),9)\n",
    "print(\"Teacher: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_student_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7fcb21",
   "metadata": {},
   "source": [
    "## Obelisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da87487",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel = OBELISK2d(24)\n",
    "init_weights(obel)\n",
    "obel.cuda().train()\n",
    "\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(list(obel.parameters()),lr=0.00025)\n",
    "\n",
    "grad_accum=4\n",
    "loss_fnc = torch.nn.KLDivLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    # Label onehot and scale to outputsize \n",
    "    label_moving = F.one_hot(moving_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    _,C1,Hf,Wf = label_moving.size()\n",
    "    label_moving = F.interpolate(label_moving,size=(H//4,Wf//4),mode='bilinear')\n",
    "    label_fixed = F.one_hot(fixed_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    label_fixed = F.interpolate(label_fixed,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "    # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "    # according to the corresponding discrete displacement pair\n",
    "    label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,9,displace_range**2,-1)\n",
    "    \n",
    "    # get the teacher output\n",
    "    flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "    teacher_flow = flow2(flow_in)\n",
    "    teacher_flow = F.interpolate(teacher_flow, size=(H//4,W//4), mode='bilinear')\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = obel(fixed.cuda())\n",
    "    feat50 = obel(moving.cuda())\n",
    "\n",
    "    ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "    #pdd_flow_pred = F.interpolate(disp_xy, scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    loss = torch.sum(torch.pow(disp_xy - teacher_flow, 2))\n",
    "    \n",
    "    label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "    # compute the loss as sum of squared differences between the fixed label representation and the \"warped\" labels\n",
    "    label_distance1 = torch.sum(torch.pow(label_fixed.reshape(9,-1)-label_warped.reshape(9,-1),2),0)\n",
    "    \n",
    "    loss += label_distance1.mean()\n",
    "    \n",
    "    loss.backward()\n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "teacher_flow = flow2(flow_in)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = obel(fixed.cuda())\n",
    "    moving_feat = obel(moving.cuda())\n",
    "\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "#warped_student_seg = warp(moving_seg.unsqueeze(0).float().cuda(), dense_flow_fit.squeeze().cuda()).cpu()\n",
    "\n",
    "#warped_teacher_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+teacher_flow.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "warped_teacher_seg = warp(moving_seg.unsqueeze(0).float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "#warped_teacher_seg = warpImage(moving_seg.unsqueeze(0).float().cuda(), teacher_flow.cuda()).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),9)\n",
    "print(\"PDD-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg,warped_teacher_seg.squeeze(),9)\n",
    "print(\"Teacher: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_student_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dc17e",
   "metadata": {},
   "source": [
    "# 2.3 using KL loss between warped labels \n",
    "without self wapring loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ceea3",
   "metadata": {},
   "source": [
    "## Obelisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel = OBELISK2d(24)\n",
    "init_weights(obel)\n",
    "obel.cuda().train()\n",
    "\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(list(obel.parameters()),lr=0.00025)\n",
    "\n",
    "grad_accum=4\n",
    "loss_fnc = torch.nn.KLDivLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    # Label onehot and scale to outputsize \n",
    "    label_moving_onehot = F.one_hot(moving_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    _,C1,Hf,Wf = label_moving_onehot.size()\n",
    "    label_moving = F.interpolate(label_moving_onehot,size=(H//4,Wf//4),mode='bilinear')\n",
    "    label_fixed = F.one_hot(fixed_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    label_fixed = F.interpolate(label_fixed,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "    # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "    # according to the corresponding discrete displacement pair\n",
    "    label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,9,displace_range**2,-1)\n",
    "    \n",
    "    # get the teacher output\n",
    "    flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "    teacher_flow = flow2(flow_in)\n",
    "    warped_teacher_seg = warp(label_moving_onehot.float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = obel(fixed.cuda())\n",
    "    feat50 = obel(moving.cuda())\n",
    "\n",
    "    ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "    pdd_flow_pred = F.interpolate(disp_xy, scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    #loss = torch.sum(torch.pow(pdd_flow_pred - teacher_flow, 2))\n",
    "    \n",
    "    label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "    # compute the loss as sum of squared differences between the fixed label representation and the \"warped\" labels\n",
    "    #label_distance1 = torch.sum(torch.pow(label_fixed.reshape(9,-1)-label_warped.reshape(9,-1),2),0)\n",
    "    \n",
    "    #loss += label_distance1.mean()\n",
    "    student_label = F.interpolate(label_warped.view(1,9,H//4,W//4), scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    loss = -loss_fnc(warped_teacher_seg,student_label)\n",
    "    \n",
    "    loss.backward()\n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "teacher_flow = flow2(flow_in)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = obel(fixed.cuda())\n",
    "    moving_feat = obel(moving.cuda())\n",
    "\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "#warped_student_seg = warp(moving_seg.unsqueeze(0).float().cuda(), dense_flow_fit.squeeze().cuda()).cpu()\n",
    "\n",
    "#warped_teacher_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+teacher_flow.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "warped_teacher_seg = warp(moving_seg.unsqueeze(0).float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "#warped_teacher_seg = warpImage(moving_seg.unsqueeze(0).float().cuda(), teacher_flow.cuda()).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),9)\n",
    "print(\"PDD-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg,warped_teacher_seg.squeeze(),9)\n",
    "print(\"Teacher: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_student_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca8f69",
   "metadata": {},
   "source": [
    "### Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.nn.Sequential(torch.nn.Conv2d(1,32,kernel_size=5,stride=2,padding=4,dilation=2),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(64),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(64,24,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "                          torch.nn.Sigmoid())\n",
    "seq.cuda().train()\n",
    "\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(list(obel.parameters()),lr=0.00025)\n",
    "\n",
    "grad_accum=4\n",
    "loss_fnc = torch.nn.KLDivLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    # Label onehot and scale to outputsize \n",
    "    label_moving_onehot = F.one_hot(moving_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    _,C1,Hf,Wf = label_moving_onehot.size()\n",
    "    label_moving = F.interpolate(label_moving_onehot,size=(H//4,Wf//4),mode='bilinear')\n",
    "    label_fixed = F.one_hot(fixed_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    label_fixed = F.interpolate(label_fixed,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "    # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "    # according to the corresponding discrete displacement pair\n",
    "    label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,9,displace_range**2,-1)\n",
    "    \n",
    "    # get the teacher output\n",
    "    flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "    teacher_flow = flow2(flow_in)\n",
    "    warped_teacher_seg = warp(label_moving_onehot.float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = seq(fixed.cuda())\n",
    "    feat50 = seq(moving.cuda())\n",
    "\n",
    "    ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "    pdd_flow_pred = F.interpolate(disp_xy, scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    #loss = torch.sum(torch.pow(pdd_flow_pred - teacher_flow, 2))\n",
    "    \n",
    "    label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "    # compute the loss as sum of squared differences between the fixed label representation and the \"warped\" labels\n",
    "    #label_distance1 = torch.sum(torch.pow(label_fixed.reshape(9,-1)-label_warped.reshape(9,-1),2),0)\n",
    "    \n",
    "    #loss += label_distance1.mean()\n",
    "    student_label = F.interpolate(label_warped.view(1,9,H//4,W//4), scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    loss = -loss_fnc(warped_teacher_seg,student_label)\n",
    "    \n",
    "    loss.backward()\n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6936d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "teacher_flow = flow2(flow_in)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = seq(fixed.cuda())\n",
    "    moving_feat = seq(moving.cuda())\n",
    "\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "#warped_student_seg = warp(moving_seg.unsqueeze(0).float().cuda(), dense_flow_fit.squeeze().cuda()).cpu()\n",
    "\n",
    "#warped_teacher_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+teacher_flow.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "warped_teacher_seg = warp(moving_seg.unsqueeze(0).float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "#warped_teacher_seg = warpImage(moving_seg.unsqueeze(0).float().cuda(), teacher_flow.cuda()).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),9)\n",
    "print(\"CNN-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg,warped_teacher_seg.squeeze(),9)\n",
    "print(\"Teacher: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_student_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9c6b6d",
   "metadata": {},
   "source": [
    "# 2.4 Combine KL-loss and warping loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da68887",
   "metadata": {},
   "source": [
    "## Obelisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel = OBELISK2d(24)\n",
    "init_weights(obel)\n",
    "obel.cuda().train()\n",
    "\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(list(obel.parameters()),lr=0.00025)\n",
    "\n",
    "grad_accum=4\n",
    "loss_fnc = torch.nn.KLDivLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    # Label onehot and scale to outputsize \n",
    "    label_moving_onehot = F.one_hot(moving_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    _,C1,Hf,Wf = label_moving_onehot.size()\n",
    "    label_moving = F.interpolate(label_moving_onehot,size=(H//4,Wf//4),mode='bilinear')\n",
    "    label_fixed = F.one_hot(fixed_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    label_fixed = F.interpolate(label_fixed,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "    # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "    # according to the corresponding discrete displacement pair\n",
    "    label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,9,displace_range**2,-1)\n",
    "    \n",
    "    # get the teacher output\n",
    "    flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "    teacher_flow = flow2(flow_in)\n",
    "    warped_teacher_seg = warp(label_moving_onehot.float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = obel(fixed.cuda())\n",
    "    feat50 = obel(moving.cuda())\n",
    "\n",
    "    ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "    pdd_flow_pred = F.interpolate(disp_xy, scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    #loss = torch.sum(torch.pow(pdd_flow_pred - teacher_flow, 2))\n",
    "    \n",
    "    label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "    # compute the loss as sum of squared differences between the fixed label representation and the \"warped\" labels\n",
    "    label_distance1 = torch.sum(torch.pow(label_fixed.reshape(9,-1)-label_warped.reshape(9,-1),2),0)\n",
    "    \n",
    "    student_label = F.interpolate(label_warped.view(1,9,H//4,W//4), scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    loss = -loss_fnc(warped_teacher_seg,student_label) + label_distance1.mean()    \n",
    "    loss.backward()\n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "teacher_flow = flow2(flow_in)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = obel(fixed.cuda())\n",
    "    moving_feat = obel(moving.cuda())\n",
    "\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "#warped_student_seg = warp(moving_seg.unsqueeze(0).float().cuda(), dense_flow_fit.squeeze().cuda()).cpu()\n",
    "\n",
    "#warped_teacher_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+teacher_flow.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "warped_teacher_seg = warp(moving_seg.unsqueeze(0).float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "#warped_teacher_seg = warpImage(moving_seg.unsqueeze(0).float().cuda(), teacher_flow.cuda()).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),9)\n",
    "print(\"PDD-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg,warped_teacher_seg.squeeze(),9)\n",
    "print(\"Teacher: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_student_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88449f6",
   "metadata": {},
   "source": [
    "## Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76673cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.nn.Sequential(torch.nn.Conv2d(1,32,kernel_size=5,stride=2,padding=4,dilation=2),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(64),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(64,24,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "                          torch.nn.Sigmoid())\n",
    "seq.cuda().train()\n",
    "\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(list(obel.parameters()),lr=0.00025)\n",
    "\n",
    "grad_accum=4\n",
    "loss_fnc = torch.nn.KLDivLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     # get training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    p_fix = train_set[rnd_train_idx[0]]\n",
    "    p_mov = train_set[rnd_train_idx[1]]\n",
    "\n",
    "    fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "    moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "    \n",
    "    fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "    moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "    \n",
    "    # Label onehot and scale to outputsize \n",
    "    label_moving_onehot = F.one_hot(moving_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    _,C1,Hf,Wf = label_moving_onehot.size()\n",
    "    label_moving = F.interpolate(label_moving_onehot,size=(H//4,Wf//4),mode='bilinear')\n",
    "    label_fixed = F.one_hot(fixed_seg,num_classes=9).permute(0,3,1,2).float()\n",
    "    label_fixed = F.interpolate(label_fixed,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "    # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "    # according to the corresponding discrete displacement pair\n",
    "    label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,9,displace_range**2,-1)\n",
    "    \n",
    "    # get the teacher output\n",
    "    flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "    teacher_flow = flow2(flow_in)\n",
    "    warped_teacher_seg = warp(label_moving_onehot.float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "    \n",
    "    fixed = Variable(fixed, requires_grad=True)           #fixed\n",
    "    moving = Variable(moving, requires_grad=True)         #moving\n",
    "    \n",
    "    feat00 = seq(fixed.cuda())\n",
    "    feat50 = seq(moving.cuda())\n",
    "\n",
    "    ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "    \n",
    "    # compute the MIN-convolution & probabilistic output with the given function\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "    pdd_flow_pred = F.interpolate(disp_xy, scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    #loss = torch.sum(torch.pow(pdd_flow_pred - teacher_flow, 2))\n",
    "    \n",
    "    label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "    # compute the loss as sum of squared differences between the fixed label representation and the \"warped\" labels\n",
    "    label_distance1 = torch.sum(torch.pow(label_fixed.reshape(9,-1)-label_warped.reshape(9,-1),2),0)\n",
    "    \n",
    "    student_label = F.interpolate(label_warped.view(1,9,H//4,W//4), scale_factor=4, mode='bicubic')\n",
    "    \n",
    "    loss = -loss_fnc(warped_teacher_seg,student_label) + label_distance1.mean()    \n",
    "    loss.backward()\n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations : backpropagate the accumulated gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb87295",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.eval()\n",
    "\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "p_mov = test_set[rnd_test_idx[1]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,:,:].unsqueeze(1).float() / 255\n",
    "moving = imgs[p_mov:p_mov+1,:,:].unsqueeze(1).float() / 255\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,:,:].long().contiguous()\n",
    "moving_seg = segs[p_mov:p_mov+1,:,:].long().contiguous()\n",
    "\n",
    "flow_in = preprocessing_flownet(fixed.reshape(H,W,1),moving.reshape(H,W,1)).cuda()\n",
    "teacher_flow = flow2(flow_in)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = seq(fixed.cuda())\n",
    "    moving_feat = seq(moving.cuda())\n",
    "\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,scale_factor=4,mode='bicubic')\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "#warped_student_seg = warp(moving_seg.unsqueeze(0).float().cuda(), dense_flow_fit.squeeze().cuda()).cpu()\n",
    "\n",
    "#warped_teacher_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+teacher_flow.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "warped_teacher_seg = warp(moving_seg.unsqueeze(0).float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "#warped_teacher_seg = warpImage(moving_seg.unsqueeze(0).float().cuda(), teacher_flow.cuda()).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),9)\n",
    "print(\"CNN-Student: \", d1,d1.mean())\n",
    "d2 = dice_coeff(fixed_seg,warped_teacher_seg.squeeze(),9)\n",
    "print(\"Teacher: \", d2, d2.mean())\n",
    "d3 = dice_coeff(fixed_seg,moving_seg,9)\n",
    "print(\"diff fixed, moving: \", d3, d3.mean())\n",
    "\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "rgb = overlaySegment(fixed.squeeze().t().flip(0),warped_student_seg.data.squeeze().t().flip(0),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b512d4",
   "metadata": {},
   "source": [
    "# Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a852c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
