{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc84dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "#sys.path.insert(1, './PWC-Net/PyTorch/')\n",
    "\n",
    "from models.pwc_net.models.PWCNet import PWCDCNet\n",
    "from utils.plotting import *\n",
    "from models.flownet2.utils.flow_utils import *\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59809841",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PWCDCNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b994190",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"models/pwc_net/pwc_net_chairs.pth.tar\")\n",
    "\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.load('/home/till/uni/masterArbeit/Tests/img.pth')\n",
    "seg = torch.load('/home/till/uni/masterArbeit/Tests/seg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaebd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = 12 ; mov = 9\n",
    "\n",
    "img_fixed = img[fix:fix + 1, :, :].float() / 255\n",
    "img_moving = img[mov:mov + 1, :, :].float() / 255\n",
    "H, W = img_fixed.shape[-2:]\n",
    "\n",
    "divisor = 64\n",
    "H_ = int(ceil(H/divisor) * divisor)\n",
    "W_ = int(ceil(W/divisor) * divisor)\n",
    "\n",
    "img_fixed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143537d",
   "metadata": {},
   "source": [
    "PWCNet expects RGB input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fixed_rgb = cv.cvtColor(img_fixed.reshape(H_,W_).numpy(), cv.COLOR_GRAY2RGB)\n",
    "img_moving_rgb = cv.cvtColor(img_moving.reshape(H_,W_).numpy(), cv.COLOR_GRAY2RGB)\n",
    "plt.imshow(img_fixed_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16dc4fc",
   "metadata": {},
   "source": [
    "Preprocessing to get the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ee748",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = img_fixed_rgb[:, :, ::-1].transpose(2,0,1)\n",
    "img_2 = img_moving_rgb[:, :, ::-1].transpose(2,0,1)\n",
    "img_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.from_numpy(np.asarray([img_1,img_2])) #np.asarray([img_fixed_rgb, img_moving_rgb])\n",
    "for i, im in enumerate(images):\n",
    "    \n",
    "    images[i] = images[i].expand(1,images[i].shape[0],images[i].shape[1],images[i].shape[2])\n",
    "    print(images[i].expand(1,images[i].shape[0],images[i].shape[1],images[i].shape[2]).shape)\n",
    "    \n",
    "images.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c8ccd",
   "metadata": {},
   "source": [
    "Somehow, the net expects two images, that are next to each other channel wise, to process them. \n",
    "\n",
    "So an array of [Batchsize, 2* channel, H, W] Wheren Batchsize is 1 and every image has 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cuda()\n",
    "flo = net(images.resize(1,6,H,W).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5030f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flo[0].shape)\n",
    "print(flo[1].shape)\n",
    "flo = flo[0]\n",
    "flo = flo.cpu().data.numpy()\n",
    "flo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flo = np.swapaxes(np.swapaxes(flo, 0, 1), 1, 2)#print(flo.shape)\n",
    "flo = np.swapaxes(flo, 0, 1)\n",
    "flo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ = cv.resize(flo[0,:,:,0],(W,H))\n",
    "v_ = cv.resize(flo[1,:,:,1],(W,H))\n",
    "u_ *= W\n",
    "v_ *= H\n",
    "flo = np.dstack((u_,v_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeeb3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "floIm = flow2img(flo)\n",
    "floIm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(floIm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba0394",
   "metadata": {},
   "source": [
    "## This result above does not look promissing. Let us try the two images, that are available in the repo and try to reproduce the flow file, that was also delivered with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = cv.imread(\"PWC-Net/PyTorch/data/frame_0010.png\")\n",
    "im1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_all = [cv.imread(\"PWC-Net/PyTorch/data/frame_0010.png\"),cv.imread(\"PWC-Net/PyTorch/data/frame_0011.png\")]\n",
    "im_all = [im[:, :, :3] for im in im_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisor = 64.\n",
    "H = im_all[0].shape[0]\n",
    "W = im_all[0].shape[1]\n",
    "\n",
    "H_ = int(ceil(H/divisor) * divisor)\n",
    "W_ = int(ceil(W/divisor) * divisor)\n",
    "for i in range(len(im_all)):\n",
    "\tim_all[i] = cv.resize(im_all[i], (W_, H_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _i, _inputs in enumerate(im_all):\n",
    "\tim_all[_i] = im_all[_i][:, :, ::-1]\n",
    "\tim_all[_i] = 1.0 * im_all[_i]/255.0\n",
    "\t\n",
    "\tim_all[_i] = np.transpose(im_all[_i], (2, 0, 1))\n",
    "\tim_all[_i] = torch.from_numpy(im_all[_i])\n",
    "\tim_all[_i] = im_all[_i].expand(1, im_all[_i].size()[0], im_all[_i].size()[1], im_all[_i].size()[2])\t\n",
    "\tim_all[_i] = im_all[_i].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#im_all = torch.autograd.Variable(torch.cat(im_all,1).cuda())\n",
    "im_all = torch.cat(im_all,1).cuda()\n",
    "print(im_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e036b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()\n",
    "net.eval()\n",
    "\n",
    "flo = net(im_all)\n",
    "print(\"Output: \", flo.shape)\n",
    "flo = flo[0] * 20.0\n",
    "flo = flo.cpu().data.numpy()\n",
    "print(\"First entry to numpy: \", flo.shape)\n",
    "# scale the flow back to the input size \n",
    "flo = np.swapaxes(np.swapaxes(flo, 0, 1), 1, 2) # \n",
    "u_ = cv.resize(flo[:,:,0],(W,H))\n",
    "v_ = cv.resize(flo[:,:,1],(W,H))\n",
    "u_ *= W/ float(W_)\n",
    "v_ *= H/ float(H_)\n",
    "flo = np.dstack((u_,v_))\n",
    "print(\"Stacked: \", flo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f3edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_rec = flow2img(flo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flow_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_original = readFlow(\"PWC-Net/PyTorch/tmp/reference_frame_0010.flo\")\n",
    "flow_im_orig = flow2img(flow_original)\n",
    "plt.imshow(flow_im_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955204a",
   "metadata": {},
   "source": [
    "## So that seemed to work. However, with the medical data it does not. \n",
    "Ideas why it does not work, include:\n",
    "- openCV function to convert gray to rgb. Maybe a better way to create a suitable image is to just double the image in all three channels.\n",
    "- Right sizing. The output of the pngs is not remotely close to the output from the medical data. \n",
    "\n",
    "# Let's explore these options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05214f61",
   "metadata": {},
   "source": [
    "Explore the first option. First, reshape the tensor and convert it to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fixed = img[fix:fix + 1, :, :].float() / 255\n",
    "img_moving = img[mov:mov + 1, :, :].float() / 255\n",
    "\n",
    "divisor = 64\n",
    "H_ = int(ceil(H/divisor) * divisor)\n",
    "W_ = int(ceil(W/divisor) * divisor)\n",
    "\n",
    "C,H,W = img_fixed.shape\n",
    "img_fixed = img_fixed.reshape(H,W,C).numpy()\n",
    "img_moving = img_moving.reshape(H,W,C).numpy()\n",
    "\n",
    "img_fixed = np.concatenate([img_fixed,img_fixed,img_fixed],2) \n",
    "img_moving = np.concatenate([img_moving,img_moving,img_moving],2)\n",
    "img_fixed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [img_fixed, img_moving]\n",
    "for i in range(len(images)):\n",
    "    images[i] = cv.resize(images[i], (W_, H_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73464e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _i, _inputs in enumerate(images):\n",
    "    images[_i] = images[_i][:, :, ::-1]\n",
    "    #images[_i] = 1.0 * images[_i]/255.0\n",
    "    \n",
    "    images[_i] = np.transpose(images[_i], (2, 0, 1))\n",
    "    \n",
    "    # Running into a \"negative number\" error in th line below, need to change that\n",
    "    # The error suggested to use the copy() function as a workaround. \n",
    "    images[_i] = torch.from_numpy(images[_i].copy())\n",
    "    # Worked ¯\\_(ツ)_/¯\n",
    "    \n",
    "    images[_i] = images[_i].expand(1, images[_i].size()[0], images[_i].size()[1], images[_i].size()[2])\t\n",
    "    images[_i] = images[_i].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f65e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.cat(images,1).cuda()\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d184f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()\n",
    "net.eval()\n",
    "\n",
    "flo = net(images)\n",
    "flo = flo[0] * 20.0\n",
    "flo = flo.cpu().data.numpy()\n",
    "\n",
    "# scale the flow back to the input size \n",
    "flo = np.swapaxes(np.swapaxes(flo, 0, 1), 1, 2) # \n",
    "u_ = cv.resize(flo[:,:,0],(W,H))\n",
    "v_ = cv.resize(flo[:,:,1],(W,H))\n",
    "u_ *= W/ float(W_)\n",
    "v_ *= H/ float(H_)\n",
    "flo = np.dstack((u_,v_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_new = flow2img(flo)\n",
    "plt.imshow(flow_new)\n",
    "plt.imsave(\"PWC-FlowVis.png\", flow_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab23eb",
   "metadata": {},
   "source": [
    "## WAY Better!!\n",
    "Shape is different, and also the RGB channels were changed to onyl be concatenated gray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0672df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
