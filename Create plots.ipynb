{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6d573a",
   "metadata": {},
   "source": [
    "# Notebook used to create plots for the MA\n",
    "In this notebook we create some plots that were used in the Thesis for showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.animation as animation\n",
    "from PIL import Image\n",
    "import datetime\n",
    "from utils.plotting import showFlow, overlaySegment\n",
    "from utils.encoding import dice_coeff, hausdorff_dist\n",
    "from utils.load_models import load_flownet2, load_pwcnet\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.layers import warp\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Select a GPU for the work\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "available_gpus = [(torch.cuda.device(i),torch.cuda.get_device_name(i)) for i in range(torch.cuda.device_count())]\n",
    "print(available_gpus)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9834f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_hw = 5\n",
    "displace_range = 11\n",
    "class OBELISK2d(nn.Module):\n",
    "    def __init__(self, chan=16, size=(150,150)):\n",
    "        super(OBELISK2d, self).__init__()\n",
    "        channels = chan\n",
    "        self.offsets = nn.Parameter(torch.randn(2, channels * 2, 2) * 0.05)\n",
    "        self.layer0 = nn.Conv2d(1, 4, 5, stride=2, bias=False, padding=2)\n",
    "        self.batch0 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.layer1 = nn.Conv2d(channels * 8, channels * 4, 1, bias=False,\n",
    "                                groups=1)\n",
    "        self.batch1 = nn.BatchNorm2d(channels * 4)\n",
    "        self.layer2 = nn.Conv2d(channels * 4, channels * 4, 3, bias=False,\n",
    "                                padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(channels * 4)\n",
    "        self.layer3 = nn.Conv2d(channels * 4, channels * 1, 1)\n",
    "\n",
    "        H = size[0]\n",
    "        W = size[1]\n",
    "        self.o_m = H // 4 +1\n",
    "        self.o_n = W // 4 +1\n",
    "\n",
    "        self.displace_range = 11\n",
    "        self.disp_hw = 5\n",
    "        self.ogrid_xy = F.affine_grid(torch.eye(2, 3).unsqueeze(0),\n",
    "                                 (1, 1, self.o_m, self.o_n)).view(1, 1, -1, 2).cuda()\n",
    "        self.disp_range = 0.25\n",
    "        self.displacement_width = 11\n",
    "        shift_xy = F.affine_grid(self.disp_range * torch.eye(2, 3).unsqueeze(0), (1, 1, self.displacement_width, self.displacement_width)).view(1, 1, -1, 2).cuda()\n",
    "        grid_size = 32  # 25#30\n",
    "        self.grid_xy = F.affine_grid(torch.eye(2, 3).unsqueeze(0),\n",
    "                                (1, 1, grid_size, grid_size)).view(1, -1, 1,\n",
    "                                                                   2).cuda()\n",
    "\n",
    "    def forward(self, fixed_img, moving_img):\n",
    "        img_in_f = F.avg_pool2d(fixed_img, 3, padding=1, stride=2)\n",
    "        img_in_f = F.relu(self.batch0(self.layer0(img_in_f)))\n",
    "        sampled_f = F.grid_sample(img_in_f,self.ogrid_xy + self.offsets[0, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "        sampled_f -= F.grid_sample(img_in_f,self.ogrid_xy + self.offsets[1, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "\n",
    "        x_1 = F.relu(self.batch1(self.layer1(sampled_f)))\n",
    "        x_1 = F.relu(self.batch2(self.layer2(x_1)))\n",
    "        features_fixed = self.layer3(x_1)\n",
    "        \n",
    "        img_in_m = F.avg_pool2d(moving_img, 3, padding=1, stride=2)\n",
    "        img_in_m = F.relu(self.batch0(self.layer0(img_in_m)))\n",
    "        sampled_m = F.grid_sample(img_in_m,self.ogrid_xy + self.offsets[0, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "        sampled_m -= F.grid_sample(img_in_m,self.ogrid_xy + self.offsets[1, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "\n",
    "        x_2 = F.relu(self.batch1(self.layer1(sampled_m)))\n",
    "        x_2 = F.relu(self.batch2(self.layer2(x_2)))\n",
    "        features_moving = self.layer3(x_2)\n",
    "\n",
    "        ssd_distance = self.correlation_layer(features_moving, features_fixed)\n",
    "        soft_cost,disp_xy = self.meanfield(ssd_distance, fixed_img, self.displace_range, self.o_m, self.o_n)\n",
    "        \n",
    "        return soft_cost, disp_xy\n",
    "\n",
    "\n",
    "    def min_convolution(self, ssd_distance, displace_range, H, W):\n",
    "        # Prepare operators for smooth dense displacement space\n",
    "        pad1 = nn.ReplicationPad2d(5)\n",
    "        avg1 = nn.AvgPool2d(5, stride=1)\n",
    "        max1 = nn.MaxPool2d(3, stride=1)\n",
    "        pad2 = nn.ReplicationPad2d(4)\n",
    "        # approximate min convolution / displacement compatibility\n",
    "\n",
    "        ssd_minconv = avg1(avg1(-max1(-pad1(\n",
    "            ssd_distance.permute(0, 2, 3, 1).reshape(1, -1, self.displace_range,\n",
    "                                                    self.displace_range)))))\n",
    "\n",
    "        ssd_minconv = ssd_minconv.permute(0, 2, 3, 1).view(1, -1, H, W)\n",
    "        min_conv_cost = avg1(avg1(pad2(ssd_minconv)))\n",
    "\n",
    "        return min_conv_cost\n",
    "\n",
    "\n",
    "    def meanfield(self, ssd_distance, img_fixed, displace_range, H, W):\n",
    "        crnt_dev = ssd_distance.device\n",
    "\n",
    "        cost = self.min_convolution(ssd_distance, displace_range, H, W)\n",
    "\n",
    "        soft_cost = F.softmax(-10 * cost.view(displace_range ** 2, -1).t(), 1)\n",
    "\n",
    "        disp_hw = (displace_range - 1) // 2\n",
    "        disp_mesh_grid = disp_hw * F.affine_grid(torch.eye(2, 3).unsqueeze(0), (\n",
    "        1, 1, displace_range, displace_range), align_corners=True)\n",
    "        disp_mesh_grid /= torch.Tensor([(W - 1) * .5, (H - 1) * .5])\n",
    "\n",
    "        disp_xy = torch.sum(\n",
    "            soft_cost.view(1, H, W, -1, 1) * disp_mesh_grid.view(1, 1, 1, -1,\n",
    "                                                                2).to(crnt_dev),\n",
    "            3).permute(0, 3, 1, 2)\n",
    "\n",
    "        return soft_cost, disp_xy\n",
    "\n",
    "\n",
    "    def correlation_layer(self, feat_moving, feat_fixed):\n",
    "        disp_hw = (self.displacement_width - 1) // 2\n",
    "        feat_moving_unfold = F.unfold(feat_moving.transpose(1, 0),\n",
    "                                    (self.displace_range, self.displace_range),\n",
    "                                    padding=self.disp_hw)\n",
    "        B, C, H, W = feat_fixed.size()\n",
    "\n",
    "        ssd_distance = ((feat_moving_unfold - feat_fixed.view(C, 1, -1)) ** 2).sum(0).view(1, displace_range ** 2, H, W)\n",
    "\n",
    "        return ssd_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c30baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model\n",
    "path_to_state_dict = \"models/Experiment_2/fineTuneSoft/tuned.pth\"\n",
    "model = OBELISK2d(16)\n",
    "model.load_state_dict(torch.load(path_to_state_dict))\n",
    "model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fae83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and segmentations from a specific ID\n",
    "\n",
    "prob_id = '717'\n",
    "path_to_data = \"/share/data_ultraschall/compressions\"\n",
    "frame_path = os.path.join(path_to_data,str(prob_id),'frames')\n",
    "seg_path = os.path.join(path_to_data,str(prob_id),'segmentations','1')\n",
    "\n",
    "frame_list = []\n",
    "for frame in os.listdir(frame_path):\n",
    "    frame_list.append(os.path.join(frame_path,frame))\n",
    "frame_list.sort()\n",
    "\n",
    "seg_list = []\n",
    "for seg in os.listdir(seg_path):\n",
    "    seg_list.append(os.path.join(seg_path,seg))\n",
    "seg_list.sort()\n",
    "\n",
    "assert len(frame_list) == len(seg_list)\n",
    "frames = torch.zeros([len(frame_list), 150,150])\n",
    "segs = torch.zeros([len(frame_list), 150,150])\n",
    "# read images\n",
    "for i in range(len(frame_list)):\n",
    "    frames[i] = torch.from_numpy(np.array(Image.open(frame_list[i]))) / 255.\n",
    "    segs[i] = torch.from_numpy(np.array(Image.open(seg_list[i]))) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = pd.read_csv('landmarks.csv')\n",
    "start_frame = landmarks[landmarks['Id']== int(prob_id)]['Start Frames'].iat[0]\n",
    "start = int(start_frame.split('[')[1].split(']')[0])\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34011005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set font and size so they are readable in the thesis\n",
    "fonts = {'fontsize': 22,'family': 'Latin Modern Roman'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3cfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = start+50\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,8))\n",
    "ax[0].imshow(overlaySegment(frames[start], segs[start]))\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title(f'Segmented Frame at {start}', fontdict=fonts)\n",
    "ax[1].imshow(overlaySegment(frames[idx], segs[idx]))\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title(f'Segmented frame at {idx}', fontdict=fonts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.imshow(overlaySegment(frames[idx+10], segs[idx+10]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = frames[start]\n",
    "moving= frames[idx]\n",
    "\n",
    "soft, flow = model(moving.unsqueeze(0).unsqueeze(0).cuda(), fixed.unsqueeze(0).unsqueeze(0).cuda())\n",
    "disp_xy = F.interpolate(flow.detach().cpu(), size=(150,150), mode='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198990ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3,figsize=(18,9))\n",
    "axs[0].imshow(overlaySegment(fixed, segs[start]), cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Fixed frame', fontdict=fonts)\n",
    "\n",
    "axs[1].imshow(showFlow(disp_xy))\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Flowfield', fontdict=fonts)\n",
    "\n",
    "axs[2].imshow(overlaySegment(moving, segs[idx]), cmap='gray')\n",
    "axs[2].axis('off')\n",
    "axs[2].set_title('Moving frame', fontdict=fonts)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec68130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
