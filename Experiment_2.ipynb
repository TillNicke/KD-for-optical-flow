{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fe0a71",
   "metadata": {},
   "source": [
    "# Second Experiment\n",
    "In this experiment, we want to investigate, the PDD network can improove the performance, when using a knowledge compression method. The teacher will be the FlowNet2 with pretrained weights, which can be found [here](https://drive.google.com/drive/folders/0B5EC7HMbyk3CbjFPb0RuODI3NmM?resourcekey=0-SuPU4qVZzuB4s83ngjrAEg). \n",
    "\n",
    "As there are multiple different way in applying the loss function, when using knowledge compression, there will be three different loss functions compared here. \n",
    "1) In a standard knowledge compression, the KL divergence is used to approximate the teacher output. We will compare the different warped labels of student and teacher. However, as this is usually done in classificatin, we do not expect it to perform really well in this setting.\n",
    "\n",
    "2) A different approach is to use the MSE between the estimated flow field of the teacher and the estimated flowfield of the student. This does, however, not incorporate the warped label and dice score. The MSE is expressed as: $$L =\\sum_{i,j}(prediction[i,j] - target[i,j])^2 $$ where $[i,j]$ denotes the flowfield at position i,j. \n",
    "\n",
    "3) What is missing in 2) will be used in the last setting. We incorporate the loss of the warped label. This can happen either by simply adding the loss to the loss between the flow fields OR by using a scale factor (probably dice score of the teacher) which indicates how well the teacher performs on this specific example. The loss can then be expressed as follows: $$L_i = \\delta * L_{flowfield} + (1-\\delta) * L_{Label}$$ With $\\delta$ being the dice score between warped teacher segment and fixed segmentation. $L_i$ is the loss ofr the $i_{th}$ example, $L_{flowfield}$ is the crossentropy loss between student and teacher flow estimation and $L_{Label}$ is the warping loss between student warped segmentation and the segmentation to approximate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3c0e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(18000000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 18000 seconds\n",
      "[(<torch.cuda.device object at 0x7fe7609c6520>, 'GeForce RTX 2080 Ti')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "%autosave 18000\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from math import ceil\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.load_models import load_flownet2, load_pwcnet, init_weights\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp, warpImage\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "\n",
    "\n",
    "from models.pdd_net.pdd_student import OBELISK2d\n",
    "\n",
    "# Select a GPU for the work\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "available_gpus = [(torch.cuda.device(i),torch.cuda.get_device_name(i)) for i in range(torch.cuda.device_count())]\n",
    "print(available_gpus)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da91ece",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ea40cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135 train examples\n",
      "60 test examples\n"
     ]
    }
   ],
   "source": [
    "imgs = torch.load('data/train_frames.pth')\n",
    "segs = torch.load('data/train_segs.pth')\n",
    "\n",
    "#define a training split \n",
    "torch.manual_seed(42)\n",
    "# Now, we prepare our train & test dataset.\n",
    "train_set = torch.from_numpy(np.random.choice(np.arange(len(imgs)),size=int(len(imgs)*0.95), replace=False))\n",
    "\n",
    "test_set = torch.arange(len(imgs))\n",
    "for idx in train_set:\n",
    "    test_set = test_set[test_set != idx]\n",
    "\n",
    "\n",
    "print(f\"{train_set.shape[0]} train examples\")\n",
    "print(f\"{test_set.shape[0]} test examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51bb73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seg in enumerate(segs):\n",
    "    f_seg = seg[0]\n",
    "    m_seg = seg[1]\n",
    "    if len(torch.where(torch.histc(f_seg) != 0)[0]) == 3 and f_seg.max() <= 2:\n",
    "        segs[i][0] = segs[i][0]*2 \n",
    "    if len(torch.where(torch.histc(m_seg) != 0)[0]) == 3 and m_seg.max() <= 2:\n",
    "        segs[i][1] = segs[i][1]*2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de5baf",
   "metadata": {},
   "source": [
    "# Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6cdab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "W,H = (150,150)\n",
    "o_m = H//4\n",
    "o_n = W//4\n",
    "ogrid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,o_m,o_n)).view(1,1,-1,2).cuda()\n",
    "disp_range = 0.25#0.25\n",
    "displacement_width = 15#15#11#17\n",
    "shift_xy = F.affine_grid(disp_range*torch.eye(2,3).unsqueeze(0),(1,1,displacement_width,displacement_width)).view(1,1,-1,2).cuda()\n",
    "\n",
    "grid_size = 32#25#30\n",
    "grid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,grid_size,grid_size)).view(1,-1,1,2).cuda()\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_normal(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant(m.bias, 0.0)\n",
    "\n",
    "class OBELISK2d(nn.Module):\n",
    "    def __init__(self, chan = 16):\n",
    "\n",
    "        super(OBELISK2d, self).__init__()\n",
    "        channels = chan\n",
    "        self.offsets = nn.Parameter(torch.randn(2,channels *2,2) *0.05)\n",
    "        self.layer0 = nn.Conv2d(1, 4, 5, stride=2, bias=False, padding=2)\n",
    "        self.batch0 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.layer1 = nn.Conv2d(channels *8, channels *4, 1, bias=False, groups=1)\n",
    "        self.batch1 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer2 = nn.Conv2d(channels *4, channels *4, 3, bias=False, padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer3 = nn.Conv2d(channels *4, channels *1, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_img):\n",
    "        img_in = F.avg_pool2d(input_img ,3 ,padding=1 ,stride=2)\n",
    "        img_in = F.relu(self.batch0(self.layer0(img_in)))\n",
    "        sampled = F.grid_sample(img_in ,ogrid_xy + self.offsets[0 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "        sampled -= F.grid_sample(img_in ,ogrid_xy + self.offsets[1 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "\n",
    "        x = F.relu(self.batch1(self.layer1(sampled)))\n",
    "        x = F.relu(self.batch2(self.layer2(x)))\n",
    "        features = self.layer3(x)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fda4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_convolution(ssd_distance, displace_range, H, W):\n",
    "    # Prepare operators for smooth dense displacement space\n",
    "    pad1 = nn.ReplicationPad2d(5)\n",
    "    avg1 = nn.AvgPool2d(5,stride=1)\n",
    "    max1 = nn.MaxPool2d(3,stride=1)\n",
    "    pad2 = nn.ReplicationPad2d(6)\n",
    "    # approximate min convolution / displacement compatibility\n",
    "\n",
    "    ssd_minconv = avg1(avg1(-max1(-pad1(ssd_distance.permute(0,2,3,1).reshape(1,-1,displace_range,displace_range)))))\n",
    "\n",
    "    ssd_minconv = ssd_minconv.permute(0,2,3,1).view(1,-1,H,W)\n",
    "    min_conv_cost = avg1(avg1(avg1(pad2(ssd_minconv))))\n",
    "    \n",
    "    return min_conv_cost\n",
    "\n",
    "def meanfield(ssd_distance,img_fixed,displace_range,H,W):\n",
    "\n",
    "    crnt_dev = ssd_distance.device\n",
    "\n",
    "    cost = min_convolution(ssd_distance, displace_range, H, W)\n",
    "\n",
    "    soft_cost = F.softmax(-10*cost.view(displace_range**2,-1).t(),1)\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    disp_mesh_grid = disp_hw*F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,displace_range,displace_range),align_corners=True)\n",
    "    disp_mesh_grid /= torch.Tensor([(W-1)*.5,(H-1)*.5])\n",
    "\n",
    "    disp_xy = torch.sum(soft_cost.view(1,H,W,-1,1)*disp_mesh_grid.view(1,1,1,-1,2).to(crnt_dev),3).permute(0,3,1,2) \n",
    "    \n",
    "\n",
    "    return soft_cost,disp_xy\n",
    "\n",
    "def correlation_layer(displace_range, feat_moving, feat_fixed):\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    feat_moving_unfold = F.unfold(feat_moving.transpose(1,0),(displace_range,displace_range),padding=disp_hw)\n",
    "    B,C,H,W = feat_fixed.size()\n",
    "    \n",
    "    ssd_distance = ((feat_moving_unfold-feat_fixed.view(C,1,-1))**2).sum(0).view(1,displace_range**2,H,W)\n",
    "\n",
    "    return ssd_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25314965",
   "metadata": {},
   "source": [
    "# Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf2ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet = load_flownet2().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d88939",
   "metadata": {},
   "source": [
    "# Eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9062436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    overall_dice = []\n",
    "    unwarped_dice = []\n",
    "    \n",
    "    for i,idx in enumerate(test_set):\n",
    "        \n",
    "        fixed = imgs[idx:idx+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[idx:idx+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[idx:idx+1,0,:].contiguous()\n",
    "        moving_seg = segs[idx:idx+1,1,:].contiguous()\n",
    "        \n",
    "        # Some images have no segmentation to them, \n",
    "        # even if it was present in the directory\n",
    "        # We leave these ones out, as they cannot be avaluated\n",
    "        # we need to check the max and min, so we can be sure to get the two labels, if there are some\n",
    "        if len(torch.where(torch.histc(fixed_seg) != 0)[0]) == 3 and fixed_seg.max() <= 2:\n",
    "            fixed_seg = fixed_seg*2\n",
    "        if len(torch.where(torch.histc(moving_seg) != 0)[0]) == 3 and moving_seg.max() <= 2:\n",
    "            moving_seg = moving_seg*2\n",
    "        if fixed_seg.max() < 1:\n",
    "            pass\n",
    "        else:\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                fixed_feat = model(fixed.cuda())\n",
    "                moving_feat = model(moving.cuda())\n",
    "\n",
    "            ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "            #regularise using meanfield inference with approx. min-convolutions\n",
    "            soft_cost_one,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "            #upsample field to original resolution\n",
    "            dense_flow_fit = F.interpolate(disp_xy,size=(H,W),mode='bicubic')\n",
    "\n",
    "\n",
    "            #apply and evaluate transformation\n",
    "            identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "            warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "\n",
    "            d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),3)\n",
    "            d2 = dice_coeff(fixed_seg, moving_seg, 3)\n",
    "            \n",
    "            overall_dice.append(d1.mean())\n",
    "            unwarped_dice.append(d2.mean())\n",
    "    \n",
    "    overall_dice = torch.from_numpy(np.array(overall_dice))\n",
    "    unwarped_dice = torch.from_numpy(np.array(unwarped_dice))\n",
    "    \n",
    "    print(f\"This model has an average Dice of {round(overall_dice.mean().item(), 5)} mit Variance: {round(overall_dice.var().item(), 5)}. The unwarped Mean dice is: {round(unwarped_dice.mean().item(), 5)} with Var {round(unwarped_dice.var().item(),5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af4b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_seg(moving_seg, flow):\n",
    "    \"\"\"\n",
    "    function to warp the segemntation of the teacher and baseline\n",
    "    \n",
    "    moving_seg: CxHxW\n",
    "    flow: size: BxCxHxW\n",
    "    \"\"\"\n",
    "    B, C, H, W = flow.size()\n",
    "    # mesh grid\n",
    "    xx = torch.arange(0, W).view(1, -1).repeat(H, 1)\n",
    "    yy = torch.arange(0, H).view(-1, 1).repeat(1, W)\n",
    "    xx = xx.view(1, 1, H, W).repeat(B, 1, 1, 1)\n",
    "    yy = yy.view(1, 1, H, W).repeat(B, 1, 1, 1)\n",
    "    grid = torch.cat((xx, yy), 1).float().to(flow.device)\n",
    "    \n",
    "    vgrid = grid + flow\n",
    "\n",
    "    # scale grid to [-1,1]\n",
    "    vgrid[:, 0, :, :] = 2.0 * vgrid[:, 0, :, :].clone() / max(W - 1, 1) - 1.0\n",
    "    vgrid[:, 1, :, :] = 2.0 * vgrid[:, 1, :, :].clone() / max(H - 1, 1) - 1.0\n",
    "\n",
    "    vgrid = vgrid.permute(0, 2, 3, 1)\n",
    "    warped_seg_grid = nn.functional.grid_sample(moving_seg.float().unsqueeze(0), vgrid)\n",
    "    return warped_seg_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e4292",
   "metadata": {},
   "source": [
    "# Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fdfa221",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_hw = 5\n",
    "displace_range = 11\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.0002\n",
    "# minibatch training\n",
    "grad_accum = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258e39f",
   "metadata": {},
   "source": [
    "# Experiment 2.1\n",
    "Using KL_divergence between student and teacher warped label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0f2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = OBELISK2d(24)\n",
    "init_weights(student)\n",
    "student.train().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(student.parameters()),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2980fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = torch.nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ab1679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:40:33<00:00, 60.34s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # Shuffle training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "\n",
    "    # show all examples to model\n",
    "    for rnd_idx in rnd_train_idx:\n",
    "        \n",
    "        p_fix = train_set[rnd_idx]\n",
    "\n",
    "        # Get image and segmentation\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].long().contiguous()\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].long().contiguous()\n",
    "\n",
    "        # Here we have to rescale the images for the flownet\n",
    "        # the flownet expects intputs that match x*64, when m and n < 200\n",
    "        teacher_fixed = F.interpolate(fixed, size=(128,128))\n",
    "        teacher_moving = F.interpolate(moving, size=(128,128))\n",
    "        # Generate the teacher flow estimation\n",
    "        flow_in = preprocessing_flownet(teacher_fixed.detach().clone().reshape(128,128,1),teacher_moving.detach().clone().reshape(128,128,1)).cuda()\n",
    "        teacher_flow = flownet(flow_in)\n",
    "        teacher_flow = F.interpolate(teacher_flow, size=(H//4,W//4), mode='bilinear')\n",
    "        \n",
    "        # Label preparation\n",
    "        C1,Hf,Wf = moving_seg.size()\n",
    "        label_moving_onehot = F.one_hot(moving_seg,num_classes=3).permute(0,3,1,2).float()\n",
    "        label_moving = F.interpolate(label_moving_onehot,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "        label_fixed = F.one_hot(fixed_seg,num_classes=3).permute(0,3,1,2).float()\n",
    "        label_fixed = F.interpolate(label_fixed,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "        # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "        # according to the corresponding discrete displacement pair\n",
    "        label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,3,displace_range**2,-1)\n",
    "        \n",
    "\n",
    "        feat00 = student(fixed.cuda())\n",
    "        feat50 = student(moving.cuda())\n",
    "\n",
    "        # compute the cost tensor using the correlation layer\n",
    "        ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "\n",
    "        # compute the MIN-convolution & probabilistic output with the given function\n",
    "        soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "\n",
    "        # warp the label\n",
    "        label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "        # warp segment with teacher flow\n",
    "        warped_teacher_seg = warp_seg(label_moving.squeeze().float().cuda(),teacher_flow.cuda()).cpu()\n",
    "        \n",
    "        loss = kl_loss(label_warped,warped_teacher_seg.view(3,-1))\n",
    "        loss.backward()\n",
    "        if (epoch+1)%grad_accum == 0:\n",
    "            # every grad_accum iterations :Make an optimizer step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1627d2c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has an average Dice of 0.34468 mit Variance: 0.02055. The unwarped Mean dice is: 0.32494 with Var 0.0243\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e49972",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), \"models/obel_klDiv.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec28970",
   "metadata": {},
   "source": [
    "# Experiment 2.2\n",
    "Using MSE loss between the flow predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "341e6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = OBELISK2d(24)\n",
    "init_weights(student)\n",
    "student.train().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(student.parameters()),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dfaa666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:34:52<00:00, 56.93s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # Shuffle training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "\n",
    "    # show all examples to model\n",
    "    for rnd_idx in rnd_train_idx:\n",
    "        \n",
    "        p_fix = train_set[rnd_idx]\n",
    "\n",
    "        # Get image and segmentation\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].long().contiguous()\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].long().contiguous()\n",
    "\n",
    "        # Here we have to rescale the images for the flownet\n",
    "        # the flownet expects intputs that match x*64, when m and n < 200\n",
    "        teacher_fixed = F.interpolate(fixed, size=(128,128))\n",
    "        teacher_moving = F.interpolate(moving, size=(128,128))\n",
    "        # Generate the teacher flow estimation\n",
    "        flow_in = preprocessing_flownet(teacher_fixed.detach().clone().reshape(128,128,1),teacher_moving.detach().clone().reshape(128,128,1)).cuda()\n",
    "        teacher_flow = flownet(flow_in)\n",
    "        teacher_flow = F.interpolate(teacher_flow, size=(H//4,W//4), mode='bilinear')\n",
    "        \n",
    "        # Label preparation\n",
    "        #C1,Hf,Wf = moving_seg.size()\n",
    "        #label_moving_onehot = F.one_hot(moving_seg,num_classes=3).permute(0,3,1,2).float()\n",
    "        #label_moving = F.interpolate(label_moving_onehot,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "        #label_fixed_onehot = F.one_hot(fixed_seg,num_classes=3).permute(0,3,1,2).float()\n",
    "        #label_fixed = F.interpolate(label_fixed_onehot,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "        # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "        # according to the corresponding discrete displacement pair\n",
    "        #label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,3,displace_range**2,-1)\n",
    "\n",
    "        feat00 = student(fixed.cuda())\n",
    "        feat50 = student(moving.cuda())\n",
    "\n",
    "        # compute the cost tensor using the correlation layer\n",
    "        ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "\n",
    "        # compute the MIN-convolution & probabilistic output with the given function\n",
    "        soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "        \n",
    "        #loss = cross_entropy_loss(disp_xy,teacher_flow)\n",
    "        loss = torch.sum(torch.pow(disp_xy - teacher_flow, 2))\n",
    "        loss.backward()\n",
    "        if (epoch+1)%grad_accum == 0:\n",
    "            # every grad_accum iterations :Make an optimizer step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef0462ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has an average Dice of 0.33651 mit Variance: 0.02122. The unwarped Mean dice is: 0.32494 with Var 0.0243\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc1755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), \"models/obel_MSE_teacher_flow.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d5ff8",
   "metadata": {},
   "source": [
    "# Experiment 2.3\n",
    "Using warped label loss as simple addition to the MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0435291",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = OBELISK2d(24)\n",
    "init_weights(student)\n",
    "student.train().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(student.parameters()),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46caa60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [48:20<00:00, 29.00s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # Shuffle training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "\n",
    "    # show all examples to model\n",
    "    for rnd_idx in rnd_train_idx:\n",
    "        \n",
    "        p_fix = train_set[rnd_idx]\n",
    "\n",
    "        # Get image and segmentation\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].long().contiguous()\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].long().contiguous()\n",
    "\n",
    "        # Here we have to rescale the images for the flownet\n",
    "        # the flownet expects intputs that match x*64, when m and n < 200\n",
    "        teacher_fixed = F.interpolate(fixed, size=(128,128))\n",
    "        teacher_moving = F.interpolate(moving, size=(128,128))\n",
    "        # Generate the teacher flow estimation\n",
    "        flow_in = preprocessing_flownet(teacher_fixed.detach().clone().reshape(128,128,1),teacher_moving.detach().clone().reshape(128,128,1)).cuda()\n",
    "        teacher_flow = flownet(flow_in)\n",
    "        teacher_flow = F.interpolate(teacher_flow, size=(H//4,W//4), mode='bilinear')\n",
    "        \n",
    "        # Label preparation\n",
    "        C1,Hf,Wf = moving_seg.size()\n",
    "        label_moving_onehot = F.one_hot(moving_seg,num_classes=3).permute(0,3,1,2).float()\n",
    "        label_moving = F.interpolate(label_moving_onehot,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "        label_fixed_onehot = F.one_hot(fixed_seg,num_classes=3).permute(0,3,1,2).float()\n",
    "        label_fixed = F.interpolate(label_fixed_onehot,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "        # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "        # according to the corresponding discrete displacement pair\n",
    "        label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,3,displace_range**2,-1)\n",
    "\n",
    "        feat00 = student(fixed.cuda())\n",
    "        feat50 = student(moving.cuda())\n",
    "\n",
    "        # compute the cost tensor using the correlation layer\n",
    "        ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "\n",
    "        # compute the MIN-convolution & probabilistic output with the given function\n",
    "        soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "        \n",
    "        # warp the label\n",
    "        label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "        # warp segment with teacher flow\n",
    "        warped_teacher_seg = warp_seg(label_moving.squeeze().float().cuda(),teacher_flow.cuda()).cpu()\n",
    "        \n",
    "        teacher_loss = torch.sum(torch.pow(disp_xy - teacher_flow, 2))\n",
    "        label_distance1 = torch.sum(torch.pow(label_fixed.reshape(3,-1)-label_warped.reshape(3,-1),2),0)\n",
    "        loss = teacher_loss + label_distance1.mean()\n",
    "        if (epoch+1)%grad_accum == 0:\n",
    "            # every grad_accum iterations :Make an optimizer step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c30e33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has an average Dice of 0.30596 mit Variance: 0.02538. The unwarped Mean dice is: 0.32494 with Var 0.0243\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b048572",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), \"models/obel_MSE_warped.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c94593",
   "metadata": {},
   "source": [
    "# Experiment 2.4\n",
    "Using the weighted label loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b3579ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = OBELISK2d(24)\n",
    "init_weights(student)\n",
    "student.train().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(student.parameters()),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595808ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [50:04<00:00, 30.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # Shuffle training examples\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "\n",
    "    # show all examples to model\n",
    "    for rnd_idx in rnd_train_idx:\n",
    "        \n",
    "        p_fix = train_set[rnd_idx]\n",
    "\n",
    "        # Get image and segmentation\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].long().contiguous()\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].long().contiguous()\n",
    "\n",
    "        # Here we have to rescale the images for the flownet\n",
    "        # the flownet expects intputs that match x*64, when m and n < 200\n",
    "        teacher_fixed = F.interpolate(fixed, size=(128,128))\n",
    "        teacher_moving = F.interpolate(moving, size=(128,128))\n",
    "        # Generate the teacher flow estimation\n",
    "        flow_in = preprocessing_flownet(teacher_fixed.detach().clone().reshape(128,128,1),teacher_moving.detach().clone().reshape(128,128,1)).cuda()\n",
    "        teacher_flow = flownet(flow_in)\n",
    "        teacher_flow = F.interpolate(teacher_flow, size=(H//4,W//4), mode='bilinear')\n",
    "        \n",
    "        # Label preparation\n",
    "        C1,Hf,Wf = moving_seg.size()\n",
    "        label_moving_onehot = F.one_hot(moving_seg,num_classes=3).permute(0,3,1,2).float()\n",
    "        label_moving = F.interpolate(label_moving_onehot,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "        label_fixed_onehot = F.one_hot(fixed_seg,num_classes=3).permute(0,3,1,2).float()\n",
    "        label_fixed = F.interpolate(label_fixed_onehot,size=(Hf//4,Wf//4),mode='bilinear')\n",
    "        # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "        # according to the corresponding discrete displacement pair\n",
    "        label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,3,displace_range**2,-1)\n",
    "\n",
    "        feat00 = student(fixed.cuda())\n",
    "        feat50 = student(moving.cuda())\n",
    "\n",
    "        # compute the cost tensor using the correlation layer\n",
    "        ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "\n",
    "        # compute the MIN-convolution & probabilistic output with the given function\n",
    "        soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "        \n",
    "        # warp the label\n",
    "        label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "        # warp segment with teacher flow\n",
    "        warped_teacher_seg = warp_seg(moving_seg.float().cuda(),F.interpolate(teacher_flow, size=(H,W), mode='bilinear').cuda()).cpu()\n",
    "        \n",
    "        # calculate losses\n",
    "        teacher_loss = torch.sum(torch.pow(disp_xy - teacher_flow, 2))\n",
    "        label_distance1 = torch.sum(torch.pow(label_fixed.reshape(3,-1)-label_warped.reshape(3,-1),2),0)\n",
    "        \n",
    "        # calculate the dice score for the warped segmentation\n",
    "        d0 = dice_coeff(warped_teacher_seg.squeeze(), fixed_seg.unsqueeze(0).float(), 3)\n",
    "        \n",
    "        # The loss can then be weighted\n",
    "        loss = (d0.mean().item()) * teacher_loss + (1- d0.mean().item()) * label_distance1.mean()\n",
    "        if (epoch+1)%grad_accum == 0:\n",
    "            # every grad_accum iterations :Make an optimizer step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a084958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has an average Dice of 0.28963 mit Variance: 0.02797. The unwarped Mean dice is: 0.33263 with Var 0.02592\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "717eace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), \"models/obel_MSE_weighted_warped.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b63703d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686a2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
