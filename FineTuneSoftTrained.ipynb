{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94dd3ee5",
   "metadata": {},
   "source": [
    "# Fine tuning training\n",
    "First the PDD-Net is trained with PWC-Net as additional soft target, then is fine tuned on a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import ceil\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.load_models import load_flownet2, load_pwcnet, init_weights\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp, warp_Flow\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "import torch.utils.checkpoint\n",
    "from models.pdd_net.pdd_student import OBELISK2d\n",
    "\n",
    "# Select a GPU for the work\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "available_gpus = [(torch.cuda.device(i),torch.cuda.get_device_name(i)) for i in range(torch.cuda.device_count())]\n",
    "print(available_gpus)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a68e65",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b22c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.load('/share/data_ultraschall/nicke_ma/data/train_frames_disp_6.pth')\n",
    "segs = torch.load('/share/data_ultraschall/nicke_ma/data/train_segs_disp_6.pth')\n",
    "\n",
    "test_imgs = torch.load('/share/data_ultraschall/nicke_ma/data/test_frames_disp_6.pth')\n",
    "test_segs = torch.load('/share/data_ultraschall/nicke_ma/data/test_segs_disp_6.pth')\n",
    "\n",
    "train_set = torch.arange(len(imgs))\n",
    "test_set = torch.arange(len(test_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa0141",
   "metadata": {},
   "source": [
    "# Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dabadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OBELISK2d(nn.Module):\n",
    "    def __init__(self, chan=16, size=(150,150)):\n",
    "        super(OBELISK2d, self).__init__()\n",
    "        channels = chan\n",
    "        self.offsets = nn.Parameter(torch.randn(2, channels * 2, 2) * 0.05)\n",
    "        self.layer0 = nn.Conv2d(1, 4, 5, stride=2, bias=False, padding=2)\n",
    "        self.batch0 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.layer1 = nn.Conv2d(channels * 8, channels * 4, 1, bias=False,\n",
    "                                groups=1)\n",
    "        self.batch1 = nn.BatchNorm2d(channels * 4)\n",
    "        self.layer2 = nn.Conv2d(channels * 4, channels * 4, 3, bias=False,\n",
    "                                padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(channels * 4)\n",
    "        self.layer3 = nn.Conv2d(channels * 4, channels * 1, 1)\n",
    "\n",
    "        H = size[0]\n",
    "        W = size[1]\n",
    "        self.o_m = H // 4 +1\n",
    "        self.o_n = W // 4 +1\n",
    "\n",
    "        self.displace_range = 11\n",
    "        self.disp_hw = 5\n",
    "        self.ogrid_xy = F.affine_grid(torch.eye(2, 3).unsqueeze(0),\n",
    "                                 (1, 1, self.o_m, self.o_n)).view(1, 1, -1, 2).cuda()\n",
    "        self.disp_range = 0.25\n",
    "        self.displacement_width = 11\n",
    "        shift_xy = F.affine_grid(self.disp_range * torch.eye(2, 3).unsqueeze(0), (1, 1, self.displacement_width, self.displacement_width)).view(1, 1, -1, 2).cuda()\n",
    "        grid_size = 32  # 25#30\n",
    "        self.grid_xy = F.affine_grid(torch.eye(2, 3).unsqueeze(0),\n",
    "                                (1, 1, grid_size, grid_size)).view(1, -1, 1,\n",
    "                                                                   2).cuda()\n",
    "\n",
    "    def forward(self, fixed_img, moving_img):\n",
    "        img_in_f = F.avg_pool2d(fixed_img, 3, padding=1, stride=2)\n",
    "        img_in_f = F.relu(self.batch0(self.layer0(img_in_f)))\n",
    "        sampled_f = F.grid_sample(img_in_f,self.ogrid_xy + self.offsets[0, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "        sampled_f -= F.grid_sample(img_in_f,self.ogrid_xy + self.offsets[1, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "\n",
    "        x_1 = F.relu(self.batch1(self.layer1(sampled_f)))\n",
    "        x_1 = F.relu(self.batch2(self.layer2(x_1)))\n",
    "        features_fixed = self.layer3(x_1)\n",
    "        \n",
    "        img_in_m = F.avg_pool2d(moving_img, 3, padding=1, stride=2)\n",
    "        img_in_m = F.relu(self.batch0(self.layer0(img_in_m)))\n",
    "        sampled_m = F.grid_sample(img_in_m,self.ogrid_xy + self.offsets[0, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "        sampled_m -= F.grid_sample(img_in_m,self.ogrid_xy + self.offsets[1, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "\n",
    "        x_2 = F.relu(self.batch1(self.layer1(sampled_m)))\n",
    "        x_2 = F.relu(self.batch2(self.layer2(x_2)))\n",
    "        features_moving = self.layer3(x_2)\n",
    "\n",
    "        ssd_distance = self.correlation_layer(features_moving, features_fixed)\n",
    "        soft_cost,disp_xy = self.meanfield(ssd_distance, fixed_img, self.displace_range, self.o_m, self.o_n)\n",
    "        \n",
    "        return soft_cost, disp_xy\n",
    "\n",
    "\n",
    "    def min_convolution(self, ssd_distance, displace_range, H, W):\n",
    "        # Prepare operators for smooth dense displacement space\n",
    "        pad1 = nn.ReplicationPad2d(5)\n",
    "        avg1 = nn.AvgPool2d(5, stride=1)\n",
    "        max1 = nn.MaxPool2d(3, stride=1)\n",
    "        pad2 = nn.ReplicationPad2d(4)\n",
    "        # approximate min convolution / displacement compatibility\n",
    "\n",
    "        ssd_minconv = avg1(avg1(-max1(-pad1(\n",
    "            ssd_distance.permute(0, 2, 3, 1).reshape(1, -1, self.displace_range,\n",
    "                                                    self.displace_range)))))\n",
    "\n",
    "        ssd_minconv = ssd_minconv.permute(0, 2, 3, 1).view(1, -1, H, W)\n",
    "        min_conv_cost = avg1(avg1(pad2(ssd_minconv)))\n",
    "\n",
    "        return min_conv_cost\n",
    "\n",
    "\n",
    "    def meanfield(self, ssd_distance, img_fixed, displace_range, H, W):\n",
    "        crnt_dev = ssd_distance.device\n",
    "\n",
    "        cost = self.min_convolution(ssd_distance, displace_range, H, W)\n",
    "\n",
    "        soft_cost = F.softmax(-10 * cost.view(displace_range ** 2, -1).t(), 1)\n",
    "\n",
    "        disp_hw = (displace_range - 1) // 2\n",
    "        disp_mesh_grid = disp_hw * F.affine_grid(torch.eye(2, 3).unsqueeze(0), (\n",
    "        1, 1, displace_range, displace_range), align_corners=True)\n",
    "        disp_mesh_grid /= torch.Tensor([(W - 1) * .5, (H - 1) * .5])\n",
    "\n",
    "        disp_xy = torch.sum(\n",
    "            soft_cost.view(1, H, W, -1, 1) * disp_mesh_grid.view(1, 1, 1, -1,\n",
    "                                                                2).to(crnt_dev),\n",
    "            3).permute(0, 3, 1, 2)\n",
    "\n",
    "        return soft_cost, disp_xy\n",
    "\n",
    "\n",
    "    def correlation_layer(self, feat_moving, feat_fixed):\n",
    "        disp_hw = (self.displacement_width - 1) // 2\n",
    "        feat_moving_unfold = F.unfold(feat_moving.transpose(1, 0),\n",
    "                                    (self.displace_range, self.displace_range),\n",
    "                                    padding=self.disp_hw)\n",
    "        B, C, H, W = feat_fixed.size()\n",
    "\n",
    "        ssd_distance = ((feat_moving_unfold - feat_fixed.view(C, 1, -1)) ** 2).sum(0).view(1, displace_range ** 2, H, W)\n",
    "\n",
    "        return ssd_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8480ce81",
   "metadata": {},
   "source": [
    "# Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfadb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet = load_flownet2().cuda()\n",
    "flownet.eval()\n",
    "pwc = load_pwcnet().cuda()\n",
    "pwc.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023a967",
   "metadata": {},
   "source": [
    "# Soft target training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_hw = 5\n",
    "displace_range = 11\n",
    "label_weights = torch.tensor([0.1,0.6, 0.3])# weights for background = 0.1, Vein = 0.6 and Artery = 0.3\n",
    "epochs = 200\n",
    "lr = 0.00025\n",
    "grad_accum = 5\n",
    "\n",
    "H=150;W=150\n",
    "\n",
    "student = OBELISK2d(16)\n",
    "student.apply(init_weights)\n",
    "student.train().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(student.parameters()),lr=lr)\n",
    "alpha=0.5\n",
    "\n",
    "prev_eval = 0\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "unwarped = []\n",
    "scale=2\n",
    "for epoch in trange(epochs, desc='epoch Loop', leave=False):\n",
    "    student.train()\n",
    "    # Cross Validation\n",
    "    #train_set = torch.from_numpy(np.random.choice(np.arange(len(imgs)),size=int(len(imgs)*0.95), replace=False))\n",
    "\n",
    "    #test_set = torch.arange(len(imgs))\n",
    "    #for idx in train_set:\n",
    "    #    test_set = test_set[test_set != idx]\n",
    "    # Shuffle training examples\n",
    "    #rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "    \n",
    "    # shuffle data\n",
    "    train_set_perm = torch.randperm(len(train_set))\n",
    "    train_set = train_set[train_set_perm]\n",
    "    # show all examples to model\n",
    "    for i in trange(len(train_set), desc='Train Loop', leave=False):\n",
    "        \n",
    "        rnd_idx = train_set[i]\n",
    "        tmp_loss = []\n",
    "        p_fix = train_set[rnd_idx]\n",
    "\n",
    "        # Get image and segmentation\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].contiguous() * 2\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].contiguous() * 2\n",
    "\n",
    "        if len(torch.where(torch.histc(fixed_seg) != 0)[0]) == 3 and fixed_seg.max() <= 1:\n",
    "            fixed_seg = fixed_seg*2\n",
    "        if len(torch.where(torch.histc(moving_seg) != 0)[0]) == 3 and moving_seg.max() <= 1:\n",
    "            moving_seg = moving_seg*2\n",
    "        \n",
    "        ########## PWC-Net\n",
    "        # Here we rescale the images for the Teacher \n",
    "        # the flownet expects intputs that match Nx64. \n",
    "        teacher_fixed = F.interpolate(fixed, size=(scale*64,scale*64), mode='bicubic')\n",
    "        teacher_moving = F.interpolate(moving, size=(scale*64,scale*64), mode='bicubic')\n",
    "\n",
    "        # Generate the pwc flow estimation\n",
    "        pwc_flow_in = preprocessing_pwc(teacher_fixed.detach().clone().reshape(scale*64,scale*64,1),teacher_moving.detach().clone().reshape(scale*64,scale*64,1)).cuda()\n",
    "        pwc_flow = pwc(pwc_flow_in) \n",
    "        pwc_flow = F.interpolate(pwc_flow, size=(H,W),mode='bicubic')\n",
    "\n",
    "        # warp the segmentations with pwc flow\n",
    "        warped_pwc_seg = warp(moving_seg.float().unsqueeze(0).cuda(), pwc_flow.cuda()).cpu()\n",
    "        \n",
    "        ########## FlowNet2\n",
    "        # Generate the flownet flow estimation\n",
    "        #flow_in = preprocessing_flownet(teacher_fixed.detach().clone().reshape(scale*64,scale*64,1),teacher_moving.detach().clone().reshape(scale*64,scale*64,1)).cuda() * 255\n",
    "        #flownet_flow = flownet(flow_in)\n",
    "        #flownet_flow = F.interpolate(flownet_flow.cpu(), size=(H,W), mode='bicubic')\n",
    "\n",
    "        # warp segmentation with flownet flow\n",
    "        #warped_flownet_seg = warp(moving_seg.float().unsqueeze(0).cuda(), flownet_flow.cuda()).cpu()\n",
    "        \n",
    "\n",
    "        # Label preparation for PDD\n",
    "        C1,Hf,Wf = moving_seg.size()\n",
    "        label_moving_onehot = F.one_hot(moving_seg.long(),num_classes=3).permute(0,3,1,2).float()\n",
    "        label_moving = F.interpolate(label_moving_onehot,size=(Hf//4 +1,Wf//4 +1),mode='bicubic')\n",
    "        label_fixed = F.one_hot(fixed_seg.long(),num_classes=3).permute(0,3,1,2).float()\n",
    "        label_fixed = F.interpolate(label_fixed,size=(Hf//4 +1,Wf//4 +1),mode='bicubic')\n",
    "        # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "        # according to the corresponding discrete displacement pair\n",
    "        label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,3,displace_range**2,-1)\n",
    "\n",
    "        \n",
    "        ########## PDD Forward pass\n",
    "        soft_cost,disp_xy = student(fixed.cuda(), moving.cuda())\n",
    "\n",
    "        # warp the label\n",
    "        label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "        \n",
    "        \n",
    "        #dense_flow_fit = F.interpolate(disp_xy,size=(H,W),mode='bicubic')\n",
    "        #apply and evaluate transformation\n",
    "        #identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "        #warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu() \n",
    "        \n",
    "        pwc_onehot = labelMatrixOneHot(F.interpolate(warped_pwc_seg, size=(H//4 +1, W//4 +1), mode='bicubic').view(1,H//4 +1, W//4 +1), 3)\n",
    "        #flownet_onehot = labelMatrixOneHot(F.interpolate(warped_flownet_seg, size=(H//4 +1, W//4 +1), mode='bicubic').view(1,H//4 +1, W//4 +1), 3)\n",
    "\n",
    "        pwc_diff = torch.sum(torch.pow(label_warped.view(3,-1)-pwc_onehot.view(3,-1).detach(),2), 1) * label_weights\n",
    "        #flownet_diff = torch.sum(torch.pow(label_warped.view(3,-1)-flownet_onehot.view(label_warped.shape),2), 1) * label_weights\n",
    "\n",
    "        label_distance1 = torch.sum(torch.pow(label_fixed.reshape(3,-1)-label_warped.reshape(3,-1),2),1) * label_weights\n",
    "\n",
    "        diffloss = 2*((disp_xy[0,:,1:,:]-disp_xy[0,:,:-1,:])**2).mean()+\\\n",
    "            2*((disp_xy[0,1:,:,:]-disp_xy[0,:-1,:,:])**2).mean()+\\\n",
    "            2*((disp_xy[0,:,:,1:]-disp_xy[0,:,:,:-1])**2).mean()\n",
    "        \n",
    "        \n",
    "        #print(flownet_onehot.max())\n",
    "        # Caclculate the label weighted teacher loss\n",
    "        #teacher_loss = alpha * pwc_diff + (1-alpha)*flownet_diff\n",
    "        \n",
    "        # Combine the teacherloss with the label loss\n",
    "        loss = 0.5 * pwc_diff.mean() + diffloss + label_distance1.mean() #+ \n",
    "        \n",
    "        # propagate backwards\n",
    "        loss.backward()\n",
    "        tmp_loss.append([0.5 * pwc_diff.mean().item(),\n",
    "                         label_distance1.mean().item(),\n",
    "                         diffloss.item()])\n",
    "        \n",
    "        if i %grad_accum == 0:\n",
    "            # every grad_accum iterations :Make an optimizer step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "    losses.append(np.mean(tmp_loss, axis=0))\n",
    "    \n",
    "    student.eval()\n",
    "    # Evaluate model:\n",
    "    eval_dice = torch.zeros(len(test_set),2)\n",
    "    for j in trange(len(test_set)-1, desc='Eval', leave=False):\n",
    "        fixed = test_imgs[j:j+1,0,:].unsqueeze(0).float()\n",
    "        moving = test_imgs[j:j+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = test_segs[j:j+1,0,:].contiguous() * 2\n",
    "        moving_seg = test_segs[j:j+1,1,:].contiguous() * 2\n",
    "\n",
    "        teacher_fixed = F.interpolate(fixed, size=(scale*64,scale*64), mode='bicubic')\n",
    "        teacher_moving = F.interpolate(moving, size=(scale*64,scale*64), mode='bicubic')\n",
    "\n",
    "        # Generate the pwc flow estimation\n",
    "        pwc_flow_in = preprocessing_pwc(teacher_fixed.detach().clone().reshape(scale*64,scale*64,1),teacher_moving.detach().clone().reshape(scale*64,scale*64,1)).cuda()\n",
    "        pwc_flow = pwc(pwc_flow_in) \n",
    "        pwc_flow = F.interpolate(pwc_flow, size=(H,W),mode='bicubic')\n",
    "\n",
    "        # warp the segmentations with pwc flow\n",
    "        warped_pwc_seg = warp(moving_seg.float().unsqueeze(0).cuda(), pwc_flow.cuda()).cpu()\n",
    "        \n",
    "        ########## FlowNet2\n",
    "        # Generate the flownet flow estimation\n",
    "        flow_in = preprocessing_flownet(teacher_fixed.detach().clone().reshape(scale*64,scale*64,1),teacher_moving.detach().clone().reshape(scale*64,scale*64,1)).cuda() * 255\n",
    "        flownet_flow = flownet(flow_in)\n",
    "        flownet_flow = F.interpolate(flownet_flow.cpu(), size=(H,W), mode='bicubic')\n",
    "\n",
    "        # warp segmentation with flownet flow\n",
    "        warped_flownet_seg = warp(moving_seg.float().unsqueeze(0).cuda(), flownet_flow.cuda()).cpu()\n",
    "        \n",
    "        oft_cost,disp_xy = student(fixed.cuda(), moving.cuda())\n",
    "        pred_flow=F.interpolate(disp_xy,size=(150,150))\n",
    "        \n",
    "        identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False)\n",
    "        warped_student_seg = F.grid_sample(moving_seg.unsqueeze(0).float(),identity+pred_flow.cpu().permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "        \n",
    "        d0 = dice_coeff(warped_student_seg.squeeze(), fixed_seg.squeeze() ,3)\n",
    "        d1 = dice_coeff(warped_student_seg.squeeze(), warped_pwc_seg.squeeze() ,3)\n",
    "        #dice = torch.sum(d0, d1, axis=0)\n",
    "        dice = torch.stack([d0,d1])\n",
    "        eval_dice[j] = dice.mean(axis=0)\n",
    "    #print(eval_dice.mean(axis=0), eval_dice.mean(), ' Loss: ', np.mean(tmp_loss, axis=0))\n",
    "    accs.append(eval_dice.mean())\n",
    "    if eval_dice.mean() > prev_eval:\n",
    "        prev_eval = eval_dice.mean()\n",
    "        best_epoch = epoch\n",
    "        torch.save(student.state_dict(), f'models/Experiment_2/fineTuneSoft/soft_trained_{best_epoch}.pth')\n",
    "    if epoch > 10:\n",
    "        if eval_dice.mean() == prev_eval:\n",
    "            if eval_dice.mean() == accs[-2]:\n",
    "                if eval_dice.mean() == accs[-3]:\n",
    "                    print(f\"Final Eval Score: {eval_dice.mean()}\")\n",
    "                    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dice.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95d21c8",
   "metadata": {},
   "source": [
    "# Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs1 = torch.load('/share/data_ultraschall/nicke_ma/data/frames_oneFixed_multipleMoving_dist2.pth')\n",
    "segs1 = torch.load('/share/data_ultraschall/nicke_ma/data/segs_oneFixed_multipleMoving_dist2.pth')\n",
    "\n",
    "imgs2 = torch.load('/share/data_ultraschall/nicke_ma/data/frames_oneFixed_multipleMoving.pth')\n",
    "segs2 = torch.load('/share/data_ultraschall/nicke_ma/data/segs_oneFixed_multipleMoving.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9cbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_imgs = torch.cat((imgs1,imgs2))\n",
    "tune_segs = torch.cat((segs1,segs2))\n",
    "\n",
    "break_point = int(len(tune_imgs)*0.9)\n",
    "tune_set = torch.arange(break_point)\n",
    "test_tune_set = torch.arange(break_point, len(tune_imgs))\n",
    "#define a training split \n",
    "torch.manual_seed(42)\n",
    "# Now, we prepare our train & test dataset.\n",
    "#tune_set = torch.from_numpy(np.random.choice(np.arange(len(tune_imgs)),size=int(len(tune_imgs)*0.9), replace=False))\n",
    "\n",
    "#test_tune_set = torch.arange(len(tune_imgs))\n",
    "#for idx in tune_set:\n",
    "#    test_tune_set = test_tune_set[test_tune_set != idx]\n",
    "\n",
    "\n",
    "print(f\"{tune_set.shape[0]} train examples\")\n",
    "print(f\"{test_tune_set.shape[0]} test examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel = OBELISK2d(16)\n",
    "path_to_state_dict = f'models/Experiment_2/fineTuneSoft/soft_trained_{best_epoch}.pth'\n",
    "obel.load_state_dict(torch.load(path_to_state_dict))\n",
    "obel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_hw = 5\n",
    "displace_range = 11\n",
    "epochs = 200\n",
    "lr = 0.00025\n",
    "grad_accum = 5\n",
    "optimizer = torch.optim.Adam(list(obel.parameters()),lr=lr, weight_decay=0.000005)\n",
    "\n",
    "best_epoch = 0\n",
    "prev_eval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "unwapred = []\n",
    "for epoch in trange(epochs):\n",
    "\n",
    "    # shuffle data\n",
    "    tune_set_perm = torch.randperm(len(tune_set))\n",
    "    tune_set = tune_set[tune_set_perm]\n",
    "    # show all examples to model\n",
    "    for i in trange(len(tune_set), desc='Train loop', leave=False):\n",
    "        rnd_idx = tune_set[i]\n",
    "        loss_tmp = []\n",
    "        p_fix = tune_set[rnd_idx]\n",
    "\n",
    "        # Get image and segmentation\n",
    "        fixed = tune_imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float()\n",
    "        moving = tune_imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = tune_segs[p_fix:p_fix+1,0,:].contiguous() * 2\n",
    "        moving_seg = tune_segs[p_fix:p_fix+1,1,:].contiguous() * 2\n",
    "\n",
    "        if len(torch.where(torch.histc(fixed_seg) != 0)[0]) == 3 and fixed_seg.max() <= 1:\n",
    "            fixed_seg = fixed_seg*2\n",
    "        if len(torch.where(torch.histc(moving_seg) != 0)[0]) == 3 and moving_seg.max() <= 1:\n",
    "            moving_seg = moving_seg*2\n",
    "            \n",
    "        # Downsize the label\n",
    "        C1,Hf,Wf = moving_seg.size()\n",
    "        label_moving = F.one_hot(moving_seg.long(),num_classes=3).permute(0,3,1,2).float()\n",
    "        label_moving = F.interpolate(label_moving,size=(Hf//4 +1,Wf//4 +1),mode='bicubic')\n",
    "        \n",
    "        label_fixed = F.one_hot(fixed_seg.long(),num_classes=3).permute(0,3,1,2).float()\n",
    "        label_fixed = F.interpolate(label_fixed,size=(Hf//4 +1,Wf//4 +1),mode='bicubic')\n",
    "        # generate the \"unfolded\" version of the moving encoding that will result in the shifted versions per channel\n",
    "        # according to the corresponding discrete displacement pair\n",
    "        label_moving_unfold = F.unfold(label_moving,(displace_range,displace_range),padding=disp_hw).view(1,3,displace_range**2,-1)\n",
    "\n",
    "        #with torch.cuda.amp.autocast():\n",
    "        # passed through obelisk layer\n",
    "        soft_cost,disp_xy = obel(fixed.cuda(), moving.cuda())      # fixed\n",
    "        #feat50 = obel(moving.cuda())     # moving\n",
    "\n",
    "         # compute the cost tensor using the correlation layer\n",
    "        #ssd_distance = correlation_layer(displace_range, feat50, feat00)\n",
    "\n",
    "        # compute the MIN-convolution & probabilistic output with the given function\n",
    "        #soft_cost,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4 +1, W//4 +1)\n",
    "\n",
    "        label_warped = torch.sum(soft_cost.cpu().t().unsqueeze(0)*label_moving_unfold.squeeze(0),1)\n",
    "        \n",
    "        #print(((torch.pow(label_fixed.reshape(3,-1)-label_warped.reshape(3,-1),2)).T.mul(label_weights)).T.shape)\n",
    "        label_distance1 = torch.sum((torch.pow(label_fixed.reshape(3,-1)-label_warped.reshape(3,-1),2)),1) * label_weights\n",
    "        #label_distance1 = label_distance1 * label_weights \n",
    "\n",
    "        diffloss = 1.5*((disp_xy[0,:,1:,:]-disp_xy[0,:,:-1,:])**2).mean()+\\\n",
    "            1.5*((disp_xy[0,1:,:,:]-disp_xy[0,:-1,:,:])**2).mean()+\\\n",
    "            1.5*((disp_xy[0,:,:,1:]-disp_xy[0,:,:,:-1])**2).mean()\n",
    "\n",
    "\n",
    "        loss = label_distance1.mean() + diffloss\n",
    "        # perform the backpropagation and weight updates\n",
    "        loss.backward()\n",
    "        loss_tmp.append(loss.item())\n",
    "\n",
    "        if (i+1)%grad_accum == 0:\n",
    "            # every grad_accum iterations :Make an optimizer step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "    losses.append(np.mean(loss_tmp))\n",
    "    \n",
    "    # Evaluate model:\n",
    "    eval_dice = torch.zeros(len(test_tune_set),2)\n",
    "    for j in trange(len(test_tune_set)-1, desc='Eval', leave=False):\n",
    "        fixed = imgs[j:j+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[j:j+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[j:j+1,0,:].contiguous() * 2\n",
    "        moving_seg = segs[j:j+1,1,:].contiguous() * 2\n",
    "        \n",
    "        oft_cost,disp_xy = obel(fixed.cuda(), moving.cuda())\n",
    "        pred_flow=F.interpolate(disp_xy,size=(150,150))\n",
    "        \n",
    "        identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False)\n",
    "        warped_student_seg = F.grid_sample(moving_seg.unsqueeze(0).float(),identity+pred_flow.cpu().permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "        \n",
    "        d0 = dice_coeff(warped_student_seg.squeeze(), fixed_seg ,3)\n",
    "        eval_dice[j] = d0\n",
    "    print(eval_dice.mean(axis=0), eval_dice.mean(), \" Loss: \", np.mean(loss_tmp))\n",
    "    accs.append(eval_dice.mean())\n",
    "    if eval_dice.mean() > prev_eval:\n",
    "        prev_eval = eval_dice.mean()\n",
    "        best_epoch = epoch\n",
    "        torch.save(obel.state_dict(), f'models/Experiment_2/fineTuneSoft/tuned-17-02.pth')\n",
    "    if epoch > 10:\n",
    "        if eval_dice.mean() == prev_eval:\n",
    "            if eval_dice.mean() == accs[-2]:\n",
    "                if eval_dice.mean() == accs[-3]:\n",
    "                    print(f\"Final Eval Score: {eval_dice.mean()}\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc48cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c85b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
