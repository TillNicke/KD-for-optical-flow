{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4eab2d9",
   "metadata": {},
   "source": [
    "# Trying to finetune flownet2 on US data\n",
    "\n",
    "Did not yield good results. Should be further investigated\n",
    "\n",
    "This Notebook is not part of the Thesis. It was an starting point I wanted to investigate, but I kindly was directed to pursue other areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from math import ceil\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp, warpImage\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "\n",
    "from models.flownet2_pytorch.flownet2_mph import *\n",
    "from models.flownet2_pytorch.flownet2_components import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Select a GPU for the work\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "available_gpus = [(torch.cuda.device(i),torch.cuda.get_device_name(i)) for i in range(torch.cuda.device_count())]\n",
    "print(available_gpus)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39842d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.load('/share/data_ultraschall/nicke_ma/data/train_frames.pth')\n",
    "segs = torch.load('/share/data_ultraschall/nicke_ma/data/train_segs.pth')\n",
    "\n",
    "#define a training split \n",
    "torch.manual_seed(42)\n",
    "# Now, we prepare our train & test dataset.\n",
    "train_set = torch.from_numpy(np.random.choice(np.arange(len(imgs)),size=int(len(imgs)*0.95), replace=False))\n",
    "\n",
    "test_set = torch.arange(len(imgs))\n",
    "for idx in train_set:\n",
    "    test_set = test_set[test_set != idx]\n",
    "\n",
    "\n",
    "print(f\"{train_set.shape[0]} train examples\")\n",
    "print(f\"{test_set.shape[0]} test examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcefa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_seg(moving_seg, flow):\n",
    "    \"\"\"\n",
    "    function to warp the segemntation of the teacher and baseline\n",
    "    \n",
    "    moving_seg: CxHxW\n",
    "    flow: size: BxCxHxW\n",
    "    \"\"\"\n",
    "    B, C, H, W = flow.size()\n",
    "    # mesh grid\n",
    "    xx = torch.arange(0, W).view(1, -1).repeat(H, 1)\n",
    "    yy = torch.arange(0, H).view(-1, 1).repeat(1, W)\n",
    "    xx = xx.view(1, 1, H, W).repeat(B, 1, 1, 1)\n",
    "    yy = yy.view(1, 1, H, W).repeat(B, 1, 1, 1)\n",
    "    grid = torch.cat((xx, yy), 1).float().to(flow.device)\n",
    "    \n",
    "    vgrid = grid + flow\n",
    "\n",
    "    # scale grid to [-1,1]\n",
    "    vgrid[:, 0, :, :] = 2.0 * vgrid[:, 0, :, :].clone() / max(W - 1, 1) - 1.0\n",
    "    vgrid[:, 1, :, :] = 2.0 * vgrid[:, 1, :, :].clone() / max(H - 1, 1) - 1.0\n",
    "\n",
    "    vgrid = vgrid.permute(0, 2, 3, 1)\n",
    "    warped_seg_grid = nn.functional.grid_sample(moving_seg.float().unsqueeze(0), vgrid)\n",
    "    return warped_seg_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cbce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet = FlowNet2()\n",
    "state_dict = torch.load(\"models/flownet2_pytorch/FlowNet2_checkpoint.pth.tar\")\n",
    "flownet.load_state_dict(state_dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994d71b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# freeze all parameters from the other blocks, except the fusion block\n",
    "for param in flownet.flownetc.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in flownet.flownets_1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in flownet.flownets_2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in flownet.flownets_d.parameters():\n",
    "    param.requires_grad = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41760aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf2be89",
   "metadata": {},
   "source": [
    "# Before finetuning\n",
    "Before fine tuning, we need to see the performance of the flownet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval Flownet\n",
    "def eval_flownet(model):\n",
    "    overall_dice = []\n",
    "    unwarped_dice = [] \n",
    "    scale=4\n",
    "    for i,idx in enumerate(test_set):\n",
    "\n",
    "        # Get image and segmentation\n",
    "        fixed = imgs[idx:idx+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[idx:idx+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[idx:idx+1,0,:].contiguous()\n",
    "        moving_seg = segs[idx:idx+1,1,:].contiguous()\n",
    "        \n",
    "        fixed = F.interpolate(fixed, size=(scale*64,scale*64), mode='bicubic')\n",
    "        moving = F.interpolate(moving, size=(scale*64,scale*64), mode='bicubic')\n",
    "        \n",
    "        fixed_seg = F.interpolate(fixed_seg.unsqueeze(0), size=(scale*64,scale*64), mode='bicubic')\n",
    "        moving_seg = F.interpolate(moving_seg.unsqueeze(0), size=(scale*64,scale*64), mode='bicubic')\n",
    "        \n",
    "        flow_in = preprocessing_flownet(fixed.detach().clone().reshape(scale*64,scale*64,1),moving.clone().reshape(scale*64,scale*64,1)).cuda()\n",
    "        \n",
    "        flow_out = flownet(flow_in)\n",
    "        \n",
    "        warped_seg = warp_seg(moving_seg.view(1,scale*64,scale*64).cuda(), flow_out).cpu()\n",
    "        \n",
    "        d1 = dice_coeff(warped_seg,fixed_seg,3)\n",
    "        d2 = dice_coeff(moving_seg, fixed_seg, 3)\n",
    "            \n",
    "        overall_dice.append(d1.mean())\n",
    "        unwarped_dice.append(d2.mean())\n",
    "        \n",
    "    overall_dice = torch.from_numpy(np.array(overall_dice))\n",
    "    unwarped_dice = torch.from_numpy(np.array(unwarped_dice))\n",
    "    \n",
    "    return overall_dice.mean(), unwarped_dice.mean()\n",
    "    #print(f\"This model has an average Dice of {round(overall_dice.mean().item(), 5)} mit Variance: {round(overall_dice.var().item(), 5)}. The unwarped Mean dice is: {round(unwarped_dice.mean().item(), 5)} with Var {round(unwarped_dice.var().item(),5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_flownet(flownet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "lr = 0.00001\n",
    "# minibatch training\n",
    "grad_accum = 30\n",
    "\n",
    "optimizer = torch.optim.Adam(list(flownet.parameters()),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "acc = []\n",
    "scale=4\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    rnd_train_idx = torch.randperm(train_set.size(0))\n",
    "\n",
    "    # show all examples to model\n",
    "    for i, rnd_idx in enumerate(rnd_train_idx):\n",
    "        tmp_loss = []\n",
    "        \n",
    "        p_fix = train_set[rnd_idx]\n",
    "\n",
    "        # Get image and segmentation\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].contiguous()\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].contiguous()\n",
    "        \n",
    "        fixed = F.interpolate(fixed, size=(scale*64,scale*64), mode='bicubic')\n",
    "        moving = F.interpolate(moving, size=(scale*64,scale*64), mode='bicubic')\n",
    "        \n",
    "        fixed_seg = F.interpolate(fixed_seg.unsqueeze(0), size=(scale*64,scale*64), mode='bicubic')\n",
    "        moving_seg = F.interpolate(moving_seg.unsqueeze(0), size=(scale*64,scale*64), mode='bicubic')\n",
    "        \n",
    "        flow_in = preprocessing_flownet(fixed.detach().clone().reshape(scale*64,scale*64,1),moving.clone().reshape(scale*64,scale*64,1)).cuda()\n",
    "        \n",
    "        flow_out = flownet(flow_in)\n",
    "        \n",
    "        warped_seg = warp_seg(moving_seg.view(1,scale*64,scale*64).cuda(), flow_out).cpu()\n",
    "        warped_seg_onehot = F.one_hot(warped_seg.long(),num_classes=2).float()\n",
    "        fixed_seg_onehot = F.one_hot(fixed_seg.long(), num_classes=2).float()\n",
    "        \n",
    "        loss = torch.sum(torch.pow(warped_seg-fixed_seg,2)).mean()\n",
    "        loss.backward()\n",
    "        tmp_loss.append(loss.item())\n",
    "    \n",
    "        \n",
    "    if (epoch+1)%grad_accum == 0:\n",
    "        # every grad_accum iterations :Make an optimizer step\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        d0 = []\n",
    "        for i,idx in enumerate(test_set):\n",
    "\n",
    "            # Get image and segmentation\n",
    "            fixed = imgs[idx:idx+1,0,:].unsqueeze(0).float()\n",
    "            moving = imgs[idx:idx+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "            fixed_seg = segs[idx:idx+1,0,:].contiguous()\n",
    "            moving_seg = segs[idx:idx+1,1,:].contiguous()\n",
    "\n",
    "            fixed = F.interpolate(fixed, size=(128,128), mode='bicubic')\n",
    "            moving = F.interpolate(moving, size=(128,128), mode='bicubic')\n",
    "\n",
    "            fixed_seg = F.interpolate(fixed_seg.unsqueeze(0), size=(128,128), mode='bicubic')\n",
    "            moving_seg = F.interpolate(moving_seg.unsqueeze(0), size=(128,128), mode='bicubic')\n",
    "\n",
    "            flow_in = preprocessing_flownet(fixed.detach().clone().reshape(128,128,1),moving.clone().reshape(128,128,1)).cuda()\n",
    "\n",
    "            flow_out = flownet(flow_in)\n",
    "\n",
    "            warped_seg = warp_seg(moving_seg.view(1,128,128).cuda(), flow_out).cpu()\n",
    "\n",
    "            d1 = dice_coeff(warped_seg,fixed_seg,3)\n",
    "            d0.append(d1.mean())\n",
    "    acc.append(np.mean(d0))\n",
    "    losses.append(np.mean(tmp_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(acc)), acc)\n",
    "plt.savefig('Flownet_finetune_acc_500epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265445ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(losses)), losses)\n",
    "plt.savefig('Flownet_finetune_loss_500epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_flownet(flownet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(flownet.state_dict(), \"flownet_finetuned_500.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5221e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0522c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
