{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6850c9e",
   "metadata": {},
   "source": [
    "# Flow refinement \n",
    "This notebook is not part of the Thesis!\n",
    "Here we try to refine the flow in a Flownet-C like manner. This is part of the future work section of the thesis.\n",
    "Unfortunately, I was not able to finish this in time.\n",
    "\n",
    "## General Ideal\n",
    "Take extracted features and concatenate them with the output flow. Then use an upsampling layer and concatenate the predicted flow again. Do this twice (to keep it light weights) and generate a flow ofsiez 150x150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from math import ceil\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.load_models import load_flownet2, load_pwcnet, init_weights\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp, warp_Flow\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "import torch.utils.checkpoint\n",
    "from models.pdd_net.pdd_student import OBELISK2d\n",
    "\n",
    "# Select a GPU for the work\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "available_gpus = [(torch.cuda.device(i),torch.cuda.get_device_name(i)) for i in range(torch.cuda.device_count())]\n",
    "print(available_gpus)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119cff6",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18edee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.load('/share/data_ultraschall/nicke_ma/data/train_frames_disp_6.pth')\n",
    "segs = torch.load('/share/data_ultraschall/nicke_ma/data/train_segs_disp_6.pth')\n",
    "\n",
    "test_imgs = torch.load('/share/data_ultraschall/nicke_ma/data/test_frames_disp_6.pth')\n",
    "test_segs = torch.load('/share/data_ultraschall/nicke_ma/data/test_segs_disp_6.pth')\n",
    "#imgs = torch.rand(40,2,150,150)\n",
    "#segs = torch.rand(40,2,150,150)\n",
    "\n",
    "train_set = torch.arange(len(imgs))\n",
    "test_set = torch.arange(len(test_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef02c8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OBELISK2d(nn.Module):\n",
    "    def __init__(self, chan=16, size=(150,150)):\n",
    "        super(OBELISK2d, self).__init__()\n",
    "        channels = chan\n",
    "        self.offsets = nn.Parameter(torch.randn(2, channels * 2, 2) * 0.05)\n",
    "        self.layer0 = nn.Conv2d(1, 4, 5, stride=2, bias=False, padding=2)\n",
    "        self.batch0 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.layer1 = nn.Conv2d(channels * 8, channels * 4, 1, bias=False,\n",
    "                                groups=1)\n",
    "        self.batch1 = nn.BatchNorm2d(channels * 4)\n",
    "        self.layer2 = nn.Conv2d(channels * 4, channels * 4, 3, bias=False,\n",
    "                                padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(channels * 4)\n",
    "        self.layer3 = nn.Conv2d(channels * 4, channels * 1, 1)\n",
    "\n",
    "        H = size[0]\n",
    "        W = size[1]\n",
    "        self.o_m = H // 4 +1\n",
    "        self.o_n = W // 4 +1\n",
    "\n",
    "        self.displace_range = 11\n",
    "        self.disp_hw = 5\n",
    "        self.ogrid_xy = F.affine_grid(torch.eye(2, 3).unsqueeze(0),\n",
    "                                 (1, 1, self.o_m, self.o_n)).view(1, 1, -1, 2).cuda()\n",
    "        self.disp_range = 0.25\n",
    "        self.displacement_width = 11\n",
    "        shift_xy = F.affine_grid(self.disp_range * torch.eye(2, 3).unsqueeze(0), (1, 1, self.displacement_width, self.displacement_width)).view(1, 1, -1, 2).cuda()\n",
    "        grid_size = 32  # 25#30\n",
    "        self.grid_xy = F.affine_grid(torch.eye(2, 3).unsqueeze(0),\n",
    "                                (1, 1, grid_size, grid_size)).view(1, -1, 1,\n",
    "                                                                   2).cuda()\n",
    "\n",
    "    def forward(self, fixed_img, moving_img):\n",
    "        img_in_f = F.avg_pool2d(fixed_img, 3, padding=1, stride=2)\n",
    "        img_in_f = F.relu(self.batch0(self.layer0(img_in_f)))\n",
    "        sampled_f = F.grid_sample(img_in_f,self.ogrid_xy + self.offsets[0, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "        sampled_f -= F.grid_sample(img_in_f,self.ogrid_xy + self.offsets[1, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "\n",
    "        x_1_1 = F.relu(self.batch1(self.layer1(sampled_f)))\n",
    "        x_1_2 = F.relu(self.batch2(self.layer2(x_1_1)))\n",
    "        features_fixed = self.layer3(x_1_2)\n",
    "        \n",
    "        img_in_m = F.avg_pool2d(moving_img, 3, padding=1, stride=2)\n",
    "        img_in_m = F.relu(self.batch0(self.layer0(img_in_m)))\n",
    "        sampled_m = F.grid_sample(img_in_m,self.ogrid_xy + self.offsets[0, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "        sampled_m -= F.grid_sample(img_in_m,self.ogrid_xy + self.offsets[1, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "\n",
    "        x_2_1 = F.relu(self.batch1(self.layer1(sampled_m)))\n",
    "        x_2_2 = F.relu(self.batch2(self.layer2(x_2_1)))\n",
    "        features_moving = self.layer3(x_2_2)\n",
    "\n",
    "        ssd_distance = self.correlation_layer(features_moving, features_fixed)\n",
    "        soft_cost,disp_xy = self.meanfield(ssd_distance, fixed_img, self.displace_range, self.o_m, self.o_n)\n",
    "        \n",
    "        return disp_xy, x_1_1, x_1_2\n",
    "\n",
    "\n",
    "    def min_convolution(self, ssd_distance, displace_range, H, W):\n",
    "        # Prepare operators for smooth dense displacement space\n",
    "        pad1 = nn.ReplicationPad2d(5)\n",
    "        avg1 = nn.AvgPool2d(5, stride=1)\n",
    "        max1 = nn.MaxPool2d(3, stride=1)\n",
    "        pad2 = nn.ReplicationPad2d(4)\n",
    "        # approximate min convolution / displacement compatibility\n",
    "\n",
    "        ssd_minconv = avg1(avg1(-max1(-pad1(\n",
    "            ssd_distance.permute(0, 2, 3, 1).reshape(1, -1, self.displace_range,\n",
    "                                                    self.displace_range)))))\n",
    "\n",
    "        ssd_minconv = ssd_minconv.permute(0, 2, 3, 1).view(1, -1, H, W)\n",
    "        min_conv_cost = avg1(avg1(pad2(ssd_minconv)))\n",
    "\n",
    "        return min_conv_cost\n",
    "\n",
    "\n",
    "    def meanfield(self, ssd_distance, img_fixed, displace_range, H, W):\n",
    "        crnt_dev = ssd_distance.device\n",
    "\n",
    "        cost = self.min_convolution(ssd_distance, displace_range, H, W)\n",
    "\n",
    "        soft_cost = F.softmax(-10 * cost.view(displace_range ** 2, -1).t(), 1)\n",
    "\n",
    "        disp_hw = (displace_range - 1) // 2\n",
    "        disp_mesh_grid = disp_hw * F.affine_grid(torch.eye(2, 3).unsqueeze(0), (\n",
    "        1, 1, displace_range, displace_range), align_corners=True)\n",
    "        disp_mesh_grid /= torch.Tensor([(W - 1) * .5, (H - 1) * .5])\n",
    "\n",
    "        disp_xy = torch.sum(\n",
    "            soft_cost.view(1, H, W, -1, 1) * disp_mesh_grid.view(1, 1, 1, -1,\n",
    "                                                                2).to(crnt_dev),\n",
    "            3).permute(0, 3, 1, 2)\n",
    "\n",
    "        return soft_cost, disp_xy\n",
    "\n",
    "\n",
    "    def correlation_layer(self, feat_moving, feat_fixed):\n",
    "        disp_hw = (self.displacement_width - 1) // 2\n",
    "        feat_moving_unfold = F.unfold(feat_moving.transpose(1, 0),\n",
    "                                    (self.displace_range, self.displace_range),\n",
    "                                    padding=self.disp_hw)\n",
    "        B, C, H, W = feat_fixed.size()\n",
    "\n",
    "        ssd_distance = ((feat_moving_unfold - feat_fixed.view(C, 1, -1)) ** 2).sum(0).view(1, displace_range ** 2, H, W)\n",
    "\n",
    "        return ssd_distance\n",
    "\n",
    "\n",
    "\n",
    "class PDD2D(nn.Module):\n",
    "    def __init__(self, chan=16, size=(150,150)):\n",
    "        super(PDD2D, self).__init__()\n",
    "        \n",
    "        self.feat_extractor = OBELISK2d(chan)\n",
    "        path_to_state_dict = f'models/Experiment_2/fineTuneSoft/soft_trained.pth'\n",
    "        self.feat_extractor.load_state_dict(torch.load(path_to_state_dict))\n",
    "        self.feat_extractor.cuda()\n",
    "\n",
    "        H = size[0]\n",
    "        W = size[1]\n",
    "        \n",
    "        self.identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "\n",
    "\n",
    "        self.deconv_1 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(\n",
    "                            128,\n",
    "                            62,\n",
    "                            kernel_size=4,\n",
    "                            stride=2,\n",
    "                            padding=1,\n",
    "                            bias=True), nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.deconv_2 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(\n",
    "                            64,\n",
    "                            32,\n",
    "                            kernel_size=4,\n",
    "                            stride=2,\n",
    "                            padding=1,\n",
    "                            bias=True), nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.upsamp_1 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=True)\n",
    "        self.upsamp_2 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=True)\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(64, 2, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.out = nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "        #self.out = nn.Conv2d(2, 2, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        \n",
    "\n",
    "    def forward(self, fixed_img, moving_img):\n",
    "       \n",
    "        disp_xy, x_1_1, x_2_1 = self.feat_extractor(fixed_img.cuda(), moving_img.cuda())\n",
    "        \n",
    "        concat_1 = torch.cat((x_1_1, x_2_1), dim=1)\n",
    "        #print(\"concat: \", concat_1.shape)\n",
    "        out_deconv_1 = self.deconv_1(concat_1)\n",
    "        #print(\"deconv: \", out_deconv_1.shape)\n",
    "        up_flow_1 = self.upsamp_1(disp_xy)\n",
    "        #print(\"up_1 : \", up_flow_1.shape)\n",
    "\n",
    "        concat_2 = torch.cat((out_deconv_1, up_flow_1), dim=1)\n",
    "        flow_1 = self.conv_1(concat_2)\n",
    "        #print(\"Flow1: \", flow_1.shape)\n",
    "        \n",
    "\n",
    "        up_flow_2 = self.upsamp_2(flow_1)\n",
    "        #print(\"flow2: \", up_flow_2.shape)\n",
    "        out = self.out(up_flow_2)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8393ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_hw = 5\n",
    "displace_range = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_weights = torch.tensor([0.1,0.6, 0.3])# weights for background = 0.1, Vein = 0.6 and Artery = 0.3\n",
    "epochs = 100\n",
    "lr = 0.0005\n",
    "\n",
    "H=150;W=150\n",
    "\n",
    "model = PDD2D()\n",
    "for param in model.feat_extractor.parameters():\n",
    "    param.require_grad=False\n",
    "model.train().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.parameters()),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b9b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "unwarped = []\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False)#.cuda()\n",
    "\n",
    "for epoch in trange(epochs, desc='epoch Loop', leave=False):\n",
    "    model.train()\n",
    "    # Shuffle Data\n",
    "    #train_set_perm = torch.randperm(len(train_set))\n",
    "    #train_set = train_set[train_set_perm]\n",
    "    # show all examples to model\n",
    "    for i in trange(3, desc='Train Loop', leave=False):\n",
    "        \n",
    "        rnd_idx = train_set[i]\n",
    "        p_fix = train_set[rnd_idx]\n",
    "        tmp_loss = torch.zeros(3)\n",
    "\n",
    "        # Get image and segmentation\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float() \n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].contiguous() * 2\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].contiguous() * 2\n",
    "\n",
    "            \n",
    "        pred = model(fixed.cuda(), moving.cuda()).cpu()\n",
    "        moving_onehot = F.one_hot(moving_seg.long(), num_classes=3).float()\n",
    "        # warp loss\n",
    "        warped = warp(fixed_seg.unsqueeze(0).float(), pred)\n",
    "        #warped = F.grid_sample(fixed_seg.unsqueeze(0).float(), identity+pred.permute(0,2,3,1))\n",
    "        warp_loss = torch.sum(torch.pow(warped - moving_seg, 2)).mean()\n",
    "        \n",
    "        diffloss = 2.5*((pred[0,:,1:,:]-pred[0,:,:-1,:])**2).mean()+\\\n",
    "            2.5*((pred[0,1:,:,:]-pred[0,:-1,:,:])**2).mean()+\\\n",
    "            2.5*((pred[0,:,:,1:]-pred[0,:,:,:-1])**2).mean()\n",
    "        \n",
    "        loss = warp_loss + diffloss\n",
    "        loss.backward()\n",
    "        tmp_loss[i] = loss.item()\n",
    "        \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    losses.append(tmp_loss.mean().item())   \n",
    "    tmp_acc = []\n",
    "    for j in trange(1, desc=\"Eval loop\", leave=False):\n",
    "        p_fix = train_set[j]\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float() \n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].contiguous() * 2\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].contiguous() * 2\n",
    "        \n",
    "        pred = model(fixed.cuda(), moving.cuda()).cpu()\n",
    "        #warped_seg = F.grid_sample(fixed_seg.unsqueeze(0).float(), identity+pred.permute(0,2,3,1))\n",
    "        warped_seg = warp(fixed_seg.unsqueeze(0).float(), pred)\n",
    "        \n",
    "        d0 = dice_coeff(warped_seg,moving_seg,3)\n",
    "        print(d0)\n",
    "        tmp_acc.append(d0.mean().item())\n",
    "    accs.append(np.mean(tmp_acc))\n",
    "    #print(np.mean(tmp_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca32031",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs), losses, label='Loss')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig('plots/refine_1-test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaf3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(showFlow(pred.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066adb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(other_warped_seg.detach().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "accs = torch.zeros(len(test_set), 2)\n",
    "un = torch.zeros(len(test_set), 2)\n",
    "for j in trange(len(test_set), desc=\"Eval loop\", leave=False):\n",
    "        p_fix = test_set[j]\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float() \n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].contiguous() * 2\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].contiguous() * 2\n",
    "        \n",
    "        pred = eval_model(moving.cuda(), fixed.cuda(), fixed_seg.cuda()).cpu()\n",
    "        \n",
    "        warped_seg = warp(fixed_seg.unsqueeze(0).float(), pred)\n",
    "        \n",
    "        d0 = dice_coeff(warped_seg,moving_seg,3)\n",
    "        d1 = dice_coeff(fixed_seg,moving_seg,3)\n",
    "        \n",
    "        accs[j] = d0\n",
    "        un[j] = d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70042de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f659a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183fe64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b3a633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195550d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdcfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78382eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9cd7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict, 'models/refine_300.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e187bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ecc131",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3378f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = PDD2D()\n",
    "eval_model.load_state_dict(torch.load('models/refine_300.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18111328",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model.eval().cuda()\n",
    "accs = torch.zeros(len(test_set), 2)\n",
    "un = torch.zeros(len(test_set), 2)\n",
    "for j in trange(len(test_set), desc=\"Eval loop\", leave=False):\n",
    "        p_fix = test_set[j]\n",
    "        fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float() \n",
    "        moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[p_fix:p_fix+1,0,:].contiguous() * 2\n",
    "        moving_seg = segs[p_fix:p_fix+1,1,:].contiguous() * 2\n",
    "        \n",
    "        pred = eval_model(moving.cuda(), fixed.cuda(), fixed_seg.cuda()).cpu()\n",
    "        \n",
    "        warped_seg = warp(fixed_seg.unsqueeze(0).float(), pred)\n",
    "        \n",
    "        d0 = dice_coeff(warped_seg,moving_seg,3)\n",
    "        d1 = dice_coeff(fixed_seg,moving_seg,3)\n",
    "        \n",
    "        accs[j] = d0\n",
    "        un[j] = d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd55fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "un.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61e7e9",
   "metadata": {},
   "source": [
    "## Eval on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_id(model, frames, segs, last_segment_available):\n",
    "    distance_between_frames = 6\n",
    "    \n",
    "    dice = torch.zeros(len(frames), 2)\n",
    "    hd = torch.zeros(len(frames), 2)\n",
    "    \n",
    "    for i, frame in enumerate(frames):\n",
    "\n",
    "        # skipp first X frames\n",
    "        if i < distance_between_frames:\n",
    "            continue\n",
    "            \n",
    "        if i-distance_between_frames <= last_segment_available:\n",
    "            fixed = torch.clone(frames[i- distance_between_frames])\n",
    "            fixed_seg = torch.clone(segs[i-distance_between_frames])\n",
    "    \n",
    "        if i-distance_between_frames > last_segment_available:\n",
    "            fixed = torch.clone(frames[last_segment_available])\n",
    "            fixed_seg = torch.clone(segs[last_segment_available])\n",
    "            \n",
    "        moving = torch.clone(frames[i])\n",
    "        moving_seg = torch.clone(segs[i])\n",
    "        \n",
    "        # not segmentation available in this seg\n",
    "        if moving_seg.max().item() == 0.:\n",
    "            continue\n",
    "        \n",
    "        pred = eval_model(moving.cuda(), fixed.cuda(), fixed_seg.cuda()).cpu()\n",
    "        \n",
    "        warped_seg = warp(moving_seg.unsqueeze(0).float(), pred)\n",
    "        \n",
    "        d0 = dice_coeff(warped_seg,moving_seg,3)\n",
    "        d1 = dice_coeff(fixed_seg,moving_seg,3)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
