{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed6a46c",
   "metadata": {},
   "source": [
    "# Creation of evaluation data\n",
    "never really used in the experiments! \n",
    "There is no storing of any data in this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb982d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the quality overview\n",
    "quality = pd.read_csv(\"~/MasterThesis/quality.csv\")\n",
    "\n",
    "# More info about the sequences\n",
    "sequences = pd.read_csv(\"~/MasterThesis/sequences.csv\")\n",
    "\n",
    "# filter based on the table above\n",
    "useable = quality[\n",
    "    #(quality[\"Vessel in Frame\"] <3) &\n",
    "    #(quality['LM configuration'] < 4) &\n",
    "    #(quality['Vein contrast/cropping error'] < 3) &\n",
    "    #(quality['Artery contrast'] < 3) &\n",
    "    #(quality['Vein boundary'] < 3) &\n",
    "    #(quality['Artery boundary'] < 3) &\n",
    "    #(quality['Gain'] == 1) &\n",
    "    #(quality['Artefacts'] < 3) &\n",
    "    #(quality['Movement'] < 3) &\n",
    "    (quality['Total'] < 20)\n",
    "]\n",
    "useable.rename(columns={'ID': 'Id'}, inplace=True)\n",
    "useable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0971ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [124,\n",
    "413,\n",
    "419,\n",
    "524,\n",
    "545,\n",
    "209,\n",
    "216,\n",
    "456,\n",
    "420,\n",
    "546,\n",
    "214,\n",
    "304,\n",
    "316,\n",
    "418,\n",
    "523,\n",
    "543,\n",
    "544,\n",
    "549,\n",
    "601,\n",
    "610,\n",
    "626,\n",
    "667,\n",
    "668,\n",
    "692,\n",
    "752,\n",
    "772,\n",
    "773,\n",
    "1046,\n",
    "1048,\n",
    "1092,\n",
    "1122,\n",
    "1123,\n",
    "1145,\n",
    "172,\n",
    "176,\n",
    "177,\n",
    " 184,\n",
    " 211,\n",
    " 219,\n",
    " 246,\n",
    " 307,\n",
    " 341,\n",
    " 349,\n",
    " 353,\n",
    " 354,\n",
    " 384,\n",
    " 402,\n",
    " 408,\n",
    " 416,\n",
    " 426,\n",
    " 442,\n",
    " 452,\n",
    " 457,\n",
    " 467,\n",
    " 486,\n",
    " 515,\n",
    " 521,\n",
    " 526,\n",
    " 542,\n",
    " 553,\n",
    " 563,\n",
    " 573,\n",
    " 578,\n",
    " 584,\n",
    " 599,\n",
    " 1055,\n",
    " 1065,\n",
    " 1072,\n",
    " 1082,\n",
    " 1091,\n",
    " 1097,\n",
    " 1098,\n",
    " 1101,\n",
    " 1111,\n",
    " 1128,\n",
    " 1131,\n",
    " 1141,\n",
    " 1146,\n",
    " 1148,\n",
    " 1149,\n",
    " 1150,\n",
    " 1156,\n",
    " 1164,\n",
    " 1166,\n",
    " 1168,\n",
    " 1169,\n",
    " 1301,\n",
    " 1311,\n",
    " 1314,\n",
    " 4,\n",
    " 9,\n",
    " 10,\n",
    " 12,\n",
    " 13,\n",
    " 17,\n",
    " 20,\n",
    " 21,\n",
    " 25,\n",
    " 28,\n",
    " 29,\n",
    " 33,\n",
    " 34,\n",
    " 36,\n",
    " 42,\n",
    " 58,\n",
    " 59,\n",
    " 61,\n",
    " 67,\n",
    " 68,\n",
    " 70,\n",
    " 75,\n",
    " 78,\n",
    " 79,\n",
    " 84,\n",
    " 100,\n",
    " 106,\n",
    " 107,\n",
    " 109,\n",
    " 113,\n",
    " 114,\n",
    " 115,\n",
    " 116,\n",
    " 117,\n",
    " 118,\n",
    " 120,\n",
    " 121,\n",
    " 122,\n",
    " 123,\n",
    " 125,\n",
    " 126,\n",
    " 127,\n",
    " 128,\n",
    " 130,\n",
    " 135,\n",
    " 136,\n",
    " 137,\n",
    " 140,\n",
    " 146,\n",
    " 147,\n",
    " 151,\n",
    " 169,\n",
    " 2709,\n",
    " 2709,\n",
    " 2710,\n",
    " 2710,\n",
    " 2713,\n",
    " 2713,\n",
    " 2714,\n",
    " 2714,\n",
    " 2733,\n",
    " 2733,\n",
    " 2754,\n",
    " 2758,\n",
    " 2761,\n",
    " 2765,\n",
    " 2765,\n",
    " 2766,\n",
    " 4774,\n",
    " 4775,\n",
    " 4778,\n",
    " 4781,\n",
    " 4796,\n",
    " 4798,\n",
    " 4799,\n",
    " 4801,\n",
    " 4804,\n",
    " 4808,\n",
    " 4810,\n",
    " 4813,\n",
    " 4814,\n",
    " 4825,\n",
    " 4834,\n",
    " 4856,\n",
    " 2185,\n",
    " 2187,\n",
    " 2199,\n",
    " 1627,\n",
    " 1643,\n",
    " 1354,\n",
    " 1352,\n",
    " 1366,\n",
    " 844,\n",
    " 1367,\n",
    " 1667,\n",
    " 913,\n",
    " 1668,\n",
    " 917,\n",
    " 918,\n",
    " 1669,\n",
    " 1671,\n",
    " 1673,\n",
    " 1676,\n",
    " 931,\n",
    " 934,\n",
    " 1015,\n",
    " 1723,\n",
    " 1452,\n",
    " 1464,\n",
    " 1462,\n",
    " 1526,\n",
    " 1616,\n",
    " 2065,\n",
    " 2141,\n",
    " 2143,\n",
    " 977,\n",
    " 1693,\n",
    " 1715,\n",
    " 1733,1735,1741,1497,1506,1519,1620,986,929,968,859,861,906,908,910,956,962,919,903,905,921,922,943,944,946,947,965,975,997,998,1778,2829,2830,2831,2732,2736,2841,2866,2867,2868,2874,2875,2764, 2885]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a98eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_IDs = useable[~useable.Id.isin(train_ids)].Id.to_numpy()\n",
    "test_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"/share/data_ultraschall/compressions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8efcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_with_segs = []\n",
    "for test_id in test_IDs:\n",
    "    id_path = os.path.join(path_to_data, str(int(test_id)), \"segmentations\", \"1\")\n",
    "    if os.path.isdir(id_path):\n",
    "        if len(os.listdir(id_path)) != 0:\n",
    "            ids_with_segs.append(test_id)\n",
    "\n",
    "ids_with_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ids = np.random.choice(ids_with_segs,30, replace=False)\n",
    "selected_ids = selected_ids.astype(np.int32)\n",
    "selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(selected_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ids of available patients\n",
    "available = pd.read_csv(\"/home/nicke/MasterThesis/available_US_probands.csv\")\n",
    "available = available.drop('Unnamed: 0', axis=1)\n",
    "available = available[available['Anatomy'] != 'BACKGROUND']\n",
    "available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d90710",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/share/data_ultraschall/compressions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = pd.read_csv('/home/nicke/MasterThesis/landmarks.csv')\n",
    "landmarks = landmarks[(landmarks['Start Frames'] != '[]') & (landmarks['End Frames'] != '[]')& (landmarks['End Frames'] != 'DNC')]\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = landmarks.merge(available, on='Id')\n",
    "id_list = (data.Id.values).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c73e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_seg(path, image):\n",
    "    \n",
    "    # load image with PIL and normalize\n",
    "    img = np.array(Image.open(os.path.join(path,\"frames\", image))) / 255\n",
    "    #print(os.path.join(path,\"frames\", image))\n",
    "    #print(os.path.join(path,\"segmentations\", \"1\", image))\n",
    "    \n",
    "    # load seg and normalize over the labels\n",
    "    seg =np.array(Image.open(os.path.join(path,\"segmentations\", \"1\", image))) / 200\n",
    "    \n",
    "    return img, seg\n",
    "\n",
    "def get_image_seg_pairs(prob_id):\n",
    "    \n",
    "    \n",
    "    print(f\"Working on id: {prob_id}\")\n",
    "    all_frames = sorted(os.listdir(os.path.join(path_to_data,prob_id,\"frames\")))\n",
    "\n",
    "    first_available_frame = np.fromstring(landmarks[landmarks['Id']== int(prob_id)]['Start Frames'].iat[0].strip(']['), sep=',', dtype=int)\n",
    "    last_available_frame = np.fromstring(landmarks[landmarks['Id']== int(prob_id)]['End Frames'].iat[0].strip(']['), sep=',', dtype=int)\n",
    "    file_pairs = []\n",
    "    for j,f_frame in enumerate(first_available_frame):\n",
    "        i = 6\n",
    "        while f_frame + i < last_available_frame[j]:\n",
    "            file_pairs.append([all_frames[f_frame], all_frames[f_frame+i]])\n",
    "            i = i+6\n",
    "            if len(file_pairs) > 6:\n",
    "                break\n",
    "    \n",
    "    frame_pairs = []\n",
    "    seg_pairs = []\n",
    "    \n",
    "    # load the seg and frame for fixed and moving\n",
    "    for fixed_file, moving_file in file_pairs:\n",
    "        \n",
    "        fixed, fixed_seg = load_image_and_seg(os.path.join(path_to_data, prob_id), fixed_file)\n",
    "        moving, moving_seg = load_image_and_seg(os.path.join(path_to_data, prob_id), moving_file)\n",
    "        \n",
    "        if fixed_seg.max() == 0:\n",
    "            continue\n",
    "        if moving_seg.max() == 0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # and store them together\n",
    "        frame_pairs.append([fixed,moving])\n",
    "        seg_pairs.append([fixed_seg,moving_seg])\n",
    "    \n",
    "    return np.array(frame_pairs), np.array(seg_pairs)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "segs = []\n",
    "ids = []\n",
    "for prob_id in id_list:\n",
    "\n",
    "    frame_pairs, seg_pairs = get_image_seg_pairs(prob_id)\n",
    "    \n",
    "    for pair in frame_pairs:\n",
    "        frames.append(pair)\n",
    "    for pair in seg_pairs:\n",
    "        segs.append(pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
