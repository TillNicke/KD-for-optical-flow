{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b87790",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "this file is used to get an overview over the files, that are on the IMI server. Included .csv files are loaded and used to determine which probands can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc75ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "#from utils.plotting import flow2img, overlaySegment\n",
    "#from utils.encoding import dice_coeff\n",
    "#from utils.layers import warp, warpImage\n",
    "#from utils.load_models import load_flownet2\n",
    "#from utils.preprocessing import preprocessing_flownet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1956fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files are located here\n",
    "path_to_data = \"/share/data_ultraschall/compressions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(path_to_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually, but somewhat random selected to see the image quality\n",
    "test_dir = os.path.join(path_to_data, \"157\")\n",
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get two random images \n",
    "random_frames = np.random.choice(os.listdir(os.path.join(test_dir,\"frames\")), 2)\n",
    "random_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ef96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and segmentations\n",
    "img_1 = Image.open(os.path.join(test_dir,\"frames\",random_frames[0]))\n",
    "img_2 = Image.open(os.path.join(test_dir,\"frames\",random_frames[1]))\n",
    "\n",
    "seg_1 = Image.open(os.path.join(test_dir,\"segmentations\",\"1\",random_frames[0]))\n",
    "seg_2 = Image.open(os.path.join(test_dir,\"segmentations\",\"1\",random_frames[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(img_1)\n",
    "plt.subplot(222)\n",
    "plt.imshow(seg_1)\n",
    "plt.subplot(223)\n",
    "plt.imshow(img_2)\n",
    "plt.subplot(224)\n",
    "plt.imshow(seg_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2bf16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images need to be normalized\n",
    "print(np.array(img_1).max())\n",
    "\n",
    "# segmentations have labels of 0,1,2 and will be divided by 100\n",
    "print(np.array(seg_1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a24c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(overlaySegment(torch.from_numpy(np.array(img_1))/255,torch.from_numpy(np.array(seg_1))/100))\n",
    "plt.subplot(122)\n",
    "plt.imshow(overlaySegment(torch.from_numpy(np.array(img_2))/255,torch.from_numpy(np.array(seg_2))/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c8ab8",
   "metadata": {},
   "source": [
    "In order to get the right label for the segmentation, we need to divide the seg image by 100, as the labels are read in as 0, 100, and 200. the image needs to be devided by 255 to get float numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00208468",
   "metadata": {},
   "source": [
    "# Plotting from randomly from all folders\n",
    "there ar around 3000 recordings and about 250.000 images with segmentations. There will need to be a selection of images taken. Maybe 1500 or 2000 images and segmentations overall. The distribution of the three markers should be 1/3 for each scan location. For this we need an overview over the different recordings. This is included in the quality.csv and sequences.csv files in the cocoAi filder..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the quality overview\n",
    "quality = pd.read_csv(\"~/MasterThesis/quality.csv\")\n",
    "\n",
    "# More info about the sequences\n",
    "sequences = pd.read_csv(\"~/MasterThesis/sequences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeac1e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b308ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1cedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# somewhat even\n",
    "sequences['Leg'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c3a91",
   "metadata": {},
   "source": [
    "There are some things, that need to be fulfilled in orer for the sequence to be used for training. The table below sums up all the different Columns and what needs to be fulfilled in order to use the ID for the training\n",
    "\n",
    "| Quality Description | useable Index | Description |\n",
    "|---|---|---|\n",
    "|Vessel boundary| 1,2| Vessel partially cut of or fully visible during frames|\n",
    "|LM configuration| 1,2| Landmarks are somewhat present for flow estimation|\n",
    "|Vein contrast| 1,2 | some loss of contrast, but still visible|\n",
    "|Artery contrast| 1,2 | some loss of contrast, but stil visible|\n",
    "|shaprnes of Vein boundaries| 1,2 | up until poorly visible boundaries, We try to learn the overall flow|\n",
    "|shaprnes of artery boundaries| 1,2 | up until poorly visible boundaries, We try to learn the overall flow|\n",
    "|Overall gain| 1 | only good images are taken. Not too bright or too dark|\n",
    "|artefacts| 1,2 | some aftefacts are present in the some frames|\n",
    "| Movement Sequence| 1,2| Exclude \"lot's\" of movement for now. The other indicate some slow or fast compression of the vein|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f8f190",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filter based on the table above\n",
    "useable = quality[\n",
    "    #(quality[\"Vessel in Frame\"] <3) &\n",
    "    #(quality['LM configuration'] < 4) &\n",
    "    #(quality['Vein contrast/cropping error'] < 3) &\n",
    "    #(quality['Artery contrast'] < 3) &\n",
    "    #(quality['Vein boundary'] < 3) &\n",
    "    #(quality['Artery boundary'] < 3) &\n",
    "    #(quality['Gain'] == 1) &\n",
    "    #(quality['Artefacts'] < 3) &\n",
    "    #(quality['Movement'] < 3) &\n",
    "    (quality['Total'] < 20)\n",
    "]\n",
    "useable.rename(columns={'ID': 'Id'}, inplace=True)\n",
    "useable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01736d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filter based on useable\n",
    "#overview = sequences[sequences.Id.isin(useable.ID.tolist())]\n",
    "overview = sequences.merge(useable, on='Id')\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86354e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many of the selected IDs are available as data\n",
    "overview_clean = overview[overview['Id'].astype(str).isin(os.listdir(path_to_data))]\n",
    "overview_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0616243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an overview. all seems to be fine.\n",
    "print(overview_clean['Leg'].value_counts())\n",
    "print(overview_clean['Device'].value_counts())\n",
    "print(overview_clean['Datatype'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all IDs available as segmented data?\n",
    "available_seg = []\n",
    "for proband in overview_clean['Id'].values:\n",
    "    proband_path = os.path.join(path_to_data,str(proband))\n",
    "    if \"segmentations\" in os.listdir(proband_path):\n",
    "        available_seg.append(proband)\n",
    "len(available_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter based on segmentation available\n",
    "overview_available = overview_clean[overview_clean['Id'].isin(available_seg)]\n",
    "overview_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35565b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sest random seed so we can come back and examine the data\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 4 to visualize\n",
    "random_selected_ids = np.random.choice(overview_available['Id'].values, size=6)\n",
    "random_selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to make the plotting easier\n",
    "def create_plots(img_path, seg_path):\n",
    "    img = Image.open(img_path)#/255 # normalize\n",
    "    seg = Image.open(seg_path)#/100 # create labels\n",
    "    \n",
    "    return overlaySegment(torch.from_numpy(np.array(img))/255,torch.from_numpy(np.array(seg))/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53322e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "for proband in random_selected_ids:\n",
    "    proband_path = os.path.join(path_to_data,str(proband))\n",
    "    \n",
    "    # sort all images, to select fixed and moving image\n",
    "    # the fixed will be randomly selected\n",
    "    # and the moving will be X images further or before\n",
    "    all_files = sorted(os.listdir(os.path.join(proband_path,\"frames\")))\n",
    "    rand_idx = np.random.(0,lrandinten(all_files), size=2)\n",
    "    file_idx = []\n",
    "    for idx in rand_idx:\n",
    "        \n",
    "        # The time intervall atm is 4 images\n",
    "        moving_idx = idx + 4\n",
    "        if moving_idx > len(all_files)-1:\n",
    "            moving_idx = idx - 4\n",
    "            if moving_idx < 0:\n",
    "                moving_idx = 0\n",
    "\n",
    "        file_idx.append([all_files[idx],all_files[moving_idx]])\n",
    "        \n",
    "    plots.append([\n",
    "        create_plots(os.path.join(proband_path,\"frames\",file_idx[0][0]),\n",
    "                    os.path.join(proband_path,\"segmentations\",\"1\",file_idx[0][0])),\n",
    "        create_plots(os.path.join(proband_path,\"frames\",file_idx[0][1]),\n",
    "                    os.path.join(proband_path,\"segmentations\",\"1\",file_idx[0][1]))\n",
    "    ])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7baf348",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(plots[0][0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(plots[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(plots[1][0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(plots[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(plots[2][0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(plots[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b266466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(plots[3][0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(plots[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c105db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(plots[4][0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(plots[4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(plots[5][0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(plots[5][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d5d23d",
   "metadata": {},
   "source": [
    "# Processing\n",
    "Next step is to load all images and save them in a .pth file, to load them later. This will be done in the US_data_processing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_available.to_csv(\"~/MasterThesis/available_US_probands.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24caff",
   "metadata": {},
   "source": [
    "# Flow Estimation Tests for visualization. \n",
    "This part of the notebook includes some tests on how to vizualize the optical flow fields and what is the best way to warp segementations. \n",
    "\n",
    "Most of the tests failed :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e56acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = cv2.optflow.DualTVL1OpticalFlow_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img_1)[:,:,np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "in1 = np.array(img_1)[:,:,np.newaxis].astype(np.float32) / 255\n",
    "in2 = np.array(img_2)[:,:,np.newaxis].astype(np.float32) / 255\n",
    "flow = baseline.calc(in1,in2,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9581b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(131)\n",
    "plt.imshow(in1)\n",
    "plt.subplot(132)\n",
    "plt.imshow(flow2img(flow))\n",
    "plt.subplot(133)\n",
    "plt.imshow(in2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flow = torch.from_numpy(flow)\n",
    "seg = torch.from_numpy(np.asarray(seg_1)).long().contiguous() /200\n",
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3088c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow=torch.from_numpy(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a198c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = F.grid_sample(seg.unsqueeze(0).unsqueeze(0),flow.unsqueeze(0).reshape(1,150,150,2),mode='nearest',align_corners=False)\n",
    "warped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warped_1 = warp(seg.unsqueeze(0).unsqueeze(0), flow.view(1,2,150,150))\n",
    "warped_2 = warpImage(seg.view(1,1,150,150).float(), flow.view(1,2,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaySegment(gray1,seg1,flag=False):\n",
    "    H, W = seg1.squeeze().size()\n",
    "    colors=torch.FloatTensor([0,0,0,199,67,66,225,140,154,78,129,170,45,170,170,240,110,38,111,163,91,235,175,86,202,255,52,162,0,183]).view(-1,3)/255.0\n",
    "    segs1 = labelMatrixOneHot(seg1.unsqueeze(0),3)\n",
    "\n",
    "    \n",
    "    seg_color = torch.mm(segs1.view(3,-1).t(),colors[:3,:]).view(H,W,3)\n",
    "    alpha = torch.clamp(1.0 - 0.5*(seg1>0).float(),0,1.0)\n",
    "\n",
    "    overlay = (gray1*alpha).unsqueeze(2) + seg_color*(1.0-alpha).unsqueeze(2)\n",
    "    if(flag):\n",
    "        plt.imshow((overlay).numpy())\n",
    "        plt.show()\n",
    "    return overlay\n",
    "\n",
    "def labelMatrixOneHot(segmentation, label_num):\n",
    "    B, H, W = segmentation.size()\n",
    "    values = segmentation.view(B,1,H,W).expand(B,label_num,H,W).to(segmentation.device)\n",
    "    linspace = torch.linspace(0, label_num-1, label_num).long().view(1,label_num,1,1).expand(B,label_num,H,W).to(segmentation.device)\n",
    "    matrix = (values.float()==linspace.float()).float().to(segmentation.device)\n",
    "    for j in range(2,matrix.shape[1]):\n",
    "        matrix[0,j,:,:] = matrix[0,j,:,:]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40de79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(overlaySegment(torch.from_numpy(in2).view(150,150),warped_2.view(150,150)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(overlaySegment(torch.from_numpy(in1).view(150,150),seg.reshape(150,150)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d58134",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(warped_2.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8e720",
   "metadata": {},
   "source": [
    "# Verdict baseline\n",
    "has difficulties.. Probably need to look at the gird_sample or warp method to have best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a5d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = load_flownet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving = F.interpolate(torch.from_numpy(in1).view(1,1,150,150), size=(2*64,2*64)).view(2*64,2*64,1) \n",
    "fixed = F.interpolate(torch.from_numpy(in2).view(1,1,150,150), size=(2*64,2*64)).view(2*64,2*64,1)\n",
    "\n",
    "print(moving.shape)\n",
    "print(fixed.shape)\n",
    "\n",
    "image = preprocessing_flownet(fixed, moving)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_out = flow(image).squeeze().detach().numpy().transpose(1,2,0)\n",
    "flow_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a88172",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(fixed)\n",
    "plt.subplot(132)\n",
    "plt.imshow(flow2img(flow_out))\n",
    "plt.subplot(133)\n",
    "plt.imshow(moving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_inter = F.interpolate(seg.view(1,1,150,150), size=(128,128)).squeeze().long()\n",
    "seg_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7879ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlaySegment(moving.squeeze(),seg_inter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = warpImage(seg_inter.view(1,1,128,128).float(), torch.from_numpy(flow_out).reshape(1,2,128,128))\n",
    "warped_sampled = F.grid_sample(seg_inter.view(1,1,128,128).float(), torch.from_numpy(flow_out).reshape(1,128,128,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlaySegment(moving.view(128,128),warped.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c2e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(warped_sampled.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d11bb7",
   "metadata": {},
   "source": [
    "These two do not work so well.. Let's try the cuda sampling one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "crnt_dev = torch.cuda.current_device()\n",
    "\n",
    "warped = warp(seg_inter.view(1,1,128,128).float().to(crnt_dev), torch.from_numpy(flow_out).reshape(1,2,128,128).to(crnt_dev)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlaySegment(fixed.view(128,128),warped.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc7fdaa",
   "metadata": {},
   "source": [
    "The does not look like it is good...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186d0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
