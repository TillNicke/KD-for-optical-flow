{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63cc3599",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "Here we preprocess the data and save it into a .pth file, to be able to load it for experiments. We also split into train, test and eval for images and seqs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.plotting import flow2img, overlaySegment\n",
    "from utils.encoding import dice_coeff\n",
    "from utils.layers import warp, warpImage\n",
    "from utils.load_models import load_flownet2\n",
    "from utils.preprocessing import preprocessing_flownet\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ids of available patients\n",
    "available = pd.read_csv(\"/home/nicke/MasterThesis/available_US_probands.csv\")\n",
    "available = available.drop('Unnamed: 0', axis=1)\n",
    "available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the IDs for training and testing aka evaluation.\n",
    "np.random.seed(42)\n",
    "id_list = available['Id'].values\n",
    "train_id = np.random.choice(id_list, (int(len(id_list) * 0.9)), replace=False)\n",
    "\n",
    "test_id = available[~available['Id'].isin(train_id)]['Id'].values\n",
    "\n",
    "print(\"There are {} IDs for training\".format(len(train_id)))\n",
    "print(\"There are {} IDs for testing\".format(len(test_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c8c3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check how many Image pairs are there for training.\n",
    "num_train_pairs = 0\n",
    "\n",
    "for train in train_id:\n",
    "    \n",
    "    path = os.path.join(\"/share/data_ultraschall/compressions\", str(train), \"frames\")\n",
    "    total_images = os.listdir(path)\n",
    "    \n",
    "    # if there are enough frames available, we take three moving and fixed pairs from it\n",
    "    if len(total_images) > 30:\n",
    "        num_train_pairs += 3\n",
    "        \n",
    "    # if there are between 2ß and 10, 2 fixed,moving pairs are selected\n",
    "    elif len(total_images) > 20:\n",
    "        num_train_pairs += 2\n",
    "        \n",
    "    # else only one can be taken\n",
    "    else:\n",
    "        num_train_pairs += 1\n",
    "        \n",
    "print(\"Over all we have {} number of training pairs\".format(num_train_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f22de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many Image pairs are there for testing.\n",
    "num_test_pairs = 0\n",
    "\n",
    "for train in test_id:\n",
    "    \n",
    "    path = os.path.join(\"/share/data_ultraschall/compressions\", str(train), \"frames\")\n",
    "    total_images = os.listdir(path)\n",
    "    \n",
    "    # if there are enough frames available, we take three moving and fixed pairs from it\n",
    "    if len(total_images) > 30:\n",
    "        num_test_pairs += 3\n",
    "        \n",
    "    # if there are between 2ß and 10, 2 fixed,moving pairs are selected\n",
    "    elif len(total_images) > 20:\n",
    "        num_test_pairs += 2\n",
    "        \n",
    "    # else only one can be taken\n",
    "    else:\n",
    "        num_test_pairs += 1\n",
    "        \n",
    "print(\"Over all we have {} number of testing/eval pairs\".format(num_test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ac75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_seg(path, image):\n",
    "    \"\"\"\n",
    "    function to load images and fitting segmentation\n",
    "    \n",
    "    path: str. path to an ID directory\n",
    "    image: str. Image number to be loaded\n",
    "    \n",
    "    return: np.ndarray. normalized gray scale image with segmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    # load image with PIL and normalize\n",
    "    img = np.array(Image.open(os.path.join(path,\"frames\", image))) / 255\n",
    "    #print(os.path.join(path,\"frames\", image))\n",
    "    #print(os.path.join(path,\"segmentations\", \"1\", image))\n",
    "    \n",
    "    # load seg and normalize over the labels\n",
    "    seg =np.array(Image.open(os.path.join(path,\"segmentations\", \"1\", image))) / 200\n",
    "    \n",
    "    return img, seg\n",
    "    \n",
    "def get_image_seg_pairs(path):\n",
    "    \"\"\"\n",
    "    function to load image pairs from one ID\n",
    "\n",
    "    prob_id: str denoting the ID of a folder to be loaded\n",
    "    return: np.ndarray image pairs ; np.ndarray segmentation pairs \n",
    "    \"\"\"\n",
    "    \n",
    "    all_files = sorted(os.listdir(os.path.join(path,\"frames\")))\n",
    "    \n",
    "    # Select how many image pairs there are for te patient\n",
    "    if len(all_files) > 30:\n",
    "        size = 3\n",
    "    elif len(all_files) > 20:\n",
    "        size = 2\n",
    "    else:\n",
    "        size = 1\n",
    "        \n",
    "    # select random index for the image and make sure none is doubled\n",
    "    rand_idx = np.random.choice(np.arange(0,len(all_files)), size=size, replace=False)\n",
    "    file_pairs = []\n",
    "    \n",
    "    # for every fixed image index, we need a moving image index.\n",
    "    for idx in rand_idx:\n",
    "        \n",
    "        # The time intervall at the moment is 4 (6) frames for the moving\n",
    "        moving_idx = idx + 6\n",
    "        if moving_idx > len(all_files)-1:\n",
    "            moving_idx = idx - 6\n",
    "            if moving_idx < 0:\n",
    "                moving_idx = 0\n",
    "\n",
    "        file_pairs.append([all_files[idx],all_files[moving_idx]])\n",
    "    \n",
    "    frame_pairs = []\n",
    "    seg_pairs = []\n",
    "    \n",
    "    # load the seg and frame for fixed and moving\n",
    "    for fixed_file, moving_file in file_pairs:\n",
    "        \n",
    "        fixed, fixed_seg = load_image_and_seg(path, fixed_file)\n",
    "        moving, moving_seg = load_image_and_seg(path, moving_file)\n",
    "        \n",
    "        if fixed_seg.max() == 0:\n",
    "            continue\n",
    "        if moving_seg.max() == 0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # and store them together\n",
    "        frame_pairs.append([fixed,moving])\n",
    "        seg_pairs.append([fixed_seg,moving_seg])\n",
    "    \n",
    "    return np.array(frame_pairs), np.array(seg_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95092243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test frames and segmentations\n",
    "\n",
    "test_frames = []\n",
    "test_segs = []\n",
    "for idx,test in enumerate(test_id):\n",
    "    \n",
    "    path = os.path.join(\"/share/data_ultraschall/compressions\", str(test))\n",
    "    imgs, segs = get_image_seg_pairs(path)\n",
    "    for pair in imgs:\n",
    "        test_frames.append(pair)\n",
    "    for pair in segs:\n",
    "        test_segs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3befda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform them into torch tensors and make sure they match\n",
    "test_frames = torch.from_numpy(np.array(test_frames))\n",
    "test_segs = torch.from_numpy(np.array(test_segs))\n",
    "\n",
    "assert test_frames.shape == test_segs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train frames and segmentations\n",
    "\n",
    "train_frames = []\n",
    "train_segs = []\n",
    "for idx, train in enumerate(train_id):\n",
    "    \n",
    "    path = os.path.join(\"/share/data_ultraschall/compressions\", str(train))\n",
    "    imgs, segs = get_image_seg_pairs(path)\n",
    "    for pair in imgs:\n",
    "        train_frames.append(pair)\n",
    "    for pair in segs:\n",
    "        train_segs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe33292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into tensor and check if they match\n",
    "\n",
    "train_frames = torch.from_numpy(np.array(train_frames))\n",
    "train_segs = torch.from_numpy(np.array(train_segs))\n",
    "\n",
    "assert train_frames.shape == train_segs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train\n",
    "torch.save(train_frames, \"/share/data_ultraschall/nicke_ma/data/train_frames_disp_6.pth\")\n",
    "torch.save(train_segs, \"share/data_ultraschall/nicke_ma/data/train_segs_disp_6.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test\n",
    "torch.save(test_frames, \"share/data_ultraschall/nicke_ma/data/test_frames_disp_6.pth\")\n",
    "torch.save(test_segs, \"share/data_ultraschall/nicke_ma/data/test_segs_disp_6.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05631b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
