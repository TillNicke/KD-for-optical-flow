{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a7b564",
   "metadata": {},
   "source": [
    "# Data set generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ids of available patients\n",
    "available = pd.read_csv(\"/home/nicke/MasterThesis/available_US_probands.csv\")\n",
    "available = available.drop('Unnamed: 0', axis=1)\n",
    "available = available[available['Anatomy'] != 'BACKGROUND']\n",
    "available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fffaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/share/data_ultraschall/compressions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = (available.Id.values).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for available landmarks in the ids.\n",
    "landmarks = pd.read_csv('/home/nicke/MasterThesis/landmarks.csv')\n",
    "\n",
    "# Get the idx of the compression starts\n",
    "landmarks = landmarks[(landmarks['Start Frames'] != '[]') & (landmarks['End Frames'] != '[]')& (landmarks['End Frames'] != 'DNC')]\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefdbebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge it all into one DF\n",
    "data = landmarks.merge(available, on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb90107",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = (data.Id.values).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_seg(path, image):\n",
    "    \"\"\"\n",
    "    function to load images and fitting segmentation\n",
    "    \n",
    "    path: str. path to an ID directory\n",
    "    image: str. Image number to be loaded\n",
    "    \n",
    "    return: np.ndarray. normalized gray scale image with segmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    # load image with PIL and normalize\n",
    "    img = np.array(Image.open(os.path.join(path,'frames', image))) / 255\n",
    "    #print(os.path.join(path,'frames', image))\n",
    "    #print(os.path.join(path,'segmentations', '1', image))\n",
    "    \n",
    "    # load seg and normalize over the labels\n",
    "    seg =np.array(Image.open(os.path.join(path,'segmentations', '1', image))) / 200\n",
    "    \n",
    "    return img, seg\n",
    "\n",
    "def get_image_seg_pairs(prob_id):\n",
    "    \"\"\"\n",
    "    function to load image pairs from one ID\n",
    "\n",
    "    prob_id: str denoting the ID of a folder to be loaded\n",
    "    return: np.ndarray image pairs ; np.ndarray segmentation pairs \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print(f'Working on id: {prob_id}')\n",
    "    # generate sorted list of image names.\n",
    "    # common structure: 00xx.png where XX is a number between 00 and the max number of recorded frames\n",
    "    all_frames = sorted(os.listdir(os.path.join(path_to_data,prob_id,'frames')))\n",
    "\n",
    "    # get the first frame bevore the comrpession starts and the last available frame after the comrepssion\n",
    "    first_available_frame = np.fromstring(landmarks[landmarks['Id']== int(prob_id)]['Start Frames'].iat[0].strip(']['), sep=',', dtype=int)[0]\n",
    "    last_available_frame = np.fromstring(landmarks[landmarks['Id']== int(prob_id)]['End Frames'].iat[0].strip(']['), sep=',', dtype=int)\n",
    "    \n",
    "    # generate image pairs by names \n",
    "    file_pairs = []\n",
    "    for j,f_frame in enumerate(first_available_frame):\n",
    "        i = 2\n",
    "        while f_frame + i < last_available_frame[j]:\n",
    "            file_pairs.append([all_frames[f_frame], all_frames[f_frame+i]])\n",
    "            i = i+2\n",
    "            if len(file_pairs) > 6:\n",
    "                break\n",
    "    \n",
    "    frame_pairs = []\n",
    "    seg_pairs = []\n",
    "    \n",
    "    # load the seg and frame for fixed and moving\n",
    "    for fixed_file, moving_file in file_pairs:\n",
    "        \n",
    "        fixed, fixed_seg = load_image_and_seg(os.path.join(path_to_data, prob_id), fixed_file)\n",
    "        moving, moving_seg = load_image_and_seg(os.path.join(path_to_data, prob_id), moving_file)\n",
    "        \n",
    "        if fixed_seg.max() == 0:\n",
    "            continue\n",
    "        if moving_seg.max() == 0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # and store them together\n",
    "        frame_pairs.append([fixed,moving])\n",
    "        seg_pairs.append([fixed_seg,moving_seg])\n",
    "    \n",
    "    return np.array(frame_pairs), np.array(seg_pairs)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd840066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# go over all usefule ID as in list\n",
    "frames = []\n",
    "segs = []\n",
    "ids = []\n",
    "for prob_id in id_list:\n",
    "\n",
    "    # select frame and segmentation pairs for every ID\n",
    "    frame_pairs, seg_pairs = get_image_seg_pairs(prob_id)\n",
    "    \n",
    "    for pair in frame_pairs:\n",
    "        frames.append(pair)\n",
    "    for pair in seg_pairs:\n",
    "        segs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72604c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch\n",
    "all_frames = torch.from_numpy(np.array(frames))\n",
    "all_segs = torch.from_numpy(np.array(segs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all_frames.shape == all_segs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and eval\n",
    "train_idx = np.random.choice(len(all_frames), size=int(len(all_frames) * 0.9), replace=False)\n",
    "test_idx = np.arange(0,len(all_frames))\n",
    "for idx in train_idx:\n",
    "    test_idx = test_idx[test_idx != idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12576d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a0ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_idx.shape)\n",
    "test_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "frames = all_frames[torch.from_numpy(train_idx)]\n",
    "segs = all_segs[torch.from_numpy(train_idx)]\n",
    "\n",
    "test_frames = all_frames[torch.from_numpy(test_idx)]\n",
    "test_segs = all_segs[torch.from_numpy(test_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8081e1",
   "metadata": {},
   "source": [
    "### Store Torch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_frames, \"/share/data_ultraschall/nicke_ma/data/test_frames_oneFixed_multipleMoving_dist2.pth\")\n",
    "torch.save(test_segs, \"/share/data_ultraschall/nicke_ma/data/test_segs_oneFixed_multipleMoving_dist2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(frames, \"/share/data_ultraschall/nicke_ma/data/frames_oneFixed_multipleMoving_dist2.pth\")\n",
    "torch.save(segs, \"/share/data_ultraschall/nicke_ma/data/segs_oneFixed_multipleMoving_dist2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51e982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
