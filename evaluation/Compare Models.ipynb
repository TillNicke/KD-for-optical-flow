{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763477e2",
   "metadata": {},
   "source": [
    "# Comparing the different Models\n",
    "\n",
    "In this notebook we comapre the saved models on Eval data. We do this, so we can have an intermediate look at the results, without using the eval data, so we don't overfit (subconciously) on the eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38676328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from math import ceil\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.load_models import load_flownet2, load_pwcnet, init_weights\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp, warpImage\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "\n",
    "\n",
    "from models.pdd_net.pdd_student import OBELISK2d\n",
    "\n",
    "# Select a GPU for the work\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "available_gpus = [(torch.cuda.device(i),torch.cuda.get_device_name(i)) for i in range(torch.cuda.device_count())]\n",
    "print(available_gpus)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ea952",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.load('/share/data_ultraschall/nicke_ma/data/test_frames.pth')\n",
    "segs = torch.load('/share/data_ultraschall/nicke_ma/data/test_segs.pth')\n",
    "\n",
    "#define a training split \n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pdd(model):\n",
    "    \"\"\"\n",
    "    Function to evaluate PDD-Net on unseen data\n",
    "\n",
    "    model: torch.nn.module Network \n",
    "\n",
    "    return: dice mean: torch.tensor and unwarped mean: torch.tensor\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # storing arrays\n",
    "    overall_dice = torch.zeros(imgs.shape[0], 2)\n",
    "    unwarped_dice = torch.zeros(imgs.shape[0], 2)\n",
    "    \n",
    "    for i,idx in enumerate(range(imgs.shape[0])):\n",
    "        fixed = imgs[idx:idx+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[idx:idx+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[idx:idx+1,0,:].contiguous()\n",
    "        moving_seg = segs[idx:idx+1,1,:].contiguous()\n",
    "        \n",
    "        # Some images have no segmentation to them, \n",
    "        # even if it was present in the directory\n",
    "        # We leave these ones out, as they cannot be avaluated\n",
    "        if len(torch.where(torch.histc(fixed_seg) != 0)[0]) == 3 and fixed_seg.max() <= 1:\n",
    "            fixed_seg = fixed_seg*2\n",
    "        if len(torch.where(torch.histc(moving_seg) != 0)[0]) == 3 and moving_seg.max() <= 1:\n",
    "            moving_seg = moving_seg*2\n",
    "       \n",
    "       # run feature extraction\n",
    "        with torch.no_grad():\n",
    "            fixed_feat = model(fixed.cuda())\n",
    "            moving_feat = model(moving.cuda())\n",
    "\n",
    "        ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "        #regularise using meanfield inference with approx. min-convolutions\n",
    "        soft_cost_one,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "        #upsample field to original resolution\n",
    "        dense_flow_fit = F.interpolate(disp_xy,size=(H,W),mode='bicubic')\n",
    "\n",
    "\n",
    "        #apply and evaluate transformation\n",
    "        identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "        warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "\n",
    "        d1 = dice_coeff(warped_student_seg.squeeze(),fixed_seg,3)\n",
    "        d2 = dice_coeff(moving_seg,fixed_seg, 3)\n",
    "\n",
    "        overall_dice[i] = d1\n",
    "        unwarped_dice[i] = d2\n",
    "    \n",
    "    overall_dice = torch.from_numpy(np.array(overall_dice))\n",
    "    unwarped_dice = torch.from_numpy(np.array(unwarped_dice))\n",
    "    return overall_dice.mean(axis=0), unwarped_dice.mean(axis=0)\n",
    "\n",
    "def eval_flownet(model):\n",
    "    \"\"\"\n",
    "    function to evaluate Flownet2\n",
    "\n",
    "    model: torch.nn.module\n",
    "\n",
    "    return: dice mean: torch.tensor and unwarped mean: torch.tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # scaling the images by a spcific factor for processing\n",
    "    scale=4\n",
    "    model.eval()\n",
    "    overall_dice = torch.zeros(imgs.shape[0], 2)\n",
    "    unwarped_dice = torch.zeros(imgs.shape[0], 2)\n",
    "    \n",
    "    for i,idx in enumerate(range(imgs.shape[0])):\n",
    "        \n",
    "        fixed = imgs[idx:idx+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[idx:idx+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[idx:idx+1,0,:].contiguous()\n",
    "        moving_seg = segs[idx:idx+1,1,:].contiguous()\n",
    "        \n",
    "        # Some images have no segmentation to them,\n",
    "        # even if it was present in the directory\n",
    "        # We leave these ones out, as they cannot be avaluated\n",
    "        if len(torch.where(torch.histc(fixed_seg) != 0)[0]) == 3 and fixed_seg.max() <= 1:\n",
    "            fixed_seg = fixed_seg*2\n",
    "        if len(torch.where(torch.histc(moving_seg) != 0)[0]) == 3 and moving_seg.max() <= 1:\n",
    "            moving_seg = moving_seg*2\n",
    "        \n",
    "        teacher_fixed = F.interpolate(fixed, size=(scale*64,scale*64), mode='bicubic')\n",
    "        teacher_moving = F.interpolate(moving, size=(scale*64,scale*64), mode='bicubic')\n",
    "        # Generate the teacher flow estimation\n",
    "        flow_in = preprocessing_flownet(teacher_fixed.detach().clone().reshape(scale*64,scale*64,1),teacher_moving.detach().clone().reshape(scale*64,scale*64,1)).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            flownet_flow = model(flow_in)\n",
    "        \n",
    "        \n",
    "        flownet_flow = F.interpolate(flownet_flow.cpu(), size=(H,W), mode='bicubic')\n",
    "\n",
    "        # warp segmentation with flownet flow\n",
    "        warped_flownet_seg = warp_seg(moving_seg, flownet_flow)\n",
    "\n",
    "            \n",
    "        d1 = dice_coeff(warped_flownet_seg.squeeze(),fixed_seg,3)\n",
    "        d2 = dice_coeff(moving_seg, fixed_seg, 3)\n",
    "\n",
    "        overall_dice[i] = d1\n",
    "        unwarped_dice[i] = d2\n",
    "    \n",
    "    overall_dice = torch.from_numpy(np.array(overall_dice))\n",
    "    unwarped_dice = torch.from_numpy(np.array(unwarped_dice))\n",
    "    return overall_dice.mean(axis=0), unwarped_dice.mean(axis=0)\n",
    "\n",
    "def eval_pwcnet(model):\n",
    "    \"\"\"\n",
    "    function to evaluate PWC-Net\n",
    "\n",
    "    model: torch.nn.module\n",
    "\n",
    "    return: dice mean: torch.tensor and unwarped mean: torch.tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # scaling images by a specific factor. \n",
    "    # can be adapted\n",
    "    scale=1\n",
    "    model.eval()\n",
    "    overall_dice = torch.zeros(imgs.shape[0], 2)\n",
    "    unwarped_dice = torch.zeros(imgs.shape[0], 2)\n",
    "    \n",
    "    for i,idx in enumerate(range(imgs.shape[0])):\n",
    "        \n",
    "        fixed = imgs[idx:idx+1,0,:].unsqueeze(0).float()\n",
    "        moving = imgs[idx:idx+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "        fixed_seg = segs[idx:idx+1,0,:].contiguous()\n",
    "        moving_seg = segs[idx:idx+1,1,:].contiguous()\n",
    "        \n",
    "        if len(torch.where(torch.histc(fixed_seg) != 0)[0]) == 3 and fixed_seg.max() <= 1:\n",
    "            fixed_seg = fixed_seg*2\n",
    "        if len(torch.where(torch.histc(moving_seg) != 0)[0]) == 3 and moving_seg.max() <= 1:\n",
    "            moving_seg = moving_seg*2\n",
    "        \n",
    "        teacher_fixed = F.interpolate(fixed, size=(scale*64,scale*64), mode='bicubic')\n",
    "        teacher_moving = F.interpolate(moving, size=(scale*64,scale*64), mode='bicubic')\n",
    "        # Generate the teacher flow estimation\n",
    "        pwc_flow_in = preprocessing_pwc(teacher_fixed.detach().clone().reshape(scale*64,scale*64,1),teacher_moving.detach().clone().reshape(scale*64,scale*64,1)).cuda()\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pwc_flow = model(pwc_flow_in)\n",
    "            pwc_flow = pwc_flow[0] * 20.0\n",
    "            pwc_flow = F.interpolate(pwc_flow.unsqueeze(0), size=(H,W))\n",
    "\n",
    "        # warp the segmentations with pwc flow\n",
    "        warped_pwc_seg = warp(moving_seg.float().unsqueeze(0).cuda(), pwc_flow.cuda()).cpu()\n",
    "\n",
    "        d1 = dice_coeff(warped_pwc_seg.squeeze(),fixed_seg,3)\n",
    "        d2 = dice_coeff(moving_seg, fixed_seg,3)\n",
    "\n",
    "        overall_dice[i] = d1\n",
    "        unwarped_dice[i] = d2\n",
    "    \n",
    "    overall_dice = torch.from_numpy(np.array(overall_dice))\n",
    "    unwarped_dice = torch.from_numpy(np.array(unwarped_dice))\n",
    "    return overall_dice.mean(axis=0), unwarped_dice.mean(axis=0)\n",
    "\n",
    "def eval_baseline():\n",
    "    \"\"\"\n",
    "    function to evaluate Dual-TVL1\n",
    "\n",
    "    model: torch.nn.module\n",
    "\n",
    "    return: dice mean: torch.tensor and unwarped mean: torch.tensor\n",
    "    \"\"\"\n",
    "    baseline = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    overall_dice = torch.zeros(imgs.shape[0], 2)\n",
    "    unwarped_dice = torch.zeros(imgs.shape[0], 2)\n",
    "    \n",
    "    for i,idx in enumerate(range(imgs.shape[0])):\n",
    "        fixed = imgs[idx:idx+1,0,:].squeeze().float()\n",
    "        moving = imgs[idx:idx+1,1,:].squeeze().float()\n",
    "\n",
    "        fixed_seg = segs[idx:idx+1,0,:].contiguous()\n",
    "        moving_seg = segs[idx:idx+1,1,:].contiguous()\n",
    "\n",
    "        if len(torch.where(torch.histc(fixed_seg) != 0)[0]) == 3 and fixed_seg.max() <= 1:\n",
    "            fixed_seg = fixed_seg*2\n",
    "        if len(torch.where(torch.histc(moving_seg) != 0)[0]) == 3 and moving_seg.max() <= 1:\n",
    "            moving_seg = moving_seg*2\n",
    "\n",
    "        flow_numpy = baseline.calc(fixed.numpy().astype(np.float32), moving.numpy().astype(np.float32), None)\n",
    "        flow = torch.from_numpy(flow_numpy) * 0.001\n",
    "        \n",
    "        warped = warp(moving_seg.float().unsqueeze(0).cuda(), flow.reshape(2,150,150).unsqueeze(0).cuda()).cpu()\n",
    "        \n",
    "        d1 = dice_coeff(warped,fixed_seg, 3)\n",
    "        d2 = dice_coeff(moving_seg,fixed_seg, 3)\n",
    "        \n",
    "        overall_dice[i] = d1\n",
    "        unwarped_dice[i] = d2\n",
    "    return overall_dice.mean(axis=0), unwarped_dice.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c21a64",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W,H = (150,150)\n",
    "o_m = H//4\n",
    "o_n = W//4\n",
    "ogrid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,o_m,o_n)).view(1,1,-1,2).cuda()\n",
    "disp_range = 0.25#0.25\n",
    "displacement_width = 15#15#11#17\n",
    "shift_xy = F.affine_grid(disp_range*torch.eye(2,3).unsqueeze(0),(1,1,displacement_width,displacement_width)).view(1,1,-1,2).cuda()\n",
    "\n",
    "grid_size = 32#25#30\n",
    "grid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,grid_size,grid_size)).view(1,-1,1,2).cuda()\n",
    "\n",
    "disp_hw = 5\n",
    "displace_range = 11\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_normal(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant(m.bias, 0.0)\n",
    "\n",
    "class OBELISK2d(nn.Module):\n",
    "    def __init__(self, chan = 16):\n",
    "\n",
    "        super(OBELISK2d, self).__init__()\n",
    "        channels = chan\n",
    "        self.offsets = nn.Parameter(torch.randn(2,channels *2,2) *0.05)\n",
    "        self.layer0 = nn.Conv2d(1, 4, 5, stride=2, bias=False, padding=2)\n",
    "        self.batch0 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.layer1 = nn.Conv2d(channels *8, channels *4, 1, bias=False, groups=1)\n",
    "        self.batch1 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer2 = nn.Conv2d(channels *4, channels *4, 3, bias=False, padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer3 = nn.Conv2d(channels *4, channels *1, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_img):\n",
    "        img_in = F.avg_pool2d(input_img ,3 ,padding=1 ,stride=2)\n",
    "        img_in = F.relu(self.batch0(self.layer0(img_in)))\n",
    "        sampled = F.grid_sample(img_in ,ogrid_xy + self.offsets[0 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "        sampled -= F.grid_sample(img_in ,ogrid_xy + self.offsets[1 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "\n",
    "        x = F.relu(self.batch1(self.layer1(sampled)))\n",
    "        x = F.relu(self.batch2(self.layer2(x)))\n",
    "        features = self.layer3(x)\n",
    "        return features\n",
    "\n",
    "\n",
    "    \n",
    "def min_convolution(ssd_distance, displace_range, H, W):\n",
    "    # Prepare operators for smooth dense displacement space\n",
    "    pad1 = nn.ReplicationPad2d(5)\n",
    "    avg1 = nn.AvgPool2d(5,stride=1)\n",
    "    max1 = nn.MaxPool2d(3,stride=1)\n",
    "    pad2 = nn.ReplicationPad2d(6)\n",
    "    # approximate min convolution / displacement compatibility\n",
    "\n",
    "    ssd_minconv = avg1(avg1(-max1(-pad1(ssd_distance.permute(0,2,3,1).reshape(1,-1,displace_range,displace_range)))))\n",
    "\n",
    "    ssd_minconv = ssd_minconv.permute(0,2,3,1).view(1,-1,H,W)\n",
    "    min_conv_cost = avg1(avg1(avg1(pad2(ssd_minconv))))\n",
    "    \n",
    "    return min_conv_cost\n",
    "\n",
    "def meanfield(ssd_distance,img_fixed,displace_range,H,W):\n",
    "\n",
    "    crnt_dev = ssd_distance.device\n",
    "\n",
    "    cost = min_convolution(ssd_distance, displace_range, H, W)\n",
    "\n",
    "    soft_cost = F.softmax(-10*cost.view(displace_range**2,-1).t(),1)\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    disp_mesh_grid = disp_hw*F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,displace_range,displace_range),align_corners=True)\n",
    "    disp_mesh_grid /= torch.Tensor([(W-1)*.5,(H-1)*.5])\n",
    "\n",
    "    disp_xy = torch.sum(soft_cost.view(1,H,W,-1,1)*disp_mesh_grid.view(1,1,1,-1,2).to(crnt_dev),3).permute(0,3,1,2) \n",
    "    \n",
    "\n",
    "    return soft_cost,disp_xy\n",
    "\n",
    "def correlation_layer(displace_range, feat_moving, feat_fixed):\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    feat_moving_unfold = F.unfold(feat_moving.transpose(1,0),(displace_range,displace_range),padding=disp_hw)\n",
    "    B,C,H,W = feat_fixed.size()\n",
    "    \n",
    "    ssd_distance = ((feat_moving_unfold-feat_fixed.view(C,1,-1))**2).sum(0).view(1,displace_range**2,H,W)\n",
    "\n",
    "    return ssd_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dbcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load different Obelisk models\n",
    "\n",
    "obel_solo = OBELISK2d(16)\n",
    "obel_solo.load_state_dict(torch.load(\"models/Experiment_1/obel16_07_10_21-14-26.pth\"))\n",
    "\n",
    "obel_ensemble = OBELISK2d(16)\n",
    "obel_ensemble.load_state_dict(torch.load(\"models/Experiment_2/obel16_ensemble_07_10_21-20-08.pth\"))\n",
    "\n",
    "obel_flow = OBELISK2d(16)\n",
    "obel_flow.load_state_dict(torch.load(\"models/Experiment_2/obel16_flownet_teacher_07_10_21-17-22.pth\"))\n",
    "\n",
    "obel_pwc = OBELISK2d(16)\n",
    "obel_pwc.load_state_dict(torch.load(\"models/Experiment_2/obel16_pwc_teacher_07_10_21-18-18.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet = load_flownet2().cuda()\n",
    "flownet.eval()\n",
    "\n",
    "pwc = load_pwcnet().cuda()\n",
    "pwc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfa818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing results.\n",
    "\n",
    "print(\"obel Solo\")\n",
    "print(eval_pdd(obel_solo.cuda()))\n",
    "\n",
    "print(\"Ensemble\")\n",
    "print(eval_pdd(obel_ensemble.cuda()))\n",
    "\n",
    "print(\"Only Flownet\")\n",
    "print(eval_pdd(obel_flow.cuda()))\n",
    "\n",
    "print(\"Only PWC\")\n",
    "print(eval_pdd(obel_pwc.cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13934778",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_flownet(flownet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5713373",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pwcnet(pwc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49421f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66aef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=1\n",
    "idx = 100\n",
    "fixed = imgs[idx:idx+1,0,:].unsqueeze(0).float()\n",
    "moving = imgs[idx:idx+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "fixed_seg = segs[idx:idx+1,0,:].contiguous()\n",
    "moving_seg = segs[idx:idx+1,1,:].contiguous()\n",
    "\n",
    "if len(torch.where(torch.histc(fixed_seg) != 0)[0]) == 3 and fixed_seg.max() <= 1:\n",
    "    fixed_seg = fixed_seg*2\n",
    "if len(torch.where(torch.histc(moving_seg) != 0)[0]) == 3 and moving_seg.max() <= 1:\n",
    "    moving_seg = moving_seg*2\n",
    "\n",
    "teacher_fixed = F.interpolate(fixed, size=(scale*64,scale*64), mode='bicubic')\n",
    "teacher_moving = F.interpolate(moving, size=(scale*64,scale*64), mode='bicubic')\n",
    "# Generate the teacher flow estimation\n",
    "pwc_flow_in = preprocessing_pwc(teacher_fixed.detach().clone().reshape(scale*64,scale*64,1),teacher_moving.detach().clone().reshape(scale*64,scale*64,1)).cuda()\n",
    "\n",
    "pwc_flow = pwc(pwc_flow_in)\n",
    "pwc_flow = pwc_flow[0] * 25.0\n",
    "\n",
    "pwc_flow = F.interpolate(pwc_flow.unsqueeze(0), size=(H,W), mode='bicubic')\n",
    "# warp the segmentations with pwc flow\n",
    "warped_pwc_seg = warp(moving_seg.float().unsqueeze(0).cuda(), pwc_flow.cuda()).cpu()\n",
    "\n",
    "\n",
    "d1 = dice_coeff(warped_pwc_seg.squeeze(),fixed_seg,3)\n",
    "d2 = dice_coeff(moving_seg,fixed_seg,3)\n",
    "print(d1)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix,ax = plt.subplots(1,4, figsize=(10,10))\n",
    "ax[0].imshow(overlaySegment(fixed.squeeze(), warped_pwc_seg.squeeze()))\n",
    "ax[0].set_title('Warped Seg')\n",
    "ax[1].imshow(overlaySegment(fixed.squeeze(), fixed_seg.squeeze()))\n",
    "ax[1].set_title('Fixed')\n",
    "ax[2].imshow(overlaySegment(moving.squeeze(), moving_seg.squeeze()))\n",
    "ax[2].set_title('Moving')\n",
    "ax[3].imshow(showFlow(pwc_flow.detach().cpu()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=1\n",
    "idx = 12\n",
    "fixed = imgs[idx:idx+1,0,:].unsqueeze(0).float()\n",
    "moving = imgs[idx:idx+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "fixed_seg = segs[idx:idx+1,0,:].contiguous()\n",
    "moving_seg = segs[idx:idx+1,1,:].contiguous()\n",
    "\n",
    "if len(torch.where(torch.histc(fixed_seg) != 0)[0]) == 3 and fixed_seg.max() <= 1:\n",
    "    fixed_seg = fixed_seg*2\n",
    "if len(torch.where(torch.histc(moving_seg) != 0)[0]) == 3 and moving_seg.max() <= 1:\n",
    "    moving_seg = moving_seg*2\n",
    "\n",
    "teacher_fixed = F.interpolate(fixed, size=(scale*64,scale*64), mode='bicubic')\n",
    "teacher_moving = F.interpolate(moving, size=(scale*64,scale*64), mode='bicubic')\n",
    "# Generate the teacher flow estimation\n",
    "flow_in = preprocessing_flownet(teacher_fixed.detach().clone().reshape(scale*64,scale*64,1),teacher_moving.detach().clone().reshape(scale*64,scale*64,1)).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    flownet_flow = flownet(flow_in)\n",
    "flownet_flow = F.interpolate(flownet_flow.cpu(), size=(H,W), mode='bicubic')\n",
    "\n",
    "# warp segmentation with flownet flow\n",
    "warped_flownet_seg = warp(moving_seg.float().unsqueeze(0).cuda(), flownet_flow.cuda()).cpu()\n",
    "#warped_flownet_seg = F.grid_sample(moving_seg.unsqueeze(0).float(), flownet_flow.view(1,150,150,2))\n",
    "d1 = dice_coeff(fixed_seg,warped_flownet_seg.squeeze().cpu(),3)\n",
    "d2 = dice_coeff(fixed_seg,moving_seg.cpu(),3)\n",
    "print(d1)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86116f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix,ax = plt.subplots(1,4, figsize=(10,10))\n",
    "ax[0].imshow(overlaySegment(fixed.squeeze(), warped_flownet_seg.squeeze()))\n",
    "ax[0].set_title('Warped Seg')\n",
    "ax[1].imshow(overlaySegment(fixed.squeeze(), fixed_seg.squeeze()))\n",
    "ax[1].set_title('Fixed')\n",
    "ax[2].imshow(overlaySegment(moving.squeeze(), moving_seg.squeeze()))\n",
    "ax[2].set_title('Moving')\n",
    "ax[3].imshow(showFlow(flownet_flow.flip(1).cpu()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6fb21",
   "metadata": {},
   "source": [
    "# Plots to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel_solo.eval()\n",
    "rnd_test_idx = torch.randperm(test_set.size(0))\n",
    "p_fix = test_set[rnd_test_idx[0]]\n",
    "\n",
    "fixed = imgs[p_fix:p_fix+1,0,:].unsqueeze(0).float()\n",
    "moving = imgs[p_fix:p_fix+1,1,:].unsqueeze(0).float()\n",
    "\n",
    "fixed_seg = segs[p_fix:p_fix+1,0,:].long().contiguous()\n",
    "moving_seg = segs[p_fix:p_fix+1,1,:].long().contiguous()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    fixed_feat = obel_solo(fixed.cuda())\n",
    "    moving_feat = obel_solo(moving.cuda())\n",
    "\n",
    "ssd_distance = correlation_layer(displace_range, moving_feat, fixed_feat).contiguous()\n",
    "#regularise using meanfield inference with approx. min-convolutions\n",
    "soft_cost_one,disp_xy = meanfield(ssd_distance, fixed, displace_range, H//4, W//4)\n",
    "#upsample field to original resolution\n",
    "dense_flow_fit = F.interpolate(disp_xy,size=(H,W),mode='bicubic')\n",
    "\n",
    "\n",
    "#apply and evaluate transformation\n",
    "identity = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,H,W),align_corners=False).cuda()\n",
    "warped_student_seg = F.grid_sample(moving_seg.cuda().float().unsqueeze(1),identity+dense_flow_fit.permute(0,2,3,1),mode='nearest',align_corners=False).cpu()\n",
    "\n",
    "#warped_teacher_seg = warp(moving_seg.unsqueeze(0).float().cuda(),teacher_flow.squeeze().cuda()).cpu()\n",
    "\n",
    "d1 = dice_coeff(fixed_seg,warped_student_seg.squeeze(),2)\n",
    "d0 = dice_coeff(fixed_seg,moving_seg,2)\n",
    "print(f\"Dice of warped: {d1} vs unwarped dice: {d0}\")\n",
    "\n",
    "rgb = showFlow(dense_flow_fit.cpu().transpose(-2,-1).flip(1))\n",
    "overlay = overlaySegment(fixed.squeeze(),warped_student_seg.data.squeeze(),False)\n",
    "\n",
    "overlay_fixed = overlaySegment(fixed.squeeze(),fixed_seg.data.squeeze(),False)\n",
    "overlay_moving = overlaySegment(moving.squeeze(),moving_seg.data.squeeze(),False)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(rgb)\n",
    "plt.title(\"Flow field\")\n",
    "plt.subplot(222)\n",
    "plt.imshow(overlay)\n",
    "plt.title(\"Warped Segmentation\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(overlay_fixed)\n",
    "plt.title(\"Fixed Frame\")\n",
    "plt.subplot(224)\n",
    "plt.title(\"Moving Frame\")\n",
    "plt.imshow(overlay_moving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3f95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
