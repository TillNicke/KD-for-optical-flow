{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637156a8",
   "metadata": {},
   "source": [
    "# MI estimation \n",
    "between Flownet2, PWC-Net and PDD-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm.notebook import tqdm, trange, tnrange\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import ceil\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.load_models import load_flownet2, load_pwcnet\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "\n",
    "from models.pdd_net.pdd_student import OBELISK2d\n",
    "\n",
    "# Select a GPU for the work\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "available_gpus = [(torch.cuda.device(i),torch.cuda.get_device_name(i)) for i in range(torch.cuda.device_count())]\n",
    "print(available_gpus)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d31d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OBELISK2d(nn.Module):\n",
    "    def __init__(self, chan=16, size=(150,150)):\n",
    "        super(OBELISK2d, self).__init__()\n",
    "        channels = chan\n",
    "        self.offsets = nn.Parameter(torch.randn(2, channels * 2, 2) * 0.05)\n",
    "        self.layer0 = nn.Conv2d(1, 4, 5, stride=2, bias=False, padding=2)\n",
    "        self.batch0 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.layer1 = nn.Conv2d(channels * 8, channels * 4, 1, bias=False,\n",
    "                                groups=1)\n",
    "        self.batch1 = nn.BatchNorm2d(channels * 4)\n",
    "        self.layer2 = nn.Conv2d(channels * 4, channels * 4, 3, bias=False,\n",
    "                                padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(channels * 4)\n",
    "        self.layer3 = nn.Conv2d(channels * 4, channels * 1, 1)\n",
    "\n",
    "        H = size[0]\n",
    "        W = size[1]\n",
    "        self.o_m = H // 4 +1\n",
    "        self.o_n = W // 4 +1\n",
    "\n",
    "        self.displace_range = 11\n",
    "        self.disp_hw = 5\n",
    "        self.ogrid_xy = F.affine_grid(torch.eye(2, 3).unsqueeze(0),(1, 1, self.o_m, self.o_n)).view(1, 1, -1, 2)#.cuda()\n",
    "        self.disp_range = 0.25\n",
    "        self.displacement_width = 11\n",
    "        shift_xy = F.affine_grid(self.disp_range * torch.eye(2, 3).unsqueeze(0), (1, 1, self.displacement_width, self.displacement_width)).view(1, 1, -1, 2)#.cuda()\n",
    "        grid_size = 32  # 25#30\n",
    "        self.grid_xy = F.affine_grid(torch.eye(2, 3).unsqueeze(0),(1, 1, grid_size, grid_size)).view(1, -1, 1,2)#.cuda()\n",
    "\n",
    "    def forward(self, fixed_img, moving_img):\n",
    "        img_in_f = F.avg_pool2d(fixed_img, 3, padding=1, stride=2)\n",
    "        img_in_f = F.relu(self.batch0(self.layer0(img_in_f)))\n",
    "        sampled_f = F.grid_sample(img_in_f,self.ogrid_xy + self.offsets[0, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "        sampled_f -= F.grid_sample(img_in_f,self.ogrid_xy + self.offsets[1, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "\n",
    "        x_1 = F.relu(self.batch1(self.layer1(sampled_f)))\n",
    "        x_1 = F.relu(self.batch2(self.layer2(x_1)))\n",
    "        features_fixed = self.layer3(x_1)\n",
    "        \n",
    "        img_in_m = F.avg_pool2d(moving_img, 3, padding=1, stride=2)\n",
    "        img_in_m = F.relu(self.batch0(self.layer0(img_in_m)))\n",
    "        sampled_m = F.grid_sample(img_in_m,self.ogrid_xy + self.offsets[0, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "        sampled_m -= F.grid_sample(img_in_m,self.ogrid_xy + self.offsets[1, :, :].view(1, -1,1,2)).view(1, -1, self.o_m, self.o_n)\n",
    "\n",
    "        x_2 = F.relu(self.batch1(self.layer1(sampled_m)))\n",
    "        x_2 = F.relu(self.batch2(self.layer2(x_2)))\n",
    "        features_moving = self.layer3(x_2)\n",
    "\n",
    "        ssd_distance = self.correlation_layer(features_moving, features_fixed)\n",
    "        soft_cost,disp_xy = self.meanfield(ssd_distance, fixed_img, self.displace_range, self.o_m, self.o_n)\n",
    "        \n",
    "        return soft_cost, disp_xy\n",
    "\n",
    "\n",
    "    def min_convolution(self, ssd_distance, displace_range, H, W):\n",
    "        # Prepare operators for smooth dense displacement space\n",
    "        pad1 = nn.ReplicationPad2d(5)\n",
    "        avg1 = nn.AvgPool2d(5, stride=1)\n",
    "        max1 = nn.MaxPool2d(3, stride=1)\n",
    "        pad2 = nn.ReplicationPad2d(4)\n",
    "        # approximate min convolution / displacement compatibility\n",
    "\n",
    "        ssd_minconv = avg1(avg1(-max1(-pad1(\n",
    "            ssd_distance.permute(0, 2, 3, 1).reshape(1, -1, self.displace_range,\n",
    "                                                    self.displace_range)))))\n",
    "\n",
    "        ssd_minconv = ssd_minconv.permute(0, 2, 3, 1).view(1, -1, H, W)\n",
    "        min_conv_cost = avg1(avg1(pad2(ssd_minconv)))\n",
    "\n",
    "        return min_conv_cost\n",
    "\n",
    "\n",
    "    def meanfield(self, ssd_distance, img_fixed, displace_range, H, W):\n",
    "        crnt_dev = ssd_distance.device\n",
    "\n",
    "        cost = self.min_convolution(ssd_distance, displace_range, H, W)\n",
    "\n",
    "        soft_cost = F.softmax(-10 * cost.view(displace_range ** 2, -1).t(), 1)\n",
    "\n",
    "        disp_hw = (displace_range - 1) // 2\n",
    "        disp_mesh_grid = disp_hw * F.affine_grid(torch.eye(2, 3).unsqueeze(0), (\n",
    "        1, 1, displace_range, displace_range), align_corners=True)\n",
    "        disp_mesh_grid /= torch.Tensor([(W - 1) * .5, (H - 1) * .5])\n",
    "\n",
    "        disp_xy = torch.sum(\n",
    "            soft_cost.view(1, H, W, -1, 1) * disp_mesh_grid.view(1, 1, 1, -1,\n",
    "                                                                2).to(crnt_dev),\n",
    "            3).permute(0, 3, 1, 2)\n",
    "\n",
    "        return soft_cost, disp_xy\n",
    "\n",
    "\n",
    "    def correlation_layer(self, feat_moving, feat_fixed):\n",
    "        disp_hw = (self.displacement_width - 1) // 2\n",
    "        feat_moving_unfold = F.unfold(feat_moving.transpose(1, 0),\n",
    "                                    (self.displace_range, self.displace_range),\n",
    "                                    padding=self.disp_hw)\n",
    "        B, C, H, W = feat_fixed.size()\n",
    "\n",
    "        ssd_distance = ((feat_moving_unfold - feat_fixed.view(C, 1, -1)) ** 2).sum(0).view(1, self.displace_range ** 2, H, W)\n",
    "\n",
    "        return ssd_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1dad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained with KD\n",
    "path_to_state_dict = \"models/Experiment_2/obel_16_KD_WL_20_01_22-12-54.pth\"\n",
    "model= OBELISK2d(16)\n",
    "model.load_state_dict(torch.load(path_to_state_dict))\n",
    "model.eval()#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af77f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet = load_flownet2().cuda()\n",
    "flownet.eval()\n",
    "pwc = load_pwcnet().cuda()\n",
    "pwc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a961a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs2 = torch.load('/share/data_ultraschall/nicke_ma/data/train_frames_disp_6.pth')\n",
    "segs2 = torch.load('/share/data_ultraschall/nicke_ma/data/train_segs_disp_6.pth')\n",
    "\n",
    "#imgs3 = torch.load('/share/data_ultraschall/nicke_ma/data/frames_oneFixed_multipleMoving.pth')\n",
    "#segs3 = torch.load('/share/data_ultraschall/nicke_ma/data/segs_oneFixed_multipleMoving.pth')\n",
    "\n",
    "#imgs = torch.cat((imgs2,imgs3))\n",
    "#segs = torch.cat((segs2,segs3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd84f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the angle of rotation per pixel\n",
    "def get_rho(def_x):\n",
    "    x = def_x.squeeze().numpy()[0,:,:]\n",
    "    y = def_x.squeeze().numpy()[1,:,:]\n",
    "    #show flow map for numpy\n",
    "    H, W = x.shape\n",
    "    rho = np.sqrt(x*x+y*y)\n",
    "    theta = np.arctan2(x,-y)\n",
    "    theta2 = (-theta+np.pi)/(2.0*np.pi);\n",
    "    rho = np.clip(rho/np.percentile(rho, 99),0,1)\n",
    "    return theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bef84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(fixed, moving):\n",
    "    \"\"\"\n",
    "    return angles of flow fields for image pair\n",
    "    \"\"\"\n",
    "    \n",
    "    # prepare for teachers\n",
    "    flow_fixed = F.interpolate(fixed.unsqueeze(0).unsqueeze(0), size=(2*64,2*64), mode='bilinear')\n",
    "    flow_moving =F.interpolate(moving.unsqueeze(0).unsqueeze(0), size=(2*64,2*64), mode='bilinear')\n",
    "\n",
    "    # Pre processing step\n",
    "    flow_in = preprocessing_flownet(flow_fixed.clone().reshape(2*64,2*64,1),flow_moving.clone().reshape(2*64,2*64,1))\n",
    "    pwc_in = preprocessing_pwc(flow_fixed.clone().reshape(2*64,2*64,1),flow_moving.clone().reshape(2*64,2*64,1))\n",
    "    \n",
    "    # flownet2 inference\n",
    "    flow_flow = flownet(flow_in.cuda()).cpu().detach() * 20\n",
    "    flow_flow = flow_flow[0]\n",
    "\n",
    "    # pwc inference\n",
    "    pwc_flow = pwc(pwc_in.cuda()).cpu().detach() * 20\n",
    "    pwc_flow = F.interpolate(pwc_flow, size=(128,128), mode='bilinear').squeeze()\n",
    "    \n",
    "    # PDD inference\n",
    "    soft, disp_xy = model(fixed.cpu().unsqueeze(0).unsqueeze(0),moving.cpu().unsqueeze(0).unsqueeze(0))\n",
    "    disp_xy = F.interpolate(disp_xy.cpu(), size=(128,128), mode='bilinear')\n",
    "    \n",
    "    # get the angles of rotation per pixel\n",
    "    pwc_angle = get_rho(pwc_flow)\n",
    "    pdd_angle = get_rho(disp_xy.detach())\n",
    "    flow_angle = get_rho(flow_flow)\n",
    "    \n",
    "    return pwc_angle, flow_angle, pdd_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdd_pwc_hists = []\n",
    "pdd_flow_hists = []\n",
    "flow_pwc_hists = []\n",
    "\n",
    "x_bins = np.arange(0,1.01, 0.01)\n",
    "y_bins = np.arange(0,1.01, 0.01)\n",
    "num_bins = 100\n",
    "# len(imgs)\n",
    "for i in trange(len(imgs2), desc='Image Loop', leave=False):\n",
    "    \n",
    "    pwc_angle, flow_angle, pdd_angle = get_angles(torch.clone(imgs2[i][0]).float(), torch.clone(imgs2[i][1].float()))\n",
    "    \n",
    "    \n",
    "    hist1, binsx, binsy, mesh = plt.hist2d(pwc_angle.ravel(), pdd_angle.ravel(), bins=[x_bins,y_bins], density=True)\n",
    "    hist2, binsx, binsy, mesh = plt.hist2d(flow_angle.ravel(), pdd_angle.ravel(), bins=[x_bins,y_bins], density=True)\n",
    "    hist3, binsx, binsy, mesh = plt.hist2d(flow_angle.ravel(), pwc_angle.ravel(), bins=[x_bins,y_bins], density=True)\n",
    "    \n",
    "    pdd_pwc_hists.append(hist1)\n",
    "    pdd_flow_hists.append(hist2)\n",
    "    flow_pwc_hists.append(hist3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts = {'fontsize': 20,'family': 'Latin Modern Roman'}\n",
    "fig, ax = plt.subplots(1,3, figsize=(18,9))\n",
    "\n",
    "ax[0].set_title('Mean MI between PDD and PWC', fontdict=fonts)\n",
    "ax[0].set_ylabel('PDD', fontdict=fonts)\n",
    "ax[0].set_xlabel('PWC', fontdict=fonts)\n",
    "ax[0].pcolormesh(x_bins, y_bins, np.array(pdd_pwc_hists).mean(axis=0))\n",
    "\n",
    "ax[1].set_title('Mean MI between PDD and Flow', fontdict=fonts)\n",
    "ax[1].set_ylabel('PDD', fontdict=fonts)\n",
    "ax[1].set_xlabel('Flownet2', fontdict=fonts)\n",
    "ax[1].pcolormesh(x_bins, y_bins, np.array(pdd_flow_hists).mean(axis=0))\n",
    "\n",
    "ax[2].set_title('Mean MI between Flow and PWC', fontdict=fonts)\n",
    "ax[2].set_xlabel('Flownet2', fontdict=fonts)\n",
    "ax[2].set_ylabel('PWC', fontdict=fonts)\n",
    "ax[2].pcolormesh(x_bins, y_bins, np.array(flow_pwc_hists).mean(axis=0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83398c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a6706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04c48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df12a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927d557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78942b92",
   "metadata": {},
   "source": [
    "Dann war das ganze doch recht aufschlussreich, wir wissen jetzt dass das Flownet einfach nicht viel tut (ob weil es auf die Daten so trainiert ist oder weil es dazu neigt idk)\n",
    "\n",
    "Und dass das Pdd von beiden Teachs lernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0c39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
