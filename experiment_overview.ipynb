{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35626ff7",
   "metadata": {},
   "source": [
    "# Overview to sort and check for results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d233c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('experiments.csv').drop(['mean dice','Unnamed: 0','date','Var eval dice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0154ef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['label loss', 'Knowledge Compression', 'DML'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83c37308",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kc = df[df['mode'] == 'Knowledge Compression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67b21bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-3720fc21b812>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  kc['unwarped dice'] = kc['unwarped dice'].apply(lambda x: x.split('(')[1].split(')')[0]).astype(float)\n"
     ]
    }
   ],
   "source": [
    "kc['unwarped dice'] = kc['unwarped dice'].apply(lambda x: x.split('(')[1].split(')')[0]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a47a6ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-60-654d9b8e0a76>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  kc['Eval mean dice'] = kc['Eval mean dice'].apply(lambda x: x.split('(')[1].split(')')[0] if \"tensor\" in x else x).astype(float)\n"
     ]
    }
   ],
   "source": [
    "kc['Eval mean dice'] = kc['Eval mean dice'].apply(lambda x: x.split('(')[1].split(')')[0] if \"tensor\" in x else x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b560164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-0673153bc694>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  kc['diff'] = kc['Eval mean dice'] - kc['unwarped dice']\n"
     ]
    }
   ],
   "source": [
    "kc['diff'] = kc['Eval mean dice'] - kc['unwarped dice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28a3cb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>optim</th>\n",
       "      <th>mode</th>\n",
       "      <th>unwarped dice</th>\n",
       "      <th>loss</th>\n",
       "      <th>time</th>\n",
       "      <th>Eval mean dice</th>\n",
       "      <th>batch size</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>notes</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>tensor(0.3636, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>30.09.21 20:38</td>\n",
       "      <td>0.521297</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64 + alpha=0.5</td>\n",
       "      <td>-0.071103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>tensor(0.3678, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>01.10.21 13:22</td>\n",
       "      <td>0.550305</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64 + alpha=0.5</td>\n",
       "      <td>-0.059995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5038</td>\n",
       "      <td>tensor(-0.2888, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>23.09.21 11:33</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for KL_div + Scale_Factr=4*64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>50</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>tensor(0.3666, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>27.10.21 13:26</td>\n",
       "      <td>0.235713</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=1*64 + alpha=0.8...</td>\n",
       "      <td>0.025913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>50</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>tensor(0.3779, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>27.10.21 11:49</td>\n",
       "      <td>0.237079</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=1*64 + dataset3</td>\n",
       "      <td>0.027279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>40</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.3245, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>10.09.21 14:10</td>\n",
       "      <td>0.522200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>3 class one hot</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>30</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.3162, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>10.09.21 12:08</td>\n",
       "      <td>0.523400</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>3 class one hot</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>50</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.4823, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>09.09.21 15:40</td>\n",
       "      <td>0.525500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>step in loop,rescale for teacher, No times 2 f...</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>60</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.3252, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>10.09.21 13:18</td>\n",
       "      <td>0.529300</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>3 class one hot</td>\n",
       "      <td>0.037200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.3857, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>09.09.21 16:02</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>step in loop,rescale for teacher, No times 2 f...</td>\n",
       "      <td>0.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>250</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.4018, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>10.09.21 10:30</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>step in loop,rescale for teacher, No times 2 f...</td>\n",
       "      <td>0.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>50</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.4677, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>09.09.21 14:48</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>step in loop,rescale for teacher, No times 2 f...</td>\n",
       "      <td>0.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>tensor(0.4385, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>07.10.21 20:08</td>\n",
       "      <td>0.588022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64 + alpha=0.5</td>\n",
       "      <td>0.042022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>tensor(0.4467, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>07.10.21 18:18</td>\n",
       "      <td>0.594114</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64</td>\n",
       "      <td>0.048114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>tensor(0.4346, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>01.10.21 16:32</td>\n",
       "      <td>0.660255</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64 + alpha=0.5</td>\n",
       "      <td>0.050355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>50</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.3650, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>09.09.21 22:01</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>step in loop,rescale for teacher, No times 2 f...</td>\n",
       "      <td>0.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>tensor(0.4466, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>07.10.21 17:22</td>\n",
       "      <td>0.598431</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64</td>\n",
       "      <td>0.052431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>tensor(-0.3226, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>15.09.21 14:07</td>\n",
       "      <td>0.601300</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>3 class one hot</td>\n",
       "      <td>0.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>60</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.4401, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>10.09.21 11:34</td>\n",
       "      <td>0.551800</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>step in loop,rescale for teacher, No times 2 f...</td>\n",
       "      <td>0.059700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>tensor(0.4320, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>30.09.21 14:40</td>\n",
       "      <td>0.563678</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64</td>\n",
       "      <td>0.060978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>80</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>tensor(0.4329, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>30.09.21 16:46</td>\n",
       "      <td>0.566710</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64</td>\n",
       "      <td>0.064010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>80</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>tensor(0.4329, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>30.09.21 16:46</td>\n",
       "      <td>0.566710</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64</td>\n",
       "      <td>0.064010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.3606, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>10.09.21 10:54</td>\n",
       "      <td>0.570400</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>step in loop,rescale for teacher, No times 2 f...</td>\n",
       "      <td>0.078300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>tensor(0.4396, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>30.09.21 18:36</td>\n",
       "      <td>0.672890</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64</td>\n",
       "      <td>0.080490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>40</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>tensor(-0.2171, device='cuda:0', grad_fn=&lt;AddB...</td>\n",
       "      <td>10.09.21 14:54</td>\n",
       "      <td>0.583700</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>3 class one hot</td>\n",
       "      <td>0.091600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>tensor(0.4413, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>13.10.21 13:43</td>\n",
       "      <td>0.375982</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64 + dataset3</td>\n",
       "      <td>0.128482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>tensor(0.4876, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>13.10.21 21:30</td>\n",
       "      <td>0.384629</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64 + alpha=0.5...</td>\n",
       "      <td>0.137129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>Knowledge Compression</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>tensor(0.5158, device='cuda:0', grad_fn=&lt;AddBa...</td>\n",
       "      <td>13.10.21 16:13</td>\n",
       "      <td>0.390136</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>One Hot for MSE + Scale_Factr=4*64 + dataset3</td>\n",
       "      <td>0.142636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs                                              optim  \\\n",
       "63     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "64     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "54     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "78      50  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "77      50  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "48      40  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "44      30  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "36      50  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "47      60  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "37      20  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "39     250  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "35      50  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "71     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "70     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "65     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "38      50  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "69     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "50     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "41      60  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "59     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "60      80  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "61      80  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "40      10  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "62     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "49      40  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "72     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "74     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "73     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "\n",
       "                     mode  unwarped dice  \\\n",
       "63  Knowledge Compression         0.5924   \n",
       "64  Knowledge Compression         0.6103   \n",
       "54  Knowledge Compression         0.5038   \n",
       "78  Knowledge Compression         0.2098   \n",
       "77  Knowledge Compression         0.2098   \n",
       "48  Knowledge Compression         0.4921   \n",
       "44  Knowledge Compression         0.4921   \n",
       "36  Knowledge Compression         0.4921   \n",
       "47  Knowledge Compression         0.4921   \n",
       "37  Knowledge Compression         0.4921   \n",
       "39  Knowledge Compression         0.4921   \n",
       "35  Knowledge Compression         0.4921   \n",
       "71  Knowledge Compression         0.5460   \n",
       "70  Knowledge Compression         0.5460   \n",
       "65  Knowledge Compression         0.6099   \n",
       "38  Knowledge Compression         0.4921   \n",
       "69  Knowledge Compression         0.5460   \n",
       "50  Knowledge Compression         0.5431   \n",
       "41  Knowledge Compression         0.4921   \n",
       "59  Knowledge Compression         0.5027   \n",
       "60  Knowledge Compression         0.5027   \n",
       "61  Knowledge Compression         0.5027   \n",
       "40  Knowledge Compression         0.4921   \n",
       "62  Knowledge Compression         0.5924   \n",
       "49  Knowledge Compression         0.4921   \n",
       "72  Knowledge Compression         0.2475   \n",
       "74  Knowledge Compression         0.2475   \n",
       "73  Knowledge Compression         0.2475   \n",
       "\n",
       "                                                 loss            time  \\\n",
       "63  tensor(0.3636, device='cuda:0', grad_fn=<AddBa...  30.09.21 20:38   \n",
       "64  tensor(0.3678, device='cuda:0', grad_fn=<AddBa...  01.10.21 13:22   \n",
       "54  tensor(-0.2888, device='cuda:0', grad_fn=<AddB...  23.09.21 11:33   \n",
       "78  tensor(0.3666, device='cuda:0', grad_fn=<AddBa...  27.10.21 13:26   \n",
       "77  tensor(0.3779, device='cuda:0', grad_fn=<AddBa...  27.10.21 11:49   \n",
       "48  tensor(-0.3245, device='cuda:0', grad_fn=<AddB...  10.09.21 14:10   \n",
       "44  tensor(-0.3162, device='cuda:0', grad_fn=<AddB...  10.09.21 12:08   \n",
       "36  tensor(-0.4823, device='cuda:0', grad_fn=<AddB...  09.09.21 15:40   \n",
       "47  tensor(-0.3252, device='cuda:0', grad_fn=<AddB...  10.09.21 13:18   \n",
       "37  tensor(-0.3857, device='cuda:0', grad_fn=<AddB...  09.09.21 16:02   \n",
       "39  tensor(-0.4018, device='cuda:0', grad_fn=<AddB...  10.09.21 10:30   \n",
       "35  tensor(-0.4677, device='cuda:0', grad_fn=<AddB...  09.09.21 14:48   \n",
       "71  tensor(0.4385, device='cuda:0', grad_fn=<AddBa...  07.10.21 20:08   \n",
       "70  tensor(0.4467, device='cuda:0', grad_fn=<AddBa...  07.10.21 18:18   \n",
       "65  tensor(0.4346, device='cuda:0', grad_fn=<AddBa...  01.10.21 16:32   \n",
       "38  tensor(-0.3650, device='cuda:0', grad_fn=<AddB...  09.09.21 22:01   \n",
       "69  tensor(0.4466, device='cuda:0', grad_fn=<AddBa...  07.10.21 17:22   \n",
       "50  tensor(-0.3226, device='cuda:0', grad_fn=<AddB...  15.09.21 14:07   \n",
       "41  tensor(-0.4401, device='cuda:0', grad_fn=<AddB...  10.09.21 11:34   \n",
       "59  tensor(0.4320, device='cuda:0', grad_fn=<AddBa...  30.09.21 14:40   \n",
       "60  tensor(0.4329, device='cuda:0', grad_fn=<AddBa...  30.09.21 16:46   \n",
       "61  tensor(0.4329, device='cuda:0', grad_fn=<AddBa...  30.09.21 16:46   \n",
       "40  tensor(-0.3606, device='cuda:0', grad_fn=<AddB...  10.09.21 10:54   \n",
       "62  tensor(0.4396, device='cuda:0', grad_fn=<AddBa...  30.09.21 18:36   \n",
       "49  tensor(-0.2171, device='cuda:0', grad_fn=<AddB...  10.09.21 14:54   \n",
       "72  tensor(0.4413, device='cuda:0', grad_fn=<AddBa...  13.10.21 13:43   \n",
       "74  tensor(0.4876, device='cuda:0', grad_fn=<AddBa...  13.10.21 21:30   \n",
       "73  tensor(0.5158, device='cuda:0', grad_fn=<AddBa...  13.10.21 16:13   \n",
       "\n",
       "    Eval mean dice  batch size  learning rate  \\\n",
       "63        0.521297        20.0        0.00020   \n",
       "64        0.550305        20.0        0.00020   \n",
       "54        0.503800        20.0        0.00020   \n",
       "78        0.235713        20.0        0.00020   \n",
       "77        0.237079        20.0        0.00020   \n",
       "48        0.522200        20.0        0.00020   \n",
       "44        0.523400        10.0        0.00020   \n",
       "36        0.525500         4.0        0.00001   \n",
       "47        0.529300        10.0        0.00020   \n",
       "37        0.530800        20.0        0.00010   \n",
       "39        0.530800        30.0        0.00010   \n",
       "35        0.533900        20.0        0.00002   \n",
       "71        0.588022        20.0        0.00020   \n",
       "70        0.594114        20.0        0.00020   \n",
       "65        0.660255        20.0        0.00020   \n",
       "38        0.544400        30.0        0.00010   \n",
       "69        0.598431        20.0        0.00020   \n",
       "50        0.601300        20.0        0.00020   \n",
       "41        0.551800         4.0        0.00010   \n",
       "59        0.563678        20.0        0.00020   \n",
       "60        0.566710        20.0        0.00020   \n",
       "61        0.566710        20.0        0.00020   \n",
       "40        0.570400        10.0        0.00050   \n",
       "62        0.672890        20.0        0.00020   \n",
       "49        0.583700        20.0        0.00020   \n",
       "72        0.375982        20.0        0.00020   \n",
       "74        0.384629        20.0        0.00020   \n",
       "73        0.390136        20.0        0.00020   \n",
       "\n",
       "                                                notes      diff  \n",
       "63     One Hot for MSE + Scale_Factr=4*64 + alpha=0.5 -0.071103  \n",
       "64     One Hot for MSE + Scale_Factr=4*64 + alpha=0.5 -0.059995  \n",
       "54              One Hot for KL_div + Scale_Factr=4*64  0.000000  \n",
       "78  One Hot for MSE + Scale_Factr=1*64 + alpha=0.8...  0.025913  \n",
       "77      One Hot for MSE + Scale_Factr=1*64 + dataset3  0.027279  \n",
       "48                                    3 class one hot  0.030100  \n",
       "44                                    3 class one hot  0.031300  \n",
       "36  step in loop,rescale for teacher, No times 2 f...  0.033400  \n",
       "47                                    3 class one hot  0.037200  \n",
       "37  step in loop,rescale for teacher, No times 2 f...  0.038700  \n",
       "39  step in loop,rescale for teacher, No times 2 f...  0.038700  \n",
       "35  step in loop,rescale for teacher, No times 2 f...  0.041800  \n",
       "71     One Hot for MSE + Scale_Factr=4*64 + alpha=0.5  0.042022  \n",
       "70                 One Hot for MSE + Scale_Factr=4*64  0.048114  \n",
       "65     One Hot for MSE + Scale_Factr=4*64 + alpha=0.5  0.050355  \n",
       "38  step in loop,rescale for teacher, No times 2 f...  0.052300  \n",
       "69                 One Hot for MSE + Scale_Factr=4*64  0.052431  \n",
       "50                                    3 class one hot  0.058200  \n",
       "41  step in loop,rescale for teacher, No times 2 f...  0.059700  \n",
       "59                 One Hot for MSE + Scale_Factr=4*64  0.060978  \n",
       "60                 One Hot for MSE + Scale_Factr=4*64  0.064010  \n",
       "61                 One Hot for MSE + Scale_Factr=4*64  0.064010  \n",
       "40  step in loop,rescale for teacher, No times 2 f...  0.078300  \n",
       "62                 One Hot for MSE + Scale_Factr=4*64  0.080490  \n",
       "49                                    3 class one hot  0.091600  \n",
       "72      One Hot for MSE + Scale_Factr=4*64 + dataset3  0.128482  \n",
       "74  One Hot for MSE + Scale_Factr=4*64 + alpha=0.5...  0.137129  \n",
       "73      One Hot for MSE + Scale_Factr=4*64 + dataset3  0.142636  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc.sort_values('diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72953cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-3badce577b81>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c['unwarped dice'] = c['unwarped dice'].apply(lambda x: x.split('(')[1].split(')')[0]).astype(float)\n",
      "<ipython-input-65-3badce577b81>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c['Eval mean dice'] = c['Eval mean dice'].apply(lambda x: x.split('(')[1].split(')')[0] if \"tensor\" in x else x).astype(float)\n",
      "<ipython-input-65-3badce577b81>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c['diff'] = c['Eval mean dice'] - c['unwarped dice']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>optim</th>\n",
       "      <th>mode</th>\n",
       "      <th>unwarped dice</th>\n",
       "      <th>loss</th>\n",
       "      <th>time</th>\n",
       "      <th>Eval mean dice</th>\n",
       "      <th>batch size</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>notes</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 08:05</td>\n",
       "      <td>0.3097</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>Sequentail label loss</td>\n",
       "      <td>03.09.21 16:56</td>\n",
       "      <td>0.4071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 08:03</td>\n",
       "      <td>0.3489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 14:03</td>\n",
       "      <td>0.3665</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>label loss</td>\n",
       "      <td>02.09.21 17:15</td>\n",
       "      <td>0.3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 10:24</td>\n",
       "      <td>0.4171</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 10:01</td>\n",
       "      <td>0.4208</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 12:36</td>\n",
       "      <td>0.4272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 09:15</td>\n",
       "      <td>0.6115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 14:29</td>\n",
       "      <td>0.4316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 14:46</td>\n",
       "      <td>0.3308</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 10:08</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 15:17</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 11:19</td>\n",
       "      <td>0.5749</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 08:15</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>80</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 14:20</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>80</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 14:20</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>80</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 14:20</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 14:21</td>\n",
       "      <td>0.3439</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 11:53</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>80</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 13:56</td>\n",
       "      <td>0.5811</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 17:08</td>\n",
       "      <td>0.5812</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 11:26</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>40</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 11:38</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.4487</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 15:44</td>\n",
       "      <td>0.5177</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>80</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 13:36</td>\n",
       "      <td>0.5827</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 11:06</td>\n",
       "      <td>0.5851</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 11:06</td>\n",
       "      <td>0.5851</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 08:54</td>\n",
       "      <td>0.7147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>60</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>10.09.21 12:11</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>all_above; 3 classes</td>\n",
       "      <td>0.0749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 08:35</td>\n",
       "      <td>0.7162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>label loss</td>\n",
       "      <td>03.09.21 12:10</td>\n",
       "      <td>0.6501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 17:35</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>09.09.21 14:34</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>HW//4, update within loop, leaveout outliers, ...</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>10.09.21 12:45</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>all_above; 3 classes</td>\n",
       "      <td>0.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5279</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 15:48</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>30</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>10.09.21 11:37</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>all_above; 3 classes</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>29.09.21 09:12</td>\n",
       "      <td>0.6683</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>16 Channels</td>\n",
       "      <td>0.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>30</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>10.09.21 11:54</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>all_above; 3 classes</td>\n",
       "      <td>0.0922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>29.09.21 10:06</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>16 Channels</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5279</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>08.09.21 16:23</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>29.09.21 10:44</td>\n",
       "      <td>0.6781</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>16 Channels</td>\n",
       "      <td>0.1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>29.09.21 11:03</td>\n",
       "      <td>0.6781</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>16 Channels</td>\n",
       "      <td>0.1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>06.01.22 11:38</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>eighted Loss</td>\n",
       "      <td>0.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1500</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5101</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>28.12.21 01:26</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>16 Channels; ampt.autocast; OneFixed</td>\n",
       "      <td>0.1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>50</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>17.12.21 14:04</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>16 Channels; ampt.autocast; OneFixed</td>\n",
       "      <td>0.1596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.5109</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>28.12.21 10:41</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>One less avg</td>\n",
       "      <td>0.1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>50</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.4122</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>17.12.21 12:34</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>16 Channels; ampt.autocast; OneFixed</td>\n",
       "      <td>0.1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>100</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>label loss</td>\n",
       "      <td>0.4122</td>\n",
       "      <td>label loss + diffloss</td>\n",
       "      <td>17.12.21 11:01</td>\n",
       "      <td>0.6126</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>16 Channels; ampt.autocast; OneFixed</td>\n",
       "      <td>0.2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs                                              optim        mode  \\\n",
       "2       10  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "11     500  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "1       10  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "14     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "0      100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "13     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "12     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "9      100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "6      100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "10     500  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "16     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "7      100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "17     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "25      20  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "3       10  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "33      80  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "31      80  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "32      80  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "15      10  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "28      40  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "30      80  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "21     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "26      30  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "27      40  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "18     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "29      80  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "24     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "23     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "5      100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "45      60  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "4      100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "8      500  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "22     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "34      30  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "46     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "19     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "42      30  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "55     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "43      30  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "56     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "20      10  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "57     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "58     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "84     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "82    1500  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "81      50  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "83     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "80      50  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "79     100  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  label loss   \n",
       "\n",
       "    unwarped dice                   loss            time  Eval mean dice  \\\n",
       "2          0.3330             label loss  03.09.21 08:05          0.3097   \n",
       "11         0.3934  Sequentail label loss  03.09.21 16:56          0.4071   \n",
       "1          0.3330             label loss  03.09.21 08:03          0.3489   \n",
       "14         0.3475  label loss + diffloss  08.09.21 14:03          0.3665   \n",
       "0          0.3238             label loss  02.09.21 17:15          0.3453   \n",
       "13         0.3934  label loss + diffloss  08.09.21 10:24          0.4171   \n",
       "12         0.3934  label loss + diffloss  08.09.21 10:01          0.4208   \n",
       "9          0.3934             label loss  03.09.21 12:36          0.4272   \n",
       "6          0.5739             label loss  03.09.21 09:15          0.6115   \n",
       "10         0.3934             label loss  03.09.21 14:29          0.4316   \n",
       "16         0.2784  label loss + diffloss  08.09.21 14:46          0.3308   \n",
       "7          0.5739             label loss  03.09.21 10:08          0.6283   \n",
       "17         0.3275  label loss + diffloss  08.09.21 15:17          0.3868   \n",
       "25         0.5134  label loss + diffloss  09.09.21 11:19          0.5749   \n",
       "3          0.6405             label loss  03.09.21 08:15          0.7025   \n",
       "33         0.5134  label loss + diffloss  09.09.21 14:20          0.5785   \n",
       "31         0.5134  label loss + diffloss  09.09.21 14:20          0.5785   \n",
       "32         0.5134  label loss + diffloss  09.09.21 14:20          0.5785   \n",
       "15         0.2784  label loss + diffloss  08.09.21 14:21          0.3439   \n",
       "28         0.5134  label loss + diffloss  09.09.21 11:53          0.5795   \n",
       "30         0.5134  label loss + diffloss  09.09.21 13:56          0.5811   \n",
       "21         0.5134  label loss + diffloss  08.09.21 17:08          0.5812   \n",
       "26         0.5134  label loss + diffloss  09.09.21 11:26          0.5820   \n",
       "27         0.5134  label loss + diffloss  09.09.21 11:38          0.5822   \n",
       "18         0.4487  label loss + diffloss  08.09.21 15:44          0.5177   \n",
       "29         0.5134  label loss + diffloss  09.09.21 13:36          0.5827   \n",
       "24         0.5134  label loss + diffloss  09.09.21 11:06          0.5851   \n",
       "23         0.5134  label loss + diffloss  09.09.21 11:06          0.5851   \n",
       "5          0.6405             label loss  03.09.21 08:54          0.7147   \n",
       "45         0.5850  label loss + diffloss  10.09.21 12:11          0.6599   \n",
       "4          0.6405             label loss  03.09.21 08:35          0.7162   \n",
       "8          0.5739             label loss  03.09.21 12:10          0.6501   \n",
       "22         0.5134  label loss + diffloss  08.09.21 17:35          0.5909   \n",
       "34         0.5134  label loss + diffloss  09.09.21 14:34          0.5930   \n",
       "46         0.5850  label loss + diffloss  10.09.21 12:45          0.6656   \n",
       "19         0.5279  label loss + diffloss  08.09.21 15:48          0.6091   \n",
       "42         0.5850  label loss + diffloss  10.09.21 11:37          0.6707   \n",
       "55         0.5779  label loss + diffloss  29.09.21 09:12          0.6683   \n",
       "43         0.5850  label loss + diffloss  10.09.21 11:54          0.6772   \n",
       "56         0.5779  label loss + diffloss  29.09.21 10:06          0.6750   \n",
       "20         0.5279  label loss + diffloss  08.09.21 16:23          0.6265   \n",
       "57         0.5779  label loss + diffloss  29.09.21 10:44          0.6781   \n",
       "58         0.5779  label loss + diffloss  29.09.21 11:03          0.6781   \n",
       "84         0.5222  label loss + diffloss  06.01.22 11:38          0.6682   \n",
       "82         0.5101  label loss + diffloss  28.12.21 01:26          0.6597   \n",
       "81         0.5198  label loss + diffloss  17.12.21 14:04          0.6794   \n",
       "83         0.5109  label loss + diffloss  28.12.21 10:41          0.6759   \n",
       "80         0.4122  label loss + diffloss  17.12.21 12:34          0.6100   \n",
       "79         0.4122  label loss + diffloss  17.12.21 11:01          0.6126   \n",
       "\n",
       "    batch size  learning rate  \\\n",
       "2          4.0        0.00020   \n",
       "11         1.0        0.00020   \n",
       "1          1.0        0.00200   \n",
       "14        10.0        0.00100   \n",
       "0          4.0        0.00020   \n",
       "13        10.0        0.00100   \n",
       "12        10.0        0.00010   \n",
       "9          1.0        0.00020   \n",
       "6          1.0        0.05000   \n",
       "10         1.0        0.00020   \n",
       "16         5.0        0.00010   \n",
       "7          1.0        0.00010   \n",
       "17         5.0        0.00010   \n",
       "25        10.0        0.00001   \n",
       "3          1.0        0.00200   \n",
       "33         4.0        0.00200   \n",
       "31         4.0        0.00200   \n",
       "32         4.0        0.00200   \n",
       "15         5.0        0.00100   \n",
       "28        20.0        0.00001   \n",
       "30        20.0        0.00001   \n",
       "21        10.0        0.00200   \n",
       "26        10.0        0.00001   \n",
       "27        10.0        0.00001   \n",
       "18         5.0        0.00010   \n",
       "29        20.0        0.00010   \n",
       "24         4.0        0.00005   \n",
       "23         4.0        0.00005   \n",
       "5          1.0        0.00500   \n",
       "45        20.0        0.00020   \n",
       "4          1.0        0.00200   \n",
       "8          1.0        0.00020   \n",
       "22        10.0        0.00500   \n",
       "34        30.0        0.00200   \n",
       "46        20.0        0.00020   \n",
       "19         5.0        0.00010   \n",
       "42        10.0        0.00020   \n",
       "55        20.0        0.00020   \n",
       "43        20.0        0.00020   \n",
       "56        30.0        0.00020   \n",
       "20         4.0        0.00200   \n",
       "57        40.0        0.00020   \n",
       "58        40.0        0.00020   \n",
       "84        20.0        0.00100   \n",
       "82        20.0        0.00100   \n",
       "81        20.0        0.00020   \n",
       "83        20.0        0.00100   \n",
       "80        20.0        0.00020   \n",
       "79        20.0        0.00020   \n",
       "\n",
       "                                                notes    diff  \n",
       "2                                                 NaN -0.0233  \n",
       "11                                                NaN  0.0137  \n",
       "1                                                 NaN  0.0159  \n",
       "14                                                NaN  0.0190  \n",
       "0                                                 NaN  0.0215  \n",
       "13                                                NaN  0.0237  \n",
       "12                                                NaN  0.0274  \n",
       "9                                                 NaN  0.0338  \n",
       "6                                                 NaN  0.0376  \n",
       "10                                                NaN  0.0382  \n",
       "16                                                NaN  0.0524  \n",
       "7                                                 NaN  0.0544  \n",
       "17                                                NaN  0.0593  \n",
       "25  HW//4, update within loop, leaveout outliers, ...  0.0615  \n",
       "3                                                 NaN  0.0620  \n",
       "33  HW//4, update within loop, leaveout outliers, ...  0.0651  \n",
       "31  HW//4, update within loop, leaveout outliers, ...  0.0651  \n",
       "32  HW//4, update within loop, leaveout outliers, ...  0.0651  \n",
       "15                                                NaN  0.0655  \n",
       "28  HW//4, update within loop, leaveout outliers, ...  0.0661  \n",
       "30  HW//4, update within loop, leaveout outliers, ...  0.0677  \n",
       "21                                                NaN  0.0678  \n",
       "26  HW//4, update within loop, leaveout outliers, ...  0.0686  \n",
       "27  HW//4, update within loop, leaveout outliers, ...  0.0688  \n",
       "18                                                NaN  0.0690  \n",
       "29  HW//4, update within loop, leaveout outliers, ...  0.0693  \n",
       "24  HW//4, update within loop, leaveout outliers, ...  0.0717  \n",
       "23                                                NaN  0.0717  \n",
       "5                                                 NaN  0.0742  \n",
       "45                               all_above; 3 classes  0.0749  \n",
       "4                                                 NaN  0.0757  \n",
       "8                                                 NaN  0.0762  \n",
       "22                                                NaN  0.0775  \n",
       "34  HW//4, update within loop, leaveout outliers, ...  0.0796  \n",
       "46                               all_above; 3 classes  0.0806  \n",
       "19                                                NaN  0.0812  \n",
       "42                               all_above; 3 classes  0.0857  \n",
       "55                                        16 Channels  0.0904  \n",
       "43                               all_above; 3 classes  0.0922  \n",
       "56                                        16 Channels  0.0971  \n",
       "20                                                NaN  0.0986  \n",
       "57                                        16 Channels  0.1002  \n",
       "58                                        16 Channels  0.1002  \n",
       "84                                       eighted Loss  0.1460  \n",
       "82               16 Channels; ampt.autocast; OneFixed  0.1496  \n",
       "81               16 Channels; ampt.autocast; OneFixed  0.1596  \n",
       "83                                       One less avg  0.1650  \n",
       "80               16 Channels; ampt.autocast; OneFixed  0.1978  \n",
       "79               16 Channels; ampt.autocast; OneFixed  0.2004  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = df[df['mode'] == 'label loss']\n",
    "c['unwarped dice'] = c['unwarped dice'].apply(lambda x: x.split('(')[1].split(')')[0]).astype(float)\n",
    "c['Eval mean dice'] = c['Eval mean dice'].apply(lambda x: x.split('(')[1].split(')')[0] if \"tensor\" in x else x).astype(float)\n",
    "c['diff'] = c['Eval mean dice'] - c['unwarped dice']\n",
    "c.sort_values('diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd13b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
