{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bee34bf",
   "metadata": {},
   "source": [
    "# Estimating space an time needed for PDD inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import ceil\n",
    "\n",
    "from utils.preprocessing import preprocessing_flownet, preprocessing_pwc\n",
    "from utils.load_models import load_flownet2, load_pwcnet, init_weights\n",
    "from utils.plotting import flow2img, overlaySegment, showFlow\n",
    "from utils.layers import warp, warpImage\n",
    "from utils.encoding import labelMatrixOneHot, dice_coeff\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "available_gpus = [(torch.cuda.device(i),torch.cuda.get_device_name(i)) for i in range(torch.cuda.device_count())]\n",
    "print(available_gpus)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e76dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W,H = (150,150)\n",
    "o_m = H//4 +1\n",
    "o_n = W//4 +1\n",
    "ogrid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,o_m,o_n)).view(1,1,-1,2).cuda()\n",
    "disp_range = 0.25#0.25\n",
    "displacement_width = 15#15#11#17\n",
    "grid_size = 32#25#30\n",
    "disp_hw = 5\n",
    "displace_range = 11\n",
    "grid_xy = F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,grid_size,grid_size)).view(1,-1,1,2).cuda()\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_normal(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant(m.bias, 0.0)\n",
    "\n",
    "class OBELISK2d(nn.Module):\n",
    "    def __init__(self, chan = 16):\n",
    "\n",
    "        super(OBELISK2d, self).__init__()\n",
    "        channels = chan\n",
    "        self.offsets = nn.Parameter(torch.randn(2,channels *2,2) *0.05)\n",
    "        self.layer0 = nn.Conv2d(1, 4, 5, stride=2, bias=False, padding=2)\n",
    "        self.batch0 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.layer1 = nn.Conv2d(channels *8, channels *4, 1, bias=False, groups=1)\n",
    "        self.batch1 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer2 = nn.Conv2d(channels *4, channels *4, 3, bias=False, padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(channels *4)\n",
    "        self.layer3 = nn.Conv2d(channels *4, channels *1, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_img):\n",
    "        img_in = F.avg_pool2d(input_img ,3 ,padding=1 ,stride=2)\n",
    "        img_in = F.relu(self.batch0(self.layer0(img_in)))\n",
    "        sampled = F.grid_sample(img_in ,ogrid_xy + self.offsets[0 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "        sampled -= F.grid_sample(img_in ,ogrid_xy + self.offsets[1 ,:,:].view(1 ,-1 ,1 ,2)).view(1 ,-1 ,o_m ,o_n)\n",
    "\n",
    "        x = F.relu(self.batch1(self.layer1(sampled)))\n",
    "        x = F.relu(self.batch2(self.layer2(x)))\n",
    "        features = self.layer3(x)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_convolution(ssd_distance, displace_range, H, W):\n",
    "    # Prepare operators for smooth dense displacement space\n",
    "    pad1 = nn.ReplicationPad2d(5)\n",
    "    avg1 = nn.AvgPool2d(5,stride=1)\n",
    "    max1 = nn.MaxPool2d(3,stride=1)\n",
    "    pad2 = nn.ReplicationPad2d(6)\n",
    "    # approximate min convolution / displacement compatibility\n",
    "\n",
    "    ssd_minconv = avg1(avg1(-max1(-pad1(ssd_distance.permute(0,2,3,1).reshape(1,-1,displace_range,displace_range)))))\n",
    "\n",
    "    ssd_minconv = ssd_minconv.permute(0,2,3,1).view(1,-1,H,W)\n",
    "    min_conv_cost = avg1(avg1(avg1(pad2(ssd_minconv))))\n",
    "    \n",
    "    return min_conv_cost\n",
    "\n",
    "def meanfield(ssd_distance,img_fixed,displace_range,H,W):\n",
    "\n",
    "    crnt_dev = ssd_distance.device\n",
    "\n",
    "    cost = min_convolution(ssd_distance, displace_range, H, W)\n",
    "\n",
    "    soft_cost = F.softmax(-10*cost.view(displace_range**2,-1).t(),1)\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    disp_mesh_grid = disp_hw*F.affine_grid(torch.eye(2,3).unsqueeze(0),(1,1,displace_range,displace_range),align_corners=True)\n",
    "    disp_mesh_grid /= torch.Tensor([(W-1)*.5,(H-1)*.5])\n",
    "\n",
    "    disp_xy = torch.sum(soft_cost.view(1,H,W,-1,1)*disp_mesh_grid.view(1,1,1,-1,2).to(crnt_dev),3).permute(0,3,1,2) \n",
    "    \n",
    "\n",
    "    return soft_cost,disp_xy\n",
    "\n",
    "def correlation_layer(displace_range, feat_moving, feat_fixed):\n",
    "    \n",
    "    disp_hw = (displace_range-1)//2\n",
    "    feat_moving_unfold = F.unfold(feat_moving.transpose(1,0),(displace_range,displace_range),padding=disp_hw)\n",
    "    B,C,H,W = feat_fixed.size()\n",
    "    \n",
    "    ssd_distance = ((feat_moving_unfold-feat_fixed.view(C,1,-1))**2).sum(0).view(1,displace_range**2,H,W)\n",
    "\n",
    "    return ssd_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_state_dict = \"models/Experiment_3/14_10_21-16-40/student_0.pth\"\n",
    "model_24 = OBELISK2d(24)\n",
    "model_24.load_state_dict(torch.load(path_to_state_dict))\n",
    "\n",
    "path_to_state_dict = \"models/Experiment_2/obel16_ensemble_13_10_21-21-30.pth\"\n",
    "model_16 = OBELISK2d(16)\n",
    "model_16.load_state_dict(torch.load(path_to_state_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e303d",
   "metadata": {},
   "source": [
    "# Space usage of different models\n",
    "comparing the inferenc time of models with 16 and 24 feature channels and the baseline algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1cd744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b093a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_16.cuda(), torch.zeros(1,1,150,150), verbose=False, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_24.cuda(), torch.zeros(1,1,150,150), verbose=False, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b9e94",
   "metadata": {},
   "source": [
    "# Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b51113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d94cb1",
   "metadata": {},
   "source": [
    "Time of a 24 feature channel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ab2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='feat1 = model(img1)\\nfeat2 = model(img2)\\nssd_distance = correlation_layer(displace_range, feat2, feat1)\\nsoft_cost,disp_xy = meanfield(ssd_distance, img1, displace_range, H//4, W//4)\\nflow=interpolate(disp_xy,size=(150,150))',\n",
    "    globals={'model': model_24.cpu(), \n",
    "            'img1': torch.rand(1,1,150,150).cpu(),\n",
    "             'img2': torch.rand(1,1,150,150).cpu(),\n",
    "             'correlation_layer': correlation_layer,\n",
    "            'displace_range': displace_range,\n",
    "            'meanfield': meanfield,\n",
    "            'H': 150,\n",
    "            'W': 150,\n",
    "            'interpolate': F.interpolate})\n",
    "t0.timeit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing it manually to have a time plot and a mean\n",
    "times = []\n",
    "for i in range(100):\n",
    "    \n",
    "    # create pseudo imgs\n",
    "    img1 = torch.rand(1,1,150,150)\n",
    "    img2 = torch.rand(1,1,150,150)\n",
    "    \n",
    "    # measure time\n",
    "    start = time.time()\n",
    "    \n",
    "    # forward pass\n",
    "    feat1 = model_24(img2)\n",
    "    feat2 = model_24(img1)\n",
    "    ssd_distance = correlation_layer(displace_range, feat2, feat1)\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, img1, displace_range, H//4, W//4)\n",
    "    # scaling\n",
    "    flow=F.interpolate(disp_xy,size=(150,150))\n",
    "    \n",
    "    # end measurement\n",
    "    end = time.time()\n",
    "    times.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243120e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=np.arange(100), y=times)\n",
    "plt.plot(np.tile(np.mean(times), 100), color='r', label=f'mean = {round(np.mean(times), 5)}')\n",
    "plt.legend()\n",
    "plt.savefig('plots/runtime_model24_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6187105a",
   "metadata": {},
   "source": [
    "Time of a 16 feature channel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e18ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='feat1 = model(img1)\\nfeat2 = model(img1)\\nssd_distance = correlation_layer(displace_range, feat2, feat1)\\nsoft_cost,disp_xy = meanfield(ssd_distance, img1, displace_range, H//4, W//4)\\nflow=interpolate(disp_xy,size=(150,150))',\n",
    "    globals={'model': model_16.cpu(), \n",
    "            'img1': torch.rand(1,1,150,150).cpu(),\n",
    "             'img2': torch.rand(1,1,150,150).cpu(),\n",
    "             'correlation_layer': correlation_layer,\n",
    "            'displace_range': displace_range,\n",
    "            'meanfield': meanfield,\n",
    "            'H': 150,\n",
    "            'W': 150,\n",
    "            'interpolate': F.interpolate})\n",
    "t0.timeit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fced37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing it manually to have a time plot and a mean\n",
    "times = []\n",
    "for i in range(100):\n",
    "    \n",
    "    # create pseudo imgs\n",
    "    img1 = torch.rand(1,1,150,150)\n",
    "    img2 = torch.rand(1,1,150,150)\n",
    "    \n",
    "    # measure time\n",
    "    start = time.time()\n",
    "    \n",
    "    # forward pass\n",
    "    feat1 = model_16(img2)\n",
    "    feat2 = model_16(img1)\n",
    "    ssd_distance = correlation_layer(displace_range, feat2, feat1)\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, img1, displace_range, H//4, W//4)\n",
    "    # scaling\n",
    "    flow=F.interpolate(disp_xy,size=(150,150))\n",
    "    \n",
    "    # end measurement\n",
    "    end = time.time()\n",
    "    times.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe628c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=np.arange(100), y=times)\n",
    "plt.plot(np.tile(np.mean(times), 100), color='r', label=f'mean = {round(np.mean(times), 5)}')\n",
    "plt.legend()\n",
    "plt.savefig('plots/runtime_model16_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65870c29",
   "metadata": {},
   "source": [
    "Time of the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff23b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "print(\"Inner iterations: \", baseline.getInnerIterations())\n",
    "print(\"Outer iterations: \", baseline.getOuterIterations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011e05e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='calc(in1,in2,None)',\n",
    "    num_threads=10,\n",
    "    globals={'calc': baseline.calc, \n",
    "            'in1': np.random.uniform(size=(150,150,1)).astype(np.float32),\n",
    "             'in2': np.random.uniform(size=(150,150,1)).astype(np.float32)})\n",
    "t0.timeit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e27e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='calc(in1,in2,None)',\n",
    "    globals={'calc': baseline.calc, \n",
    "            'in1': np.random.uniform(size=(150,150,1)).astype(np.float32),\n",
    "             'in2': np.random.uniform(size=(150,150,1)).astype(np.float32)})\n",
    "t0.timeit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b211f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='calc(in1,in2,None)',\n",
    "    num_threads=50,\n",
    "    globals={'calc': baseline.calc, \n",
    "            'in1': np.random.uniform(size=(150,150,1)).astype(np.float32),\n",
    "             'in2': np.random.uniform(size=(150,150,1)).astype(np.float32)})\n",
    "t0.timeit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb580d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing it manually to have a time plot and a mean\n",
    "times = []\n",
    "for i in range(100):\n",
    "    \n",
    "    # create pseudo imgs\n",
    "    img1 = np.random.uniform(size=(150,150,1)).astype(np.float32)\n",
    "    img2 = np.random.uniform(size=(150,150,1)).astype(np.float32)\n",
    "    \n",
    "    # measure time\n",
    "    start = time.time()\n",
    "    flow = baseline.calc(img1, img2, None)\n",
    "    \n",
    "    # end measurement\n",
    "    end = time.time()\n",
    "    times.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=np.arange(100), y=times)\n",
    "plt.plot(np.tile(np.mean(times), 100), color='r', label=f'mean = {round(np.mean(times), 5)}')\n",
    "plt.legend()\n",
    "plt.savefig('plots/runtime_baseline_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac3b5d",
   "metadata": {},
   "source": [
    "# Verdict\n",
    "Running it on the server on Tue 26.10.2021 around 22:20 - 22:25 with no other thread using the CPUs and GPUs.\n",
    "\n",
    "I am getting 358 ms with 10m, 365 ms with 1 thread and 362 ms with 50 threads for DualTVL1 and 91.05 or 74ms for the two PDD-Nets 24 and 16 respectively.\n",
    "With GPU acceleration, these numbers drop to 2.8 and 2.1 ms respectively. \n",
    "Taking the mean of about 80ms, and 360ms for the baseline, the PDD-Net is about 4.5 times faster in computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a829b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OBELISK2d(16)\n",
    "model.cuda()\n",
    "\n",
    "seq = torch.nn.Sequential(torch.nn.Conv2d(1,32,kernel_size=5,stride=2,padding=4,dilation=2),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(32),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(32,64,kernel_size=3,stride=2,padding=1,dilation=1),\n",
    "                          torch.nn.BatchNorm2d(64),\n",
    "                          torch.nn.PReLU(),\n",
    "                          torch.nn.Conv2d(64,16,kernel_size=1,stride=1,padding=0,dilation=1),\n",
    "                          torch.nn.Sigmoid())\n",
    "seq.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fe82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obel_time = []\n",
    "seq_time = []\n",
    "for i in range(100):\n",
    "    in1 = torch.rand(1,1,150,150)\n",
    "    in2 = torch.rand(1,1,150,150)\n",
    "    \n",
    "    feat1 = model(in1.cuda())\n",
    "    start = time.time()\n",
    "    #feat1 = model(in1.cuda())\n",
    "    feat2 = model(in2.cuda())\n",
    "    ssd_distance = correlation_layer(displace_range, feat1, feat2)\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, in1, displace_range, H//4 +1, W//4 +1)\n",
    "    end = time.time()\n",
    "    \n",
    "    obel_time.append((end-start)*1000)\n",
    "    \n",
    "    \n",
    "    in1 = torch.rand(1,1,150,150)\n",
    "    in2 = torch.rand(1,1,150,150)\n",
    "    \n",
    "    feat1 = seq(in1.cuda())\n",
    "    start = time.time()\n",
    "    #feat1 = seq(in1.cuda())\n",
    "    \n",
    "    feat2 = seq(in2.cuda())\n",
    "    ssd_distance = correlation_layer(displace_range, feat1, feat2)\n",
    "    soft_cost,disp_xy = meanfield(ssd_distance, in1, displace_range, H//4 +1, W//4 +1)\n",
    "    end = time.time()\n",
    "    \n",
    "    seq_time.append((end-start)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts = {'fontsize': 22,'family': 'Latin Modern Roman'}\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.scatter(np.arange(100), obel_time, label=f'Obelisk: {round(np.mean(obel_time), 3)}', alpha=0.5)\n",
    "plt.scatter(np.arange(100), seq_time, label=f'Sequential: {round(np.mean(seq_time), 3)}', alpha=0.5)\n",
    "plt.xlabel('# of Iterations', fontdict=fonts)\n",
    "plt.ylabel('Time [ms]', fontdict=fonts)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8046f7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
